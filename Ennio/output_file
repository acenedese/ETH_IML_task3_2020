Sender: LSF System <lsfadmin@eu-c7-048-04>
Subject: Job 120109624: <python3.7 ./find_parameters.py> in cluster <euler> Done

Job <python3.7 ./find_parameters.py> was submitted from host <eu-login-37> by user <efilicicc> in cluster <euler> at Tue Apr 28 21:48:38 2020
Job was executed on host(s) <2*eu-c7-048-04>, in queue <normal.24h>, as user <efilicicc> in cluster <euler> at Tue Apr 28 21:48:55 2020
</cluster/home/efilicicc> was used as the home directory.
</cluster/home/efilicicc/3_task/Ennio> was used as the working directory.
Started at Tue Apr 28 21:48:55 2020
Terminated at Wed Apr 29 00:32:33 2020
Results reported at Wed Apr 29 00:32:33 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3.7 ./find_parameters.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   9822.48 sec.
    Max Memory :                                 759 MB
    Average Memory :                             682.74 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               1289.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   9827 sec.
    Turnaround time :                            9835 sec.

The output (if any) follows:

Iteration 1, loss = 0.15081349
Iteration 2, loss = 0.06629567
Iteration 3, loss = 0.05594935
Iteration 4, loss = 0.04893689
Iteration 5, loss = 0.04339061
Iteration 6, loss = 0.03903814
Iteration 7, loss = 0.03577594
Iteration 8, loss = 0.03310831
Iteration 9, loss = 0.03091754
Iteration 10, loss = 0.02907779
Iteration 11, loss = 0.02748625
Iteration 12, loss = 0.02616057
Iteration 13, loss = 0.02504600
Iteration 14, loss = 0.02399786
Iteration 15, loss = 0.02301452
Iteration 16, loss = 0.02207514
Iteration 17, loss = 0.02133836
Iteration 18, loss = 0.02064991
Iteration 19, loss = 0.01998055
Iteration 20, loss = 0.01948043
Iteration 21, loss = 0.01882939
Iteration 22, loss = 0.01833728
Iteration 23, loss = 0.01778442
Iteration 24, loss = 0.01736081
Iteration 25, loss = 0.01681572
Iteration 26, loss = 0.01645772
Iteration 27, loss = 0.01613727
Iteration 28, loss = 0.01566859
Iteration 29, loss = 0.01533429
Iteration 30, loss = 0.01486252
Iteration 31, loss = 0.01460621
Iteration 32, loss = 0.01437994
Iteration 33, loss = 0.01401949
Iteration 34, loss = 0.01358846
Iteration 35, loss = 0.01333849
Iteration 36, loss = 0.01310233
Iteration 37, loss = 0.01283887
Iteration 38, loss = 0.01251085
Iteration 39, loss = 0.01236957
Iteration 40, loss = 0.01214606
Iteration 41, loss = 0.01188157
Iteration 42, loss = 0.01159528
Iteration 43, loss = 0.01137774
Iteration 44, loss = 0.01116102
Iteration 45, loss = 0.01095461
Iteration 46, loss = 0.01077567
Iteration 47, loss = 0.01058927
Iteration 48, loss = 0.01028248
Iteration 49, loss = 0.01014768
Iteration 50, loss = 0.00998305
Iteration 51, loss = 0.00980029
Iteration 52, loss = 0.00956561
Iteration 53, loss = 0.00939456
Iteration 54, loss = 0.00927627
Iteration 55, loss = 0.00915904
Iteration 56, loss = 0.00890855
Iteration 57, loss = 0.00882036
Iteration 58, loss = 0.00865908
Iteration 59, loss = 0.00850476
Iteration 60, loss = 0.00834852
Iteration 61, loss = 0.00818951
Iteration 62, loss = 0.00803958
Iteration 63, loss = 0.00787441
Iteration 64, loss = 0.00777887
Iteration 65, loss = 0.00767577
Iteration 66, loss = 0.00751683
Iteration 67, loss = 0.00731201
Iteration 68, loss = 0.00722167
Iteration 69, loss = 0.00706172
Iteration 70, loss = 0.00706168
Iteration 71, loss = 0.00696146
Iteration 72, loss = 0.00671932
Iteration 73, loss = 0.00666502
Iteration 74, loss = 0.00655483
Iteration 75, loss = 0.00639081
Iteration 76, loss = 0.00639481
Iteration 77, loss = 0.00629826
Iteration 78, loss = 0.00614341
Iteration 79, loss = 0.00605746
Iteration 80, loss = 0.00590673
Iteration 81, loss = 0.00586721
Iteration 82, loss = 0.00573905
Iteration 83, loss = 0.00560414
Iteration 84, loss = 0.00558624
Iteration 85, loss = 0.00547202
Iteration 86, loss = 0.00534058
Iteration 87, loss = 0.00523292
Iteration 88, loss = 0.00518782
Iteration 89, loss = 0.00510684
Iteration 90, loss = 0.00503433
Iteration 91, loss = 0.00496181
Iteration 92, loss = 0.00482366
Iteration 93, loss = 0.00481323
Iteration 94, loss = 0.00465574
Iteration 95, loss = 0.00468148
Iteration 96, loss = 0.00457983
Iteration 97, loss = 0.00447172
Iteration 98, loss = 0.00449520
Iteration 99, loss = 0.00435856
Iteration 100, loss = 0.00429771
Iteration 101, loss = 0.00416668
Iteration 102, loss = 0.00413390
Iteration 103, loss = 0.00408822
Iteration 104, loss = 0.00421062
Iteration 105, loss = 0.00392480
Iteration 106, loss = 0.00395963
Iteration 107, loss = 0.00383852
Iteration 108, loss = 0.00377440
Iteration 109, loss = 0.00374667
Iteration 110, loss = 0.00372455
Iteration 111, loss = 0.00369677
Iteration 112, loss = 0.00357443
Iteration 113, loss = 0.00349583
Iteration 114, loss = 0.00350947
Iteration 115, loss = 0.00340264
Iteration 116, loss = 0.00342747
Iteration 117, loss = 0.00330344
Iteration 118, loss = 0.00330727
Iteration 119, loss = 0.00324014
Iteration 120, loss = 0.00316454
Iteration 121, loss = 0.00305585
Iteration 122, loss = 0.00302846
Iteration 123, loss = 0.00299654
Iteration 124, loss = 0.00299399
Iteration 125, loss = 0.00301975
Iteration 126, loss = 0.00297522
Iteration 127, loss = 0.00288005
Iteration 128, loss = 0.00281531
Iteration 129, loss = 0.00280125
Iteration 130, loss = 0.00273116
Iteration 131, loss = 0.00274435
Iteration 132, loss = 0.00269947
Iteration 133, loss = 0.00264667
Iteration 134, loss = 0.00253632
Iteration 135, loss = 0.00251241
Iteration 136, loss = 0.00243150
Iteration 137, loss = 0.00250387
Iteration 138, loss = 0.00255280
Iteration 139, loss = 0.00240707
Iteration 140, loss = 0.00235289
Iteration 141, loss = 0.00231201
Iteration 142, loss = 0.00226233
Iteration 143, loss = 0.00228100
Iteration 144, loss = 0.00225353
Iteration 145, loss = 0.00218154
Iteration 146, loss = 0.00215123
Iteration 147, loss = 0.00210449
Iteration 148, loss = 0.00210628
Iteration 149, loss = 0.00216415
Iteration 150, loss = 0.00205252
Iteration 151, loss = 0.00201345
Iteration 152, loss = 0.00198435
Iteration 153, loss = 0.00200938
Iteration 154, loss = 0.00192917
Iteration 155, loss = 0.00189082
Iteration 156, loss = 0.00190883
Iteration 157, loss = 0.00186393
Iteration 158, loss = 0.00186550
Iteration 159, loss = 0.00175115
Iteration 160, loss = 0.00183046
Iteration 161, loss = 0.00170162
Iteration 162, loss = 0.00164353
Iteration 163, loss = 0.00176569
Iteration 164, loss = 0.00169116
Iteration 165, loss = 0.00166469
Iteration 166, loss = 0.00162282
Iteration 167, loss = 0.00160315
Iteration 168, loss = 0.00162997
Iteration 169, loss = 0.00160775
Iteration 170, loss = 0.00147441
Iteration 171, loss = 0.00152435
Iteration 172, loss = 0.00155484
Iteration 173, loss = 0.00155436
Iteration 174, loss = 0.00148158
Iteration 175, loss = 0.00145915
Iteration 176, loss = 0.00137346
Iteration 177, loss = 0.00139548
Iteration 178, loss = 0.00137325
Iteration 179, loss = 0.00134461
Iteration 180, loss = 0.00132607
Iteration 181, loss = 0.00134977
Iteration 182, loss = 0.00134793
Iteration 183, loss = 0.00132569
Iteration 184, loss = 0.00126562
Iteration 185, loss = 0.00127595
Iteration 186, loss = 0.00125205
Iteration 187, loss = 0.00125947
Iteration 188, loss = 0.00123870
Iteration 189, loss = 0.00116119
Iteration 190, loss = 0.00120270
Iteration 191, loss = 0.00119841
Iteration 192, loss = 0.00121973
Iteration 193, loss = 0.00113858
Iteration 194, loss = 0.00110491
Iteration 195, loss = 0.00114730
Iteration 196, loss = 0.00118821
Iteration 197, loss = 0.00111628
Iteration 198, loss = 0.00102902
Iteration 199, loss = 0.00113591
Iteration 200, loss = 0.00106181
Iteration 1, loss = 0.16435600
Iteration 2, loss = 0.07103818
Iteration 3, loss = 0.05874414
Iteration 4, loss = 0.05169591
Iteration 5, loss = 0.04617900
Iteration 6, loss = 0.04155837
Iteration 7, loss = 0.03761164
Iteration 8, loss = 0.03398732
Iteration 9, loss = 0.03136300
Iteration 10, loss = 0.02912185
Iteration 11, loss = 0.02735789
Iteration 12, loss = 0.02591784
Iteration 13, loss = 0.02459707
Iteration 14, loss = 0.02355954
Iteration 15, loss = 0.02264808
Iteration 16, loss = 0.02173091
Iteration 17, loss = 0.02087924
Iteration 18, loss = 0.02018544
Iteration 19, loss = 0.01951303
Iteration 20, loss = 0.01881727
Iteration 21, loss = 0.01830295
Iteration 22, loss = 0.01767657
Iteration 23, loss = 0.01711121
Iteration 24, loss = 0.01675798
Iteration 25, loss = 0.01627068
Iteration 26, loss = 0.01587611
Iteration 27, loss = 0.01547257
Iteration 28, loss = 0.01502273
Iteration 29, loss = 0.01466900
Iteration 30, loss = 0.01434580
Iteration 31, loss = 0.01399568
Iteration 32, loss = 0.01362837
Iteration 33, loss = 0.01326119
Iteration 34, loss = 0.01303421
Iteration 35, loss = 0.01272311
Iteration 36, loss = 0.01236483
Iteration 37, loss = 0.01215512
Iteration 38, loss = 0.01184416
Iteration 39, loss = 0.01167790
Iteration 40, loss = 0.01133994
Iteration 41, loss = 0.01113832
Iteration 42, loss = 0.01100705
Iteration 43, loss = 0.01073501
Iteration 44, loss = 0.01042873
Iteration 45, loss = 0.01023060
Iteration 46, loss = 0.01012796
Iteration 47, loss = 0.00988031
Iteration 48, loss = 0.00971348
Iteration 49, loss = 0.00940489
Iteration 50, loss = 0.00936734
Iteration 51, loss = 0.00915418
Iteration 52, loss = 0.00892773
Iteration 53, loss = 0.00882478
Iteration 54, loss = 0.00861002
Iteration 55, loss = 0.00845861
Iteration 56, loss = 0.00830054
Iteration 57, loss = 0.00820081
Iteration 58, loss = 0.00803703
Iteration 59, loss = 0.00789427
Iteration 60, loss = 0.00774500
Iteration 61, loss = 0.00751987
Iteration 62, loss = 0.00744400
Iteration 63, loss = 0.00728882
Iteration 64, loss = 0.00713998
Iteration 65, loss = 0.00702627
Iteration 66, loss = 0.00688687
Iteration 67, loss = 0.00678207
Iteration 68, loss = 0.00671254
Iteration 69, loss = 0.00657371
Iteration 70, loss = 0.00642831
Iteration 71, loss = 0.00633508
Iteration 72, loss = 0.00611844
Iteration 73, loss = 0.00608105
Iteration 74, loss = 0.00598832
Iteration 75, loss = 0.00590772
Iteration 76, loss = 0.00572446
Iteration 77, loss = 0.00575544
Iteration 78, loss = 0.00557201
Iteration 79, loss = 0.00554132
Iteration 80, loss = 0.00548582
Iteration 81, loss = 0.00538225
Iteration 82, loss = 0.00531894
Iteration 83, loss = 0.00514137
Iteration 84, loss = 0.00505187
Iteration 85, loss = 0.00496407
Iteration 86, loss = 0.00490691
Iteration 87, loss = 0.00482342
Iteration 88, loss = 0.00470283
Iteration 89, loss = 0.00466196
Iteration 90, loss = 0.00457694
Iteration 91, loss = 0.00455884
Iteration 92, loss = 0.00435397
Iteration 93, loss = 0.00440643
Iteration 94, loss = 0.00420542
Iteration 95, loss = 0.00420256
Iteration 96, loss = 0.00417552
Iteration 97, loss = 0.00404173
Iteration 98, loss = 0.00400431
Iteration 99, loss = 0.00388205
Iteration 100, loss = 0.00390011
Iteration 101, loss = 0.00380966
Iteration 102, loss = 0.00376038
Iteration 103, loss = 0.00369822
Iteration 104, loss = 0.00362815
Iteration 105, loss = 0.00354300
Iteration 106, loss = 0.00354323
Iteration 107, loss = 0.00339618
Iteration 108, loss = 0.00345658
Iteration 109, loss = 0.00327688
Iteration 110, loss = 0.00320579
Iteration 111, loss = 0.00323518
Iteration 112, loss = 0.00321035
Iteration 113, loss = 0.00312848
Iteration 114, loss = 0.00312463
Iteration 115, loss = 0.00304249
Iteration 116, loss = 0.00296313
Iteration 117, loss = 0.00285920
Iteration 118, loss = 0.00295027
Iteration 119, loss = 0.00285182
Iteration 120, loss = 0.00274226
Iteration 121, loss = 0.00273379
Iteration 122, loss = 0.00270909
Iteration 123, loss = 0.00266104
Iteration 124, loss = 0.00260924
Iteration 125, loss = 0.00258257
Iteration 126, loss = 0.00252123
Iteration 127, loss = 0.00250497
Iteration 128, loss = 0.00244976
Iteration 129, loss = 0.00237734
Iteration 130, loss = 0.00236230
Iteration 131, loss = 0.00231088
Iteration 132, loss = 0.00231229
Iteration 133, loss = 0.00229175
Iteration 134, loss = 0.00222754
Iteration 135, loss = 0.00216318
Iteration 136, loss = 0.00219655
Iteration 137, loss = 0.00216486
Iteration 138, loss = 0.00207644
Iteration 139, loss = 0.00208765
Iteration 140, loss = 0.00202825
Iteration 141, loss = 0.00199797
Iteration 142, loss = 0.00192250
Iteration 143, loss = 0.00193828
Iteration 144, loss = 0.00191927
Iteration 145, loss = 0.00187566
Iteration 146, loss = 0.00183032
Iteration 147, loss = 0.00186384
Iteration 148, loss = 0.00183293
Iteration 149, loss = 0.00181089
Iteration 150, loss = 0.00172114
Iteration 151, loss = 0.00168861
Iteration 152, loss = 0.00171751
Iteration 153, loss = 0.00169296
Iteration 154, loss = 0.00164284
Iteration 155, loss = 0.00167098
Iteration 156, loss = 0.00159769
Iteration 157, loss = 0.00164325
Iteration 158, loss = 0.00155503
Iteration 159, loss = 0.00149943
Iteration 160, loss = 0.00151151
Iteration 161, loss = 0.00148658
Iteration 162, loss = 0.00147552
Iteration 163, loss = 0.00143787
Iteration 164, loss = 0.00144611
Iteration 165, loss = 0.00142484
Iteration 166, loss = 0.00140699
Iteration 167, loss = 0.00139071
Iteration 168, loss = 0.00138764
Iteration 169, loss = 0.00135180
Iteration 170, loss = 0.00131053
Iteration 171, loss = 0.00131811
Iteration 172, loss = 0.00128936
Iteration 173, loss = 0.00128013
Iteration 174, loss = 0.00136575
Iteration 175, loss = 0.00123310
Iteration 176, loss = 0.00122031
Iteration 177, loss = 0.00118049
Iteration 178, loss = 0.00126541
Iteration 179, loss = 0.00117637
Iteration 180, loss = 0.00117816
Iteration 181, loss = 0.00121526
Iteration 182, loss = 0.00111200
Iteration 183, loss = 0.00111092
Iteration 184, loss = 0.00111113
Iteration 185, loss = 0.00109912
Iteration 186, loss = 0.00110466
Iteration 187, loss = 0.00106876
Iteration 188, loss = 0.00109578
Iteration 189, loss = 0.00106921
Iteration 190, loss = 0.00103838
Iteration 191, loss = 0.00107724
Iteration 192, loss = 0.00099356
Iteration 193, loss = 0.00101742
Iteration 194, loss = 0.00097652
Iteration 195, loss = 0.00099702
Iteration 196, loss = 0.00098876
Iteration 197, loss = 0.00103642
Iteration 198, loss = 0.00099584
Iteration 199, loss = 0.00097773
Iteration 200, loss = 0.00094362
Iteration 1, loss = 0.16450926
Iteration 2, loss = 0.06877060
Iteration 3, loss = 0.05772089
Iteration 4, loss = 0.05059396
Iteration 5, loss = 0.04463428
Iteration 6, loss = 0.04007814
Iteration 7, loss = 0.03637534
Iteration 8, loss = 0.03339546
Iteration 9, loss = 0.03099984
Iteration 10, loss = 0.02904333
Iteration 11, loss = 0.02738761
Iteration 12, loss = 0.02583652
Iteration 13, loss = 0.02470377
Iteration 14, loss = 0.02349709
Iteration 15, loss = 0.02253470
Iteration 16, loss = 0.02156430
Iteration 17, loss = 0.02072310
Iteration 18, loss = 0.02005585
Iteration 19, loss = 0.01929861
Iteration 20, loss = 0.01871855
Iteration 21, loss = 0.01809571
Iteration 22, loss = 0.01745395
Iteration 23, loss = 0.01695814
Iteration 24, loss = 0.01655357
Iteration 25, loss = 0.01605720
Iteration 26, loss = 0.01556463
Iteration 27, loss = 0.01520137
Iteration 28, loss = 0.01486156
Iteration 29, loss = 0.01445054
Iteration 30, loss = 0.01406084
Iteration 31, loss = 0.01369266
Iteration 32, loss = 0.01333906
Iteration 33, loss = 0.01310681
Iteration 34, loss = 0.01286235
Iteration 35, loss = 0.01249396
Iteration 36, loss = 0.01212979
Iteration 37, loss = 0.01187458
Iteration 38, loss = 0.01170928
Iteration 39, loss = 0.01146135
Iteration 40, loss = 0.01109560
Iteration 41, loss = 0.01101745
Iteration 42, loss = 0.01076141
Iteration 43, loss = 0.01040330
Iteration 44, loss = 0.01023677
Iteration 45, loss = 0.01000517
Iteration 46, loss = 0.00971521
Iteration 47, loss = 0.00957576
Iteration 48, loss = 0.00934927
Iteration 49, loss = 0.00913995
Iteration 50, loss = 0.00889182
Iteration 51, loss = 0.00880320
Iteration 52, loss = 0.00861175
Iteration 53, loss = 0.00841525
Iteration 54, loss = 0.00829047
Iteration 55, loss = 0.00804940
Iteration 56, loss = 0.00797518
Iteration 57, loss = 0.00765651
Iteration 58, loss = 0.00760273
Iteration 59, loss = 0.00749656
Iteration 60, loss = 0.00731322
Iteration 61, loss = 0.00713949
Iteration 62, loss = 0.00696781
Iteration 63, loss = 0.00689245
Iteration 64, loss = 0.00680637
Iteration 65, loss = 0.00660951
Iteration 66, loss = 0.00647691
Iteration 67, loss = 0.00635076
Iteration 68, loss = 0.00616038
Iteration 69, loss = 0.00611534
Iteration 70, loss = 0.00591041
Iteration 71, loss = 0.00587004
Iteration 72, loss = 0.00578345
Iteration 73, loss = 0.00561393
Iteration 74, loss = 0.00556687
Iteration 75, loss = 0.00542885
Iteration 76, loss = 0.00528456
Iteration 77, loss = 0.00525693
Iteration 78, loss = 0.00510666
Iteration 79, loss = 0.00508378
Iteration 80, loss = 0.00493405
Iteration 81, loss = 0.00486938
Iteration 82, loss = 0.00472402
Iteration 83, loss = 0.00468966
Iteration 84, loss = 0.00467985
Iteration 85, loss = 0.00448745
Iteration 86, loss = 0.00435244
Iteration 87, loss = 0.00441526
Iteration 88, loss = 0.00428391
Iteration 89, loss = 0.00421438
Iteration 90, loss = 0.00411675
Iteration 91, loss = 0.00404149
Iteration 92, loss = 0.00396118
Iteration 93, loss = 0.00384473
Iteration 94, loss = 0.00382062
Iteration 95, loss = 0.00378487
Iteration 96, loss = 0.00370668
Iteration 97, loss = 0.00361928
Iteration 98, loss = 0.00355597
Iteration 99, loss = 0.00346171
Iteration 100, loss = 0.00338153
Iteration 101, loss = 0.00334601
Iteration 102, loss = 0.00325304
Iteration 103, loss = 0.00321217
Iteration 104, loss = 0.00319327
Iteration 105, loss = 0.00309104
Iteration 106, loss = 0.00309211
Iteration 107, loss = 0.00303813
Iteration 108, loss = 0.00295984
Iteration 109, loss = 0.00288954
Iteration 110, loss = 0.00286517
Iteration 111, loss = 0.00272309
Iteration 112, loss = 0.00271490
Iteration 113, loss = 0.00268263
Iteration 114, loss = 0.00258757
Iteration 115, loss = 0.00257572
Iteration 116, loss = 0.00252126
Iteration 117, loss = 0.00251870
Iteration 118, loss = 0.00245706
Iteration 119, loss = 0.00237765
Iteration 120, loss = 0.00233356
Iteration 121, loss = 0.00232784
Iteration 122, loss = 0.00223117
Iteration 123, loss = 0.00222195
Iteration 124, loss = 0.00220136
Iteration 125, loss = 0.00219442
Iteration 126, loss = 0.00216458
Iteration 127, loss = 0.00209622
Iteration 128, loss = 0.00204797
Iteration 129, loss = 0.00198480
Iteration 130, loss = 0.00198864
Iteration 131, loss = 0.00200494
Iteration 132, loss = 0.00184026
Iteration 133, loss = 0.00189594
Iteration 134, loss = 0.00179733
Iteration 135, loss = 0.00186458
Iteration 136, loss = 0.00181939
Iteration 137, loss = 0.00171143
Iteration 138, loss = 0.00176698
Iteration 139, loss = 0.00168235
Iteration 140, loss = 0.00163356
Iteration 141, loss = 0.00160347
Iteration 142, loss = 0.00162828
Iteration 143, loss = 0.00162560
Iteration 144, loss = 0.00153418
Iteration 145, loss = 0.00151014
Iteration 146, loss = 0.00155764
Iteration 147, loss = 0.00149097
Iteration 148, loss = 0.00148702
Iteration 149, loss = 0.00141841
Iteration 150, loss = 0.00146042
Iteration 151, loss = 0.00142328
Iteration 152, loss = 0.00138032
Iteration 153, loss = 0.00137875
Iteration 154, loss = 0.00132474
Iteration 155, loss = 0.00129964
Iteration 156, loss = 0.00130086
Iteration 157, loss = 0.00131408
Iteration 158, loss = 0.00124415
Iteration 159, loss = 0.00124990
Iteration 160, loss = 0.00122016
Iteration 161, loss = 0.00121714
Iteration 162, loss = 0.00120189
Iteration 163, loss = 0.00117212
Iteration 164, loss = 0.00116011
Iteration 165, loss = 0.00114620
Iteration 166, loss = 0.00114610
Iteration 167, loss = 0.00108936
Iteration 168, loss = 0.00108700
Iteration 169, loss = 0.00107513
Iteration 170, loss = 0.00107377
Iteration 171, loss = 0.00106820
Iteration 172, loss = 0.00106371
Iteration 173, loss = 0.00100976
Iteration 174, loss = 0.00108173
Iteration 175, loss = 0.00099815
Iteration 176, loss = 0.00097039
Iteration 177, loss = 0.00101347
Iteration 178, loss = 0.00102202
Iteration 179, loss = 0.00094893
Iteration 180, loss = 0.00093097
Iteration 181, loss = 0.00093984
Iteration 182, loss = 0.00094265
Iteration 183, loss = 0.00092270
Iteration 184, loss = 0.00088823
Iteration 185, loss = 0.00091267
Iteration 186, loss = 0.00092368
Iteration 187, loss = 0.00089471
Iteration 188, loss = 0.00083930
Iteration 189, loss = 0.00085346
Iteration 190, loss = 0.00090070
Iteration 191, loss = 0.00083889
Iteration 192, loss = 0.00084198
Iteration 193, loss = 0.00080425
Iteration 194, loss = 0.00080161
Iteration 195, loss = 0.00079585
Iteration 196, loss = 0.00079881
Iteration 197, loss = 0.00079831
Iteration 198, loss = 0.00077854
Iteration 199, loss = 0.00079340
Iteration 200, loss = 0.00077263
Iteration 1, loss = 0.15001260
Iteration 2, loss = 0.06535634
Iteration 3, loss = 0.05576072
Iteration 4, loss = 0.04885806
Iteration 5, loss = 0.04311529
Iteration 6, loss = 0.03859733
Iteration 7, loss = 0.03496930
Iteration 8, loss = 0.03213837
Iteration 9, loss = 0.02966561
Iteration 10, loss = 0.02764152
Iteration 11, loss = 0.02598738
Iteration 12, loss = 0.02440701
Iteration 13, loss = 0.02312840
Iteration 14, loss = 0.02195880
Iteration 15, loss = 0.02098470
Iteration 16, loss = 0.01998928
Iteration 17, loss = 0.01924140
Iteration 18, loss = 0.01838490
Iteration 19, loss = 0.01772409
Iteration 20, loss = 0.01709740
Iteration 21, loss = 0.01633908
Iteration 22, loss = 0.01582958
Iteration 23, loss = 0.01527273
Iteration 24, loss = 0.01476536
Iteration 25, loss = 0.01430961
Iteration 26, loss = 0.01376505
Iteration 27, loss = 0.01339928
Iteration 28, loss = 0.01288418
Iteration 29, loss = 0.01252486
Iteration 30, loss = 0.01227624
Iteration 31, loss = 0.01185427
Iteration 32, loss = 0.01151454
Iteration 33, loss = 0.01108085
Iteration 34, loss = 0.01077678
Iteration 35, loss = 0.01042763
Iteration 36, loss = 0.01010788
Iteration 37, loss = 0.00984317
Iteration 38, loss = 0.00971329
Iteration 39, loss = 0.00933522
Iteration 40, loss = 0.00910584
Iteration 41, loss = 0.00878399
Iteration 42, loss = 0.00858859
Iteration 43, loss = 0.00837999
Iteration 44, loss = 0.00815815
Iteration 45, loss = 0.00790941
Iteration 46, loss = 0.00768928
Iteration 47, loss = 0.00761914
Iteration 48, loss = 0.00730148
Iteration 49, loss = 0.00721313
Iteration 50, loss = 0.00702401
Iteration 51, loss = 0.00670237
Iteration 52, loss = 0.00654374
Iteration 53, loss = 0.00654540
Iteration 54, loss = 0.00625154
Iteration 55, loss = 0.00613892
Iteration 56, loss = 0.00591853
Iteration 57, loss = 0.00575274
Iteration 58, loss = 0.00562941
Iteration 59, loss = 0.00544574
Iteration 60, loss = 0.00536590
Iteration 61, loss = 0.00512739
Iteration 62, loss = 0.00504968
Iteration 63, loss = 0.00492843
Iteration 64, loss = 0.00483755
Iteration 65, loss = 0.00463825
Iteration 66, loss = 0.00459727
Iteration 67, loss = 0.00443454
Iteration 68, loss = 0.00435620
Iteration 69, loss = 0.00416818
Iteration 70, loss = 0.00412651
Iteration 71, loss = 0.00405528
Iteration 72, loss = 0.00389921
Iteration 73, loss = 0.00381058
Iteration 74, loss = 0.00368890
Iteration 75, loss = 0.00362946
Iteration 76, loss = 0.00353596
Iteration 77, loss = 0.00351450
Iteration 78, loss = 0.00329472
Iteration 79, loss = 0.00327768
Iteration 80, loss = 0.00324901
Iteration 81, loss = 0.00303681
Iteration 82, loss = 0.00311182
Iteration 83, loss = 0.00292336
Iteration 84, loss = 0.00287666
Iteration 85, loss = 0.00289057
Iteration 86, loss = 0.00273976
Iteration 87, loss = 0.00265399
Iteration 88, loss = 0.00265776
Iteration 89, loss = 0.00250033
Iteration 90, loss = 0.00252628
Iteration 91, loss = 0.00241035
Iteration 92, loss = 0.00243572
Iteration 93, loss = 0.00237645
Iteration 94, loss = 0.00232135
Iteration 95, loss = 0.00220272
Iteration 96, loss = 0.00213069
Iteration 97, loss = 0.00214754
Iteration 98, loss = 0.00211136
Iteration 99, loss = 0.00203037
Iteration 100, loss = 0.00203296
Iteration 101, loss = 0.00191968
Iteration 102, loss = 0.00193613
Iteration 103, loss = 0.00186220
Iteration 104, loss = 0.00181601
Iteration 105, loss = 0.00180655
Iteration 106, loss = 0.00174991
Iteration 107, loss = 0.00167625
Iteration 108, loss = 0.00162293
Iteration 109, loss = 0.00166089
Iteration 110, loss = 0.00156226
Iteration 111, loss = 0.00156382
Iteration 112, loss = 0.00158546
Iteration 113, loss = 0.00150517
Iteration 114, loss = 0.00142610
Iteration 115, loss = 0.00139047
Iteration 116, loss = 0.00138952
Iteration 117, loss = 0.00134598
Iteration 118, loss = 0.00138264
Iteration 119, loss = 0.00131186
Iteration 120, loss = 0.00132205
Iteration 121, loss = 0.00128654
Iteration 122, loss = 0.00126374
Iteration 123, loss = 0.00123079
Iteration 124, loss = 0.00121485
Iteration 125, loss = 0.00117678
Iteration 126, loss = 0.00117699
Iteration 127, loss = 0.00113056
Iteration 128, loss = 0.00117848
Iteration 129, loss = 0.00108035
Iteration 130, loss = 0.00105004
Iteration 131, loss = 0.00102658
Iteration 132, loss = 0.00108154
Iteration 133, loss = 0.00103420
Iteration 134, loss = 0.00103017
Iteration 135, loss = 0.00097815
Iteration 136, loss = 0.00095990
Iteration 137, loss = 0.00102863
Iteration 138, loss = 0.00097366
Iteration 139, loss = 0.00096952
Iteration 140, loss = 0.00092161
Iteration 141, loss = 0.00090544
Iteration 142, loss = 0.00093457
Iteration 143, loss = 0.00085025
Iteration 144, loss = 0.00084217
Iteration 145, loss = 0.00086610
Iteration 146, loss = 0.00087387
Iteration 147, loss = 0.00084346
Iteration 148, loss = 0.00088413
Iteration 149, loss = 0.00078728
Iteration 150, loss = 0.00077755
Iteration 151, loss = 0.00076770
Iteration 152, loss = 0.00080219
Iteration 153, loss = 0.00091754
Iteration 154, loss = 0.00074357
Iteration 155, loss = 0.00072931
Iteration 156, loss = 0.00076840
Iteration 157, loss = 0.00074634
Iteration 158, loss = 0.00073292
Iteration 159, loss = 0.00071454
Iteration 160, loss = 0.00073803
Iteration 161, loss = 0.00070891
Iteration 162, loss = 0.00074635
Iteration 163, loss = 0.00071137
Iteration 164, loss = 0.00068225
Iteration 165, loss = 0.00067166
Iteration 166, loss = 0.00070883
Iteration 167, loss = 0.00071884
Iteration 168, loss = 0.00067441
Iteration 169, loss = 0.00063192
Iteration 170, loss = 0.00063412
Iteration 171, loss = 0.00065935
Iteration 172, loss = 0.00064718
Iteration 173, loss = 0.00069202
Iteration 174, loss = 0.00067777
Iteration 175, loss = 0.00079688
Iteration 176, loss = 0.00059048
Iteration 177, loss = 0.00057291
Iteration 178, loss = 0.00057526
Iteration 179, loss = 0.00058176
Iteration 180, loss = 0.00059713
Iteration 181, loss = 0.00061978
Iteration 182, loss = 0.00062830
Iteration 183, loss = 0.00062874
Iteration 184, loss = 0.00064151
Iteration 185, loss = 0.00063793
Iteration 186, loss = 0.00072762
Iteration 187, loss = 0.00055359
Iteration 188, loss = 0.00054249
Iteration 189, loss = 0.00055427
Iteration 190, loss = 0.00055194
Iteration 191, loss = 0.00069873
Iteration 192, loss = 0.00057547
Iteration 193, loss = 0.00056725
Iteration 194, loss = 0.00055578
Iteration 195, loss = 0.00053530
Iteration 196, loss = 0.00057609
Iteration 197, loss = 0.00068970
Iteration 198, loss = 0.00054844
Iteration 199, loss = 0.00053928
Iteration 200, loss = 0.00051427
Iteration 1, loss = 0.14066300
Iteration 2, loss = 0.06382894
Iteration 3, loss = 0.05375624
Iteration 4, loss = 0.04636249
Iteration 5, loss = 0.04090671
Iteration 6, loss = 0.03680659
Iteration 7, loss = 0.03359396
Iteration 8, loss = 0.03114583
Iteration 9, loss = 0.02888255
Iteration 10, loss = 0.02700037
Iteration 11, loss = 0.02552655
Iteration 12, loss = 0.02422879
Iteration 13, loss = 0.02293750
Iteration 14, loss = 0.02195146
Iteration 15, loss = 0.02096855
Iteration 16, loss = 0.02010391
Iteration 17, loss = 0.01936694
Iteration 18, loss = 0.01861144
Iteration 19, loss = 0.01793423
Iteration 20, loss = 0.01727101
Iteration 21, loss = 0.01666731
Iteration 22, loss = 0.01613361
Iteration 23, loss = 0.01566461
Iteration 24, loss = 0.01530678
Iteration 25, loss = 0.01467108
Iteration 26, loss = 0.01422752
Iteration 27, loss = 0.01382219
Iteration 28, loss = 0.01342421
Iteration 29, loss = 0.01297499
Iteration 30, loss = 0.01256502
Iteration 31, loss = 0.01233324
Iteration 32, loss = 0.01193702
Iteration 33, loss = 0.01158048
Iteration 34, loss = 0.01138977
Iteration 35, loss = 0.01098651
Iteration 36, loss = 0.01062751
Iteration 37, loss = 0.01035643
Iteration 38, loss = 0.01017262
Iteration 39, loss = 0.00989726
Iteration 40, loss = 0.00962019
Iteration 41, loss = 0.00941764
Iteration 42, loss = 0.00907158
Iteration 43, loss = 0.00893424
Iteration 44, loss = 0.00869344
Iteration 45, loss = 0.00845016
Iteration 46, loss = 0.00821386
Iteration 47, loss = 0.00800312
Iteration 48, loss = 0.00783522
Iteration 49, loss = 0.00763727
Iteration 50, loss = 0.00747607
Iteration 51, loss = 0.00728876
Iteration 52, loss = 0.00703249
Iteration 53, loss = 0.00692342
Iteration 54, loss = 0.00674388
Iteration 55, loss = 0.00664763
Iteration 56, loss = 0.00642211
Iteration 57, loss = 0.00622341
Iteration 58, loss = 0.00614602
Iteration 59, loss = 0.00593008
Iteration 60, loss = 0.00596273
Iteration 61, loss = 0.00577942
Iteration 62, loss = 0.00561110
Iteration 63, loss = 0.00549292
Iteration 64, loss = 0.00530251
Iteration 65, loss = 0.00522977
Iteration 66, loss = 0.00505021
Iteration 67, loss = 0.00501568
Iteration 68, loss = 0.00486840
Iteration 69, loss = 0.00472054
Iteration 70, loss = 0.00458829
Iteration 71, loss = 0.00456590
Iteration 72, loss = 0.00443775
Iteration 73, loss = 0.00434379
Iteration 74, loss = 0.00422632
Iteration 75, loss = 0.00415216
Iteration 76, loss = 0.00401852
Iteration 77, loss = 0.00396376
Iteration 78, loss = 0.00381820
Iteration 79, loss = 0.00371170
Iteration 80, loss = 0.00374105
Iteration 81, loss = 0.00363443
Iteration 82, loss = 0.00349497
Iteration 83, loss = 0.00347954
Iteration 84, loss = 0.00336521
Iteration 85, loss = 0.00329655
Iteration 86, loss = 0.00313077
Iteration 87, loss = 0.00326106
Iteration 88, loss = 0.00311838
Iteration 89, loss = 0.00293855
Iteration 90, loss = 0.00294619
Iteration 91, loss = 0.00302661
Iteration 92, loss = 0.00282490
Iteration 93, loss = 0.00278087
Iteration 94, loss = 0.00269067
Iteration 95, loss = 0.00264942
Iteration 96, loss = 0.00259238
Iteration 97, loss = 0.00253683
Iteration 98, loss = 0.00240619
Iteration 99, loss = 0.00243289
Iteration 100, loss = 0.00239444
Iteration 101, loss = 0.00231336
Iteration 102, loss = 0.00227118
Iteration 103, loss = 0.00214504
Iteration 104, loss = 0.00219218
Iteration 105, loss = 0.00209058
Iteration 106, loss = 0.00215044
Iteration 107, loss = 0.00196609
Iteration 108, loss = 0.00196321
Iteration 109, loss = 0.00190167
Iteration 110, loss = 0.00187391
Iteration 111, loss = 0.00187764
Iteration 112, loss = 0.00177910
Iteration 113, loss = 0.00174693
Iteration 114, loss = 0.00173754
Iteration 115, loss = 0.00165556
Iteration 116, loss = 0.00166950
Iteration 117, loss = 0.00164552
Iteration 118, loss = 0.00160113
Iteration 119, loss = 0.00154073
Iteration 120, loss = 0.00149813
Iteration 121, loss = 0.00145550
Iteration 122, loss = 0.00143673
Iteration 123, loss = 0.00144272
Iteration 124, loss = 0.00141580
Iteration 125, loss = 0.00148422
Iteration 126, loss = 0.00140059
Iteration 127, loss = 0.00133109
Iteration 128, loss = 0.00127330
Iteration 129, loss = 0.00127027
Iteration 130, loss = 0.00122901
Iteration 131, loss = 0.00123848
Iteration 132, loss = 0.00116890
Iteration 133, loss = 0.00118512
Iteration 134, loss = 0.00119070
Iteration 135, loss = 0.00118592
Iteration 136, loss = 0.00113765
Iteration 137, loss = 0.00109526
Iteration 138, loss = 0.00111060
Iteration 139, loss = 0.00106994
Iteration 140, loss = 0.00110504
Iteration 141, loss = 0.00102705
Iteration 142, loss = 0.00101718
Iteration 143, loss = 0.00099742
Iteration 144, loss = 0.00102716
Iteration 145, loss = 0.00095141
Iteration 146, loss = 0.00100311
Iteration 147, loss = 0.00091684
Iteration 148, loss = 0.00095180
Iteration 149, loss = 0.00090893
Iteration 150, loss = 0.00092482
Iteration 151, loss = 0.00092550
Iteration 152, loss = 0.00091598
Iteration 153, loss = 0.00085993
Iteration 154, loss = 0.00087609
Iteration 155, loss = 0.00085737
Iteration 156, loss = 0.00085424
Iteration 157, loss = 0.00080379
Iteration 158, loss = 0.00078867
Iteration 159, loss = 0.00081164
Iteration 160, loss = 0.00087540
Iteration 161, loss = 0.00075082
Iteration 162, loss = 0.00075728
Iteration 163, loss = 0.00074341
Iteration 164, loss = 0.00080856
Iteration 165, loss = 0.00073198
Iteration 166, loss = 0.00074250
Iteration 167, loss = 0.00076550
Iteration 168, loss = 0.00076131
Iteration 169, loss = 0.00068649
Iteration 170, loss = 0.00070988
Iteration 171, loss = 0.00072743
Iteration 172, loss = 0.00069856
Iteration 173, loss = 0.00066185
Iteration 174, loss = 0.00077815
Iteration 175, loss = 0.00067997
Iteration 176, loss = 0.00063706
Iteration 177, loss = 0.00066345
Iteration 178, loss = 0.00066374
Iteration 179, loss = 0.00073966
Iteration 180, loss = 0.00067145
Iteration 181, loss = 0.00064858
Iteration 182, loss = 0.00060987
Iteration 183, loss = 0.00061779
Iteration 184, loss = 0.00064666
Iteration 185, loss = 0.00062817
Iteration 186, loss = 0.00063667
Iteration 187, loss = 0.00062932
Iteration 188, loss = 0.00064346
Iteration 189, loss = 0.00068750
Iteration 190, loss = 0.00061263
Iteration 191, loss = 0.00057591
Iteration 192, loss = 0.00057339
Iteration 193, loss = 0.00057437
Iteration 194, loss = 0.00065948
Iteration 195, loss = 0.00069594
Iteration 196, loss = 0.00056387
Iteration 197, loss = 0.00054984
Iteration 198, loss = 0.00055614
Iteration 199, loss = 0.00057058
Iteration 200, loss = 0.00058238
Iteration 1, loss = 0.14826621
Iteration 2, loss = 0.06599664
Iteration 3, loss = 0.05495449
Iteration 4, loss = 0.04694223
Iteration 5, loss = 0.04098227
Iteration 6, loss = 0.03649685
Iteration 7, loss = 0.03338551
Iteration 8, loss = 0.03081320
Iteration 9, loss = 0.02875264
Iteration 10, loss = 0.02691692
Iteration 11, loss = 0.02547579
Iteration 12, loss = 0.02411113
Iteration 13, loss = 0.02300072
Iteration 14, loss = 0.02188348
Iteration 15, loss = 0.02100819
Iteration 16, loss = 0.02007506
Iteration 17, loss = 0.01932935
Iteration 18, loss = 0.01859269
Iteration 19, loss = 0.01778093
Iteration 20, loss = 0.01728180
Iteration 21, loss = 0.01657828
Iteration 22, loss = 0.01607736
Iteration 23, loss = 0.01554014
Iteration 24, loss = 0.01490764
Iteration 25, loss = 0.01462529
Iteration 26, loss = 0.01426053
Iteration 27, loss = 0.01367589
Iteration 28, loss = 0.01340396
Iteration 29, loss = 0.01277141
Iteration 30, loss = 0.01245204
Iteration 31, loss = 0.01211429
Iteration 32, loss = 0.01183920
Iteration 33, loss = 0.01148206
Iteration 34, loss = 0.01123260
Iteration 35, loss = 0.01082578
Iteration 36, loss = 0.01057454
Iteration 37, loss = 0.01036949
Iteration 38, loss = 0.01006824
Iteration 39, loss = 0.00979405
Iteration 40, loss = 0.00956188
Iteration 41, loss = 0.00930858
Iteration 42, loss = 0.00891801
Iteration 43, loss = 0.00877100
Iteration 44, loss = 0.00854628
Iteration 45, loss = 0.00825567
Iteration 46, loss = 0.00806106
Iteration 47, loss = 0.00784692
Iteration 48, loss = 0.00771509
Iteration 49, loss = 0.00745398
Iteration 50, loss = 0.00727358
Iteration 51, loss = 0.00713170
Iteration 52, loss = 0.00704709
Iteration 53, loss = 0.00675546
Iteration 54, loss = 0.00666302
Iteration 55, loss = 0.00642598
Iteration 56, loss = 0.00630810
Iteration 57, loss = 0.00611197
Iteration 58, loss = 0.00597903
Iteration 59, loss = 0.00582915
Iteration 60, loss = 0.00572424
Iteration 61, loss = 0.00550630
Iteration 62, loss = 0.00539766
Iteration 63, loss = 0.00528984
Iteration 64, loss = 0.00510475
Iteration 65, loss = 0.00499007
Iteration 66, loss = 0.00495281
Iteration 67, loss = 0.00473093
Iteration 68, loss = 0.00460400
Iteration 69, loss = 0.00458110
Iteration 70, loss = 0.00430898
Iteration 71, loss = 0.00431948
Iteration 72, loss = 0.00421944
Iteration 73, loss = 0.00414123
Iteration 74, loss = 0.00398574
Iteration 75, loss = 0.00385133
Iteration 76, loss = 0.00380065
Iteration 77, loss = 0.00370446
Iteration 78, loss = 0.00363391
Iteration 79, loss = 0.00354141
Iteration 80, loss = 0.00348620
Iteration 81, loss = 0.00332506
Iteration 82, loss = 0.00324758
Iteration 83, loss = 0.00316359
Iteration 84, loss = 0.00319761
Iteration 85, loss = 0.00305709
Iteration 86, loss = 0.00292721
Iteration 87, loss = 0.00290837
Iteration 88, loss = 0.00286005
Iteration 89, loss = 0.00280619
Iteration 90, loss = 0.00267851
Iteration 91, loss = 0.00267814
Iteration 92, loss = 0.00260151
Iteration 93, loss = 0.00251382
Iteration 94, loss = 0.00247677
Iteration 95, loss = 0.00236023
Iteration 96, loss = 0.00232058
Iteration 97, loss = 0.00228604
Iteration 98, loss = 0.00227375
Iteration 99, loss = 0.00220992
Iteration 100, loss = 0.00214932
Iteration 101, loss = 0.00210060
Iteration 102, loss = 0.00204783
Iteration 103, loss = 0.00193532
Iteration 104, loss = 0.00200248
Iteration 105, loss = 0.00186649
Iteration 106, loss = 0.00183165
Iteration 107, loss = 0.00186208
Iteration 108, loss = 0.00175769
Iteration 109, loss = 0.00180132
Iteration 110, loss = 0.00168479
Iteration 111, loss = 0.00164971
Iteration 112, loss = 0.00155363
Iteration 113, loss = 0.00163385
Iteration 114, loss = 0.00158648
Iteration 115, loss = 0.00153789
Iteration 116, loss = 0.00146425
Iteration 117, loss = 0.00146108
Iteration 118, loss = 0.00151626
Iteration 119, loss = 0.00138304
Iteration 120, loss = 0.00136614
Iteration 121, loss = 0.00130523
Iteration 122, loss = 0.00130635
Iteration 123, loss = 0.00130583
Iteration 124, loss = 0.00123502
Iteration 125, loss = 0.00129907
Iteration 126, loss = 0.00122761
Iteration 127, loss = 0.00114191
Iteration 128, loss = 0.00114280
Iteration 129, loss = 0.00116689
Iteration 130, loss = 0.00112621
Iteration 131, loss = 0.00115181
Iteration 132, loss = 0.00106340
Iteration 133, loss = 0.00103021
Iteration 134, loss = 0.00108774
Iteration 135, loss = 0.00102722
Iteration 136, loss = 0.00099756
Iteration 137, loss = 0.00104499
Iteration 138, loss = 0.00098406
Iteration 139, loss = 0.00095698
Iteration 140, loss = 0.00096537
Iteration 141, loss = 0.00095219
Iteration 142, loss = 0.00092754
Iteration 143, loss = 0.00090685
Iteration 144, loss = 0.00085148
Iteration 145, loss = 0.00088441
Iteration 146, loss = 0.00100344
Iteration 147, loss = 0.00084882
Iteration 148, loss = 0.00086921
Iteration 149, loss = 0.00082748
Iteration 150, loss = 0.00080545
Iteration 151, loss = 0.00082369
Iteration 152, loss = 0.00086368
Iteration 153, loss = 0.00080868
Iteration 154, loss = 0.00080910
Iteration 155, loss = 0.00076560
Iteration 156, loss = 0.00076635
Iteration 157, loss = 0.00074077
Iteration 158, loss = 0.00074204
Iteration 159, loss = 0.00073507
Iteration 160, loss = 0.00073346
Iteration 161, loss = 0.00077300
Iteration 162, loss = 0.00071107
Iteration 163, loss = 0.00072376
Iteration 164, loss = 0.00067612
Iteration 165, loss = 0.00068658
Iteration 166, loss = 0.00081926
Iteration 167, loss = 0.00073663
Iteration 168, loss = 0.00062399
Iteration 169, loss = 0.00062193
Iteration 170, loss = 0.00064164
Iteration 171, loss = 0.00064901
Iteration 172, loss = 0.00070653
Iteration 173, loss = 0.00070324
Iteration 174, loss = 0.00062292
Iteration 175, loss = 0.00063694
Iteration 176, loss = 0.00062206
Iteration 177, loss = 0.00059946
Iteration 178, loss = 0.00067282
Iteration 179, loss = 0.00077888
Iteration 180, loss = 0.00057736
Iteration 181, loss = 0.00058200
Iteration 182, loss = 0.00057226
Iteration 183, loss = 0.00059803
Iteration 184, loss = 0.00070581
Iteration 185, loss = 0.00058358
Iteration 186, loss = 0.00059274
Iteration 187, loss = 0.00056865
Iteration 188, loss = 0.00057336
Iteration 189, loss = 0.00059713
Iteration 190, loss = 0.00058223
Iteration 191, loss = 0.00059145
Iteration 192, loss = 0.00057013
Iteration 193, loss = 0.00059988
Iteration 194, loss = 0.00060258
Iteration 195, loss = 0.00056527
Iteration 196, loss = 0.00054484
Iteration 197, loss = 0.00055491
Iteration 198, loss = 0.00057995
Iteration 199, loss = 0.00066577
Iteration 200, loss = 0.00052605
Iteration 1, loss = 0.14214325
Iteration 2, loss = 0.06330180
Iteration 3, loss = 0.05237840
Iteration 4, loss = 0.04476111
Iteration 5, loss = 0.03921061
Iteration 6, loss = 0.03482216
Iteration 7, loss = 0.03138854
Iteration 8, loss = 0.02870584
Iteration 9, loss = 0.02656318
Iteration 10, loss = 0.02494752
Iteration 11, loss = 0.02335873
Iteration 12, loss = 0.02219690
Iteration 13, loss = 0.02098982
Iteration 14, loss = 0.02001744
Iteration 15, loss = 0.01903913
Iteration 16, loss = 0.01835244
Iteration 17, loss = 0.01745420
Iteration 18, loss = 0.01679345
Iteration 19, loss = 0.01611658
Iteration 20, loss = 0.01551986
Iteration 21, loss = 0.01480085
Iteration 22, loss = 0.01436924
Iteration 23, loss = 0.01382891
Iteration 24, loss = 0.01334471
Iteration 25, loss = 0.01282473
Iteration 26, loss = 0.01241222
Iteration 27, loss = 0.01200414
Iteration 28, loss = 0.01160321
Iteration 29, loss = 0.01122824
Iteration 30, loss = 0.01086616
Iteration 31, loss = 0.01044917
Iteration 32, loss = 0.01013449
Iteration 33, loss = 0.00975658
Iteration 34, loss = 0.00956416
Iteration 35, loss = 0.00920025
Iteration 36, loss = 0.00890145
Iteration 37, loss = 0.00864626
Iteration 38, loss = 0.00845126
Iteration 39, loss = 0.00815537
Iteration 40, loss = 0.00793054
Iteration 41, loss = 0.00765086
Iteration 42, loss = 0.00746024
Iteration 43, loss = 0.00728653
Iteration 44, loss = 0.00710961
Iteration 45, loss = 0.00682563
Iteration 46, loss = 0.00665441
Iteration 47, loss = 0.00643264
Iteration 48, loss = 0.00629500
Iteration 49, loss = 0.00606423
Iteration 50, loss = 0.00594077
Iteration 51, loss = 0.00570067
Iteration 52, loss = 0.00562434
Iteration 53, loss = 0.00543500
Iteration 54, loss = 0.00524649
Iteration 55, loss = 0.00510881
Iteration 56, loss = 0.00497436
Iteration 57, loss = 0.00477751
Iteration 58, loss = 0.00470667
Iteration 59, loss = 0.00464376
Iteration 60, loss = 0.00433341
Iteration 61, loss = 0.00435268
Iteration 62, loss = 0.00415696
Iteration 63, loss = 0.00401735
Iteration 64, loss = 0.00396546
Iteration 65, loss = 0.00384801
Iteration 66, loss = 0.00370755
Iteration 67, loss = 0.00350009
Iteration 68, loss = 0.00350047
Iteration 69, loss = 0.00353917
Iteration 70, loss = 0.00333960
Iteration 71, loss = 0.00330612
Iteration 72, loss = 0.00316302
Iteration 73, loss = 0.00305247
Iteration 74, loss = 0.00293479
Iteration 75, loss = 0.00299553
Iteration 76, loss = 0.00280702
Iteration 77, loss = 0.00277010
Iteration 78, loss = 0.00264940
Iteration 79, loss = 0.00261796
Iteration 80, loss = 0.00251433
Iteration 81, loss = 0.00242635
Iteration 82, loss = 0.00243219
Iteration 83, loss = 0.00231702
Iteration 84, loss = 0.00220876
Iteration 85, loss = 0.00221930
Iteration 86, loss = 0.00217901
Iteration 87, loss = 0.00213035
Iteration 88, loss = 0.00197762
Iteration 89, loss = 0.00196614
Iteration 90, loss = 0.00191479
Iteration 91, loss = 0.00191014
Iteration 92, loss = 0.00185365
Iteration 93, loss = 0.00176405
Iteration 94, loss = 0.00174520
Iteration 95, loss = 0.00166993
Iteration 96, loss = 0.00167283
Iteration 97, loss = 0.00156178
Iteration 98, loss = 0.00153048
Iteration 99, loss = 0.00150744
Iteration 100, loss = 0.00147255
Iteration 101, loss = 0.00150376
Iteration 102, loss = 0.00140903
Iteration 103, loss = 0.00140575
Iteration 104, loss = 0.00133793
Iteration 105, loss = 0.00135952
Iteration 106, loss = 0.00137418
Iteration 107, loss = 0.00128185
Iteration 108, loss = 0.00123335
Iteration 109, loss = 0.00130081
Iteration 110, loss = 0.00112367
Iteration 111, loss = 0.00116566
Iteration 112, loss = 0.00118597
Iteration 113, loss = 0.00111845
Iteration 114, loss = 0.00107718
Iteration 115, loss = 0.00110048
Iteration 116, loss = 0.00099452
Iteration 117, loss = 0.00100313
Iteration 118, loss = 0.00100010
Iteration 119, loss = 0.00108999
Iteration 120, loss = 0.00092933
Iteration 121, loss = 0.00094410
Iteration 122, loss = 0.00092915
Iteration 123, loss = 0.00097302
Iteration 124, loss = 0.00087900
Iteration 125, loss = 0.00086150
Iteration 126, loss = 0.00084176
Iteration 127, loss = 0.00088468
Iteration 128, loss = 0.00091887
Iteration 129, loss = 0.00083914
Iteration 130, loss = 0.00086839
Iteration 131, loss = 0.00080336
Iteration 132, loss = 0.00081795
Iteration 133, loss = 0.00075341
Iteration 134, loss = 0.00075768
Iteration 135, loss = 0.00076757
Iteration 136, loss = 0.00073654
Iteration 137, loss = 0.00077782
Iteration 138, loss = 0.00074657
Iteration 139, loss = 0.00074284
Iteration 140, loss = 0.00069465
Iteration 141, loss = 0.00070094
Iteration 142, loss = 0.00071366
Iteration 143, loss = 0.00079673
Iteration 144, loss = 0.00076760
Iteration 145, loss = 0.00066646
Iteration 146, loss = 0.00060243
Iteration 147, loss = 0.00062947
Iteration 148, loss = 0.00066798
Iteration 149, loss = 0.00066649
Iteration 150, loss = 0.00062376
Iteration 151, loss = 0.00062206
Iteration 152, loss = 0.00066782
Iteration 153, loss = 0.00061298
Iteration 154, loss = 0.00057948
Iteration 155, loss = 0.00070628
Iteration 156, loss = 0.00074306
Iteration 157, loss = 0.00057282
Iteration 158, loss = 0.00054874
Iteration 159, loss = 0.00054334
Iteration 160, loss = 0.00056402
Iteration 161, loss = 0.00068119
Iteration 162, loss = 0.00067214
Iteration 163, loss = 0.00069218
Iteration 164, loss = 0.00053125
Iteration 165, loss = 0.00052610
Iteration 166, loss = 0.00053532
Iteration 167, loss = 0.00053874
Iteration 168, loss = 0.00062590
Iteration 169, loss = 0.00054447
Iteration 170, loss = 0.00054600
Iteration 171, loss = 0.00051728
Iteration 172, loss = 0.00056667
Iteration 173, loss = 0.00067402
Iteration 174, loss = 0.00062200
Iteration 175, loss = 0.00051561
Iteration 176, loss = 0.00052183
Iteration 177, loss = 0.00061467
Iteration 178, loss = 0.00050767
Iteration 179, loss = 0.00049444
Iteration 180, loss = 0.00049308
Iteration 181, loss = 0.00053310
Iteration 182, loss = 0.00082098
Iteration 183, loss = 0.00073714
Iteration 184, loss = 0.00049067
Iteration 185, loss = 0.00047910
Iteration 186, loss = 0.00047524
Iteration 187, loss = 0.00047811
Iteration 188, loss = 0.00047694
Iteration 189, loss = 0.00048070
Iteration 190, loss = 0.00073745
Iteration 191, loss = 0.00050778
Iteration 192, loss = 0.00053811
Iteration 193, loss = 0.00048117
Iteration 194, loss = 0.00047111
Iteration 195, loss = 0.00047412
Iteration 196, loss = 0.00048360
Iteration 197, loss = 0.00079309
Iteration 198, loss = 0.00060718
Iteration 199, loss = 0.00048143
Iteration 200, loss = 0.00047141
Iteration 1, loss = 0.12699190
Iteration 2, loss = 0.06144398
Iteration 3, loss = 0.05104962
Iteration 4, loss = 0.04327099
Iteration 5, loss = 0.03784450
Iteration 6, loss = 0.03393011
Iteration 7, loss = 0.03099359
Iteration 8, loss = 0.02834999
Iteration 9, loss = 0.02634559
Iteration 10, loss = 0.02457188
Iteration 11, loss = 0.02319405
Iteration 12, loss = 0.02191029
Iteration 13, loss = 0.02073156
Iteration 14, loss = 0.01978869
Iteration 15, loss = 0.01886779
Iteration 16, loss = 0.01790703
Iteration 17, loss = 0.01725389
Iteration 18, loss = 0.01659178
Iteration 19, loss = 0.01586379
Iteration 20, loss = 0.01527871
Iteration 21, loss = 0.01471533
Iteration 22, loss = 0.01427761
Iteration 23, loss = 0.01364468
Iteration 24, loss = 0.01321036
Iteration 25, loss = 0.01269921
Iteration 26, loss = 0.01228283
Iteration 27, loss = 0.01189851
Iteration 28, loss = 0.01139420
Iteration 29, loss = 0.01104540
Iteration 30, loss = 0.01059633
Iteration 31, loss = 0.01033577
Iteration 32, loss = 0.00995291
Iteration 33, loss = 0.00964250
Iteration 34, loss = 0.00937046
Iteration 35, loss = 0.00905253
Iteration 36, loss = 0.00872948
Iteration 37, loss = 0.00846851
Iteration 38, loss = 0.00816156
Iteration 39, loss = 0.00797831
Iteration 40, loss = 0.00758899
Iteration 41, loss = 0.00737979
Iteration 42, loss = 0.00713255
Iteration 43, loss = 0.00704163
Iteration 44, loss = 0.00668872
Iteration 45, loss = 0.00645432
Iteration 46, loss = 0.00625598
Iteration 47, loss = 0.00615910
Iteration 48, loss = 0.00593973
Iteration 49, loss = 0.00575073
Iteration 50, loss = 0.00553603
Iteration 51, loss = 0.00532316
Iteration 52, loss = 0.00522434
Iteration 53, loss = 0.00512444
Iteration 54, loss = 0.00484447
Iteration 55, loss = 0.00468529
Iteration 56, loss = 0.00458876
Iteration 57, loss = 0.00443827
Iteration 58, loss = 0.00432840
Iteration 59, loss = 0.00412333
Iteration 60, loss = 0.00394854
Iteration 61, loss = 0.00391553
Iteration 62, loss = 0.00383542
Iteration 63, loss = 0.00370567
Iteration 64, loss = 0.00356174
Iteration 65, loss = 0.00343634
Iteration 66, loss = 0.00336405
Iteration 67, loss = 0.00327907
Iteration 68, loss = 0.00316325
Iteration 69, loss = 0.00304551
Iteration 70, loss = 0.00294376
Iteration 71, loss = 0.00283877
Iteration 72, loss = 0.00276749
Iteration 73, loss = 0.00275552
Iteration 74, loss = 0.00261414
Iteration 75, loss = 0.00244156
Iteration 76, loss = 0.00245472
Iteration 77, loss = 0.00237165
Iteration 78, loss = 0.00225688
Iteration 79, loss = 0.00228253
Iteration 80, loss = 0.00215863
Iteration 81, loss = 0.00208587
Iteration 82, loss = 0.00205083
Iteration 83, loss = 0.00200032
Iteration 84, loss = 0.00190637
Iteration 85, loss = 0.00188910
Iteration 86, loss = 0.00178850
Iteration 87, loss = 0.00179731
Iteration 88, loss = 0.00171775
Iteration 89, loss = 0.00162518
Iteration 90, loss = 0.00163017
Iteration 91, loss = 0.00157118
Iteration 92, loss = 0.00150611
Iteration 93, loss = 0.00155653
Iteration 94, loss = 0.00139219
Iteration 95, loss = 0.00140384
Iteration 96, loss = 0.00136728
Iteration 97, loss = 0.00137372
Iteration 98, loss = 0.00124978
Iteration 99, loss = 0.00122506
Iteration 100, loss = 0.00127577
Iteration 101, loss = 0.00128105
Iteration 102, loss = 0.00113881
Iteration 103, loss = 0.00116392
Iteration 104, loss = 0.00110861
Iteration 105, loss = 0.00107968
Iteration 106, loss = 0.00107565
Iteration 107, loss = 0.00107782
Iteration 108, loss = 0.00102049
Iteration 109, loss = 0.00097758
Iteration 110, loss = 0.00096711
Iteration 111, loss = 0.00097316
Iteration 112, loss = 0.00092748
Iteration 113, loss = 0.00091985
Iteration 114, loss = 0.00091643
Iteration 115, loss = 0.00087887
Iteration 116, loss = 0.00085555
Iteration 117, loss = 0.00093362
Iteration 118, loss = 0.00086749
Iteration 119, loss = 0.00080177
Iteration 120, loss = 0.00081333
Iteration 121, loss = 0.00078046
Iteration 122, loss = 0.00076746
Iteration 123, loss = 0.00077737
Iteration 124, loss = 0.00075493
Iteration 125, loss = 0.00075939
Iteration 126, loss = 0.00073696
Iteration 127, loss = 0.00076522
Iteration 128, loss = 0.00071235
Iteration 129, loss = 0.00071553
Iteration 130, loss = 0.00067298
Iteration 131, loss = 0.00070548
Iteration 132, loss = 0.00068993
Iteration 133, loss = 0.00064791
Iteration 134, loss = 0.00062710
Iteration 135, loss = 0.00068834
Iteration 136, loss = 0.00071645
Iteration 137, loss = 0.00067651
Iteration 138, loss = 0.00059524
Iteration 139, loss = 0.00059811
Iteration 140, loss = 0.00058470
Iteration 141, loss = 0.00058456
Iteration 142, loss = 0.00067161
Iteration 143, loss = 0.00072079
Iteration 144, loss = 0.00056161
Iteration 145, loss = 0.00054972
Iteration 146, loss = 0.00064711
Iteration 147, loss = 0.00070277
Iteration 148, loss = 0.00065270
Iteration 149, loss = 0.00052339
Iteration 150, loss = 0.00051497
Iteration 151, loss = 0.00052779
Iteration 152, loss = 0.00054035
Iteration 153, loss = 0.00054825
Iteration 154, loss = 0.00080441
Iteration 155, loss = 0.00056439
Iteration 156, loss = 0.00050420
Iteration 157, loss = 0.00050614
Iteration 158, loss = 0.00050376
Iteration 159, loss = 0.00050970
Iteration 160, loss = 0.00053474
Iteration 161, loss = 0.00073567
Iteration 162, loss = 0.00056989
Iteration 163, loss = 0.00049369
Iteration 164, loss = 0.00048992
Iteration 165, loss = 0.00049946
Iteration 166, loss = 0.00059677
Iteration 167, loss = 0.00058803
Iteration 168, loss = 0.00048830
Iteration 169, loss = 0.00048948
Iteration 170, loss = 0.00059257
Iteration 171, loss = 0.00049123
Iteration 172, loss = 0.00048131
Iteration 173, loss = 0.00048298
Iteration 174, loss = 0.00050184
Iteration 175, loss = 0.00067540
Iteration 176, loss = 0.00048287
Iteration 177, loss = 0.00046615
Iteration 178, loss = 0.00046555
Iteration 179, loss = 0.00048592
Iteration 180, loss = 0.00047738
Iteration 181, loss = 0.00048522
Iteration 182, loss = 0.00079951
Iteration 183, loss = 0.00048747
Iteration 184, loss = 0.00045740
Iteration 185, loss = 0.00045325
Iteration 186, loss = 0.00045348
Iteration 187, loss = 0.00045471
Iteration 188, loss = 0.00045971
Iteration 189, loss = 0.00046519
Iteration 190, loss = 0.00107809
Iteration 191, loss = 0.00052051
Iteration 192, loss = 0.00046018
Iteration 193, loss = 0.00044912
Iteration 194, loss = 0.00044586
Iteration 195, loss = 0.00044454
Iteration 196, loss = 0.00044206
Iteration 197, loss = 0.00044337
Iteration 198, loss = 0.00045463
Iteration 199, loss = 0.00077615
Iteration 200, loss = 0.00046877
Iteration 1, loss = 0.14407903
Iteration 2, loss = 0.06350574
Iteration 3, loss = 0.05296400
Iteration 4, loss = 0.04496389
Iteration 5, loss = 0.03924790
Iteration 6, loss = 0.03516700
Iteration 7, loss = 0.03204214
Iteration 8, loss = 0.02953467
Iteration 9, loss = 0.02750260
Iteration 10, loss = 0.02572756
Iteration 11, loss = 0.02412548
Iteration 12, loss = 0.02276069
Iteration 13, loss = 0.02161556
Iteration 14, loss = 0.02057944
Iteration 15, loss = 0.01960991
Iteration 16, loss = 0.01869950
Iteration 17, loss = 0.01790830
Iteration 18, loss = 0.01699622
Iteration 19, loss = 0.01642643
Iteration 20, loss = 0.01588995
Iteration 21, loss = 0.01508964
Iteration 22, loss = 0.01455822
Iteration 23, loss = 0.01402399
Iteration 24, loss = 0.01359630
Iteration 25, loss = 0.01292190
Iteration 26, loss = 0.01252199
Iteration 27, loss = 0.01216146
Iteration 28, loss = 0.01162302
Iteration 29, loss = 0.01134170
Iteration 30, loss = 0.01081848
Iteration 31, loss = 0.01070026
Iteration 32, loss = 0.01017220
Iteration 33, loss = 0.00991526
Iteration 34, loss = 0.00961749
Iteration 35, loss = 0.00926932
Iteration 36, loss = 0.00889592
Iteration 37, loss = 0.00871677
Iteration 38, loss = 0.00846589
Iteration 39, loss = 0.00832418
Iteration 40, loss = 0.00795122
Iteration 41, loss = 0.00777514
Iteration 42, loss = 0.00756592
Iteration 43, loss = 0.00721963
Iteration 44, loss = 0.00702703
Iteration 45, loss = 0.00703712
Iteration 46, loss = 0.00680735
Iteration 47, loss = 0.00649589
Iteration 48, loss = 0.00623108
Iteration 49, loss = 0.00610681
Iteration 50, loss = 0.00589646
Iteration 51, loss = 0.00564010
Iteration 52, loss = 0.00561088
Iteration 53, loss = 0.00537597
Iteration 54, loss = 0.00522374
Iteration 55, loss = 0.00519193
Iteration 56, loss = 0.00492983
Iteration 57, loss = 0.00476982
Iteration 58, loss = 0.00467752
Iteration 59, loss = 0.00443642
Iteration 60, loss = 0.00441584
Iteration 61, loss = 0.00432106
Iteration 62, loss = 0.00407919
Iteration 63, loss = 0.00397638
Iteration 64, loss = 0.00381467
Iteration 65, loss = 0.00378399
Iteration 66, loss = 0.00354637
Iteration 67, loss = 0.00362148
Iteration 68, loss = 0.00332751
Iteration 69, loss = 0.00342112
Iteration 70, loss = 0.00321556
Iteration 71, loss = 0.00312632
Iteration 72, loss = 0.00303647
Iteration 73, loss = 0.00288034
Iteration 74, loss = 0.00291292
Iteration 75, loss = 0.00273917
Iteration 76, loss = 0.00273088
Iteration 77, loss = 0.00261699
Iteration 78, loss = 0.00250160
Iteration 79, loss = 0.00239971
Iteration 80, loss = 0.00236625
Iteration 81, loss = 0.00234098
Iteration 82, loss = 0.00219216
Iteration 83, loss = 0.00214927
Iteration 84, loss = 0.00206628
Iteration 85, loss = 0.00207328
Iteration 86, loss = 0.00206852
Iteration 87, loss = 0.00195079
Iteration 88, loss = 0.00184575
Iteration 89, loss = 0.00179920
Iteration 90, loss = 0.00172936
Iteration 91, loss = 0.00174047
Iteration 92, loss = 0.00164608
Iteration 93, loss = 0.00168551
Iteration 94, loss = 0.00165330
Iteration 95, loss = 0.00149547
Iteration 96, loss = 0.00149548
Iteration 97, loss = 0.00144194
Iteration 98, loss = 0.00139294
Iteration 99, loss = 0.00136118
Iteration 100, loss = 0.00136822
Iteration 101, loss = 0.00131201
Iteration 102, loss = 0.00123925
Iteration 103, loss = 0.00128622
Iteration 104, loss = 0.00117290
Iteration 105, loss = 0.00129032
Iteration 106, loss = 0.00115607
Iteration 107, loss = 0.00110839
Iteration 108, loss = 0.00106551
Iteration 109, loss = 0.00104126
Iteration 110, loss = 0.00104117
Iteration 111, loss = 0.00101440
Iteration 112, loss = 0.00106376
Iteration 113, loss = 0.00103348
Iteration 114, loss = 0.00095370
Iteration 115, loss = 0.00094900
Iteration 116, loss = 0.00093963
Iteration 117, loss = 0.00089909
Iteration 118, loss = 0.00087763
Iteration 119, loss = 0.00091946
Iteration 120, loss = 0.00090325
Iteration 121, loss = 0.00082902
Iteration 122, loss = 0.00088466
Iteration 123, loss = 0.00083200
Iteration 124, loss = 0.00078647
Iteration 125, loss = 0.00076075
Iteration 126, loss = 0.00080279
Iteration 127, loss = 0.00076189
Iteration 128, loss = 0.00075093
Iteration 129, loss = 0.00076706
Iteration 130, loss = 0.00077302
Iteration 131, loss = 0.00068871
Iteration 132, loss = 0.00070683
Iteration 133, loss = 0.00070012
Iteration 134, loss = 0.00068685
Iteration 135, loss = 0.00072158
Iteration 136, loss = 0.00067231
Iteration 137, loss = 0.00064654
Iteration 138, loss = 0.00070486
Iteration 139, loss = 0.00074484
Iteration 140, loss = 0.00061269
Iteration 141, loss = 0.00060295
Iteration 142, loss = 0.00064729
Iteration 143, loss = 0.00065852
Iteration 144, loss = 0.00060921
Iteration 145, loss = 0.00058426
Iteration 146, loss = 0.00068465
Iteration 147, loss = 0.00063111
Iteration 148, loss = 0.00063476
Iteration 149, loss = 0.00057845
Iteration 150, loss = 0.00057083
Iteration 151, loss = 0.00061104
Iteration 152, loss = 0.00056244
Iteration 153, loss = 0.00056789
Iteration 154, loss = 0.00072855
Iteration 155, loss = 0.00059473
Iteration 156, loss = 0.00052885
Iteration 157, loss = 0.00052324
Iteration 158, loss = 0.00053052
Iteration 159, loss = 0.00057027
Iteration 160, loss = 0.00054480
Iteration 161, loss = 0.00060829
Iteration 162, loss = 0.00053889
Iteration 163, loss = 0.00068894
Iteration 164, loss = 0.00060413
Iteration 165, loss = 0.00050484
Iteration 166, loss = 0.00049623
Iteration 167, loss = 0.00049632
Iteration 168, loss = 0.00050202
Iteration 169, loss = 0.00053194
Iteration 170, loss = 0.00052671
Iteration 171, loss = 0.00053405
Iteration 172, loss = 0.00050027
Iteration 173, loss = 0.00053524
Iteration 174, loss = 0.00070777
Iteration 175, loss = 0.00049253
Iteration 176, loss = 0.00048172
Iteration 177, loss = 0.00047335
Iteration 178, loss = 0.00048704
Iteration 179, loss = 0.00048715
Iteration 180, loss = 0.00053213
Iteration 181, loss = 0.00064187
Iteration 182, loss = 0.00048190
Iteration 183, loss = 0.00046815
Iteration 184, loss = 0.00047478
Iteration 185, loss = 0.00047330
Iteration 186, loss = 0.00049094
Iteration 187, loss = 0.00082006
Iteration 188, loss = 0.00062080
Iteration 189, loss = 0.00046997
Iteration 190, loss = 0.00045946
Iteration 191, loss = 0.00045651
Iteration 192, loss = 0.00045345
Iteration 193, loss = 0.00045675
Iteration 194, loss = 0.00046287
Iteration 195, loss = 0.00046881
Iteration 196, loss = 0.00070695
Iteration 197, loss = 0.00059501
Iteration 198, loss = 0.00046504
Iteration 199, loss = 0.00045419
Iteration 200, loss = 0.00045064
Iteration 1, loss = 0.12530327
Iteration 2, loss = 0.06109290
Iteration 3, loss = 0.05080825
Iteration 4, loss = 0.04303069
Iteration 5, loss = 0.03696810
Iteration 6, loss = 0.03253213
Iteration 7, loss = 0.02932680
Iteration 8, loss = 0.02679350
Iteration 9, loss = 0.02476721
Iteration 10, loss = 0.02318541
Iteration 11, loss = 0.02158824
Iteration 12, loss = 0.02019803
Iteration 13, loss = 0.01914771
Iteration 14, loss = 0.01810538
Iteration 15, loss = 0.01726343
Iteration 16, loss = 0.01658085
Iteration 17, loss = 0.01577005
Iteration 18, loss = 0.01519189
Iteration 19, loss = 0.01443963
Iteration 20, loss = 0.01386528
Iteration 21, loss = 0.01329529
Iteration 22, loss = 0.01276014
Iteration 23, loss = 0.01228834
Iteration 24, loss = 0.01178720
Iteration 25, loss = 0.01145337
Iteration 26, loss = 0.01086136
Iteration 27, loss = 0.01059572
Iteration 28, loss = 0.01009242
Iteration 29, loss = 0.00975382
Iteration 30, loss = 0.00954768
Iteration 31, loss = 0.00904582
Iteration 32, loss = 0.00882140
Iteration 33, loss = 0.00833774
Iteration 34, loss = 0.00812942
Iteration 35, loss = 0.00785113
Iteration 36, loss = 0.00753851
Iteration 37, loss = 0.00740602
Iteration 38, loss = 0.00708773
Iteration 39, loss = 0.00680756
Iteration 40, loss = 0.00662979
Iteration 41, loss = 0.00638346
Iteration 42, loss = 0.00613630
Iteration 43, loss = 0.00594878
Iteration 44, loss = 0.00559737
Iteration 45, loss = 0.00558120
Iteration 46, loss = 0.00530414
Iteration 47, loss = 0.00513906
Iteration 48, loss = 0.00501874
Iteration 49, loss = 0.00471196
Iteration 50, loss = 0.00465840
Iteration 51, loss = 0.00448886
Iteration 52, loss = 0.00432028
Iteration 53, loss = 0.00417562
Iteration 54, loss = 0.00403318
Iteration 55, loss = 0.00387423
Iteration 56, loss = 0.00376006
Iteration 57, loss = 0.00361746
Iteration 58, loss = 0.00353537
Iteration 59, loss = 0.00339730
Iteration 60, loss = 0.00329529
Iteration 61, loss = 0.00323579
Iteration 62, loss = 0.00308420
Iteration 63, loss = 0.00298612
Iteration 64, loss = 0.00291783
Iteration 65, loss = 0.00282865
Iteration 66, loss = 0.00263297
Iteration 67, loss = 0.00262542
Iteration 68, loss = 0.00255313
Iteration 69, loss = 0.00249135
Iteration 70, loss = 0.00235773
Iteration 71, loss = 0.00235865
Iteration 72, loss = 0.00229595
Iteration 73, loss = 0.00209733
Iteration 74, loss = 0.00220944
Iteration 75, loss = 0.00205776
Iteration 76, loss = 0.00201837
Iteration 77, loss = 0.00198741
Iteration 78, loss = 0.00182736
Iteration 79, loss = 0.00185898
Iteration 80, loss = 0.00177296
Iteration 81, loss = 0.00170388
Iteration 82, loss = 0.00164897
Iteration 83, loss = 0.00164253
Iteration 84, loss = 0.00157670
Iteration 85, loss = 0.00157780
Iteration 86, loss = 0.00151596
Iteration 87, loss = 0.00145727
Iteration 88, loss = 0.00138319
Iteration 89, loss = 0.00140737
Iteration 90, loss = 0.00133693
Iteration 91, loss = 0.00126844
Iteration 92, loss = 0.00132644
Iteration 93, loss = 0.00116898
Iteration 94, loss = 0.00121786
Iteration 95, loss = 0.00119673
Iteration 96, loss = 0.00114892
Iteration 97, loss = 0.00115420
Iteration 98, loss = 0.00112741
Iteration 99, loss = 0.00103634
Iteration 100, loss = 0.00106618
Iteration 101, loss = 0.00106198
Iteration 102, loss = 0.00098796
Iteration 103, loss = 0.00096134
Iteration 104, loss = 0.00098715
Iteration 105, loss = 0.00090293
Iteration 106, loss = 0.00095220
Iteration 107, loss = 0.00090230
Iteration 108, loss = 0.00087416
Iteration 109, loss = 0.00091089
Iteration 110, loss = 0.00085059
Iteration 111, loss = 0.00087606
Iteration 112, loss = 0.00078940
Iteration 113, loss = 0.00078999
Iteration 114, loss = 0.00075033
Iteration 115, loss = 0.00084677
Iteration 116, loss = 0.00085619
Iteration 117, loss = 0.00073381
Iteration 118, loss = 0.00072617
Iteration 119, loss = 0.00077782
Iteration 120, loss = 0.00078707
Iteration 121, loss = 0.00076253
Iteration 122, loss = 0.00071269
Iteration 123, loss = 0.00066680
Iteration 124, loss = 0.00069519
Iteration 125, loss = 0.00073720
Iteration 126, loss = 0.00073491
Iteration 127, loss = 0.00064232
Iteration 128, loss = 0.00061602
Iteration 129, loss = 0.00065121
Iteration 130, loss = 0.00072098
Iteration 131, loss = 0.00072673
Iteration 132, loss = 0.00068920
Iteration 133, loss = 0.00058505
Iteration 134, loss = 0.00056845
Iteration 135, loss = 0.00057935
Iteration 136, loss = 0.00061508
Iteration 137, loss = 0.00080200
Iteration 138, loss = 0.00059437
Iteration 139, loss = 0.00054428
Iteration 140, loss = 0.00055885
Iteration 141, loss = 0.00057579
Iteration 142, loss = 0.00065491
Iteration 143, loss = 0.00067209
Iteration 144, loss = 0.00055650
Iteration 145, loss = 0.00056452
Iteration 146, loss = 0.00056865
Iteration 147, loss = 0.00092652
Iteration 148, loss = 0.00053256
Iteration 149, loss = 0.00051305
Iteration 150, loss = 0.00051004
Iteration 151, loss = 0.00051001
Iteration 152, loss = 0.00052577
Iteration 153, loss = 0.00070413
Iteration 154, loss = 0.00071814
Iteration 155, loss = 0.00051765
Iteration 156, loss = 0.00049794
Iteration 157, loss = 0.00050462
Iteration 158, loss = 0.00050136
Iteration 159, loss = 0.00050179
Iteration 160, loss = 0.00054172
Iteration 161, loss = 0.00066725
Iteration 162, loss = 0.00050876
Iteration 163, loss = 0.00049603
Iteration 164, loss = 0.00066615
Iteration 165, loss = 0.00050603
Iteration 166, loss = 0.00048592
Iteration 167, loss = 0.00049187
Iteration 168, loss = 0.00048508
Iteration 169, loss = 0.00048873
Iteration 170, loss = 0.00078634
Iteration 171, loss = 0.00049074
Iteration 172, loss = 0.00047721
Iteration 173, loss = 0.00047431
Iteration 174, loss = 0.00047428
Iteration 175, loss = 0.00055590
Iteration 176, loss = 0.00078486
Iteration 177, loss = 0.00049171
Iteration 178, loss = 0.00046979
Iteration 179, loss = 0.00046276
Iteration 180, loss = 0.00046188
Iteration 181, loss = 0.00046422
Iteration 182, loss = 0.00047299
Iteration 183, loss = 0.00051078
Iteration 184, loss = 0.00095490
Iteration 185, loss = 0.00047071
Iteration 186, loss = 0.00045810
Iteration 187, loss = 0.00045812
Iteration 188, loss = 0.00045273
Iteration 189, loss = 0.00045322
Iteration 190, loss = 0.00045400
Iteration 191, loss = 0.00045797
Iteration 192, loss = 0.00046883
Iteration 193, loss = 0.00094751
Iteration 194, loss = 0.00056159
Iteration 195, loss = 0.00046333
Iteration 196, loss = 0.00045220
Iteration 197, loss = 0.00044692
Iteration 198, loss = 0.00044509
Iteration 199, loss = 0.00044537
Iteration 200, loss = 0.00044635
Iteration 1, loss = 0.13802017
Iteration 2, loss = 0.06223062
Iteration 3, loss = 0.05201737
Iteration 4, loss = 0.04463422
Iteration 5, loss = 0.03905300
Iteration 6, loss = 0.03457668
Iteration 7, loss = 0.03114094
Iteration 8, loss = 0.02838509
Iteration 9, loss = 0.02615627
Iteration 10, loss = 0.02439965
Iteration 11, loss = 0.02294031
Iteration 12, loss = 0.02162519
Iteration 13, loss = 0.02028432
Iteration 14, loss = 0.01933554
Iteration 15, loss = 0.01830292
Iteration 16, loss = 0.01751680
Iteration 17, loss = 0.01669747
Iteration 18, loss = 0.01589317
Iteration 19, loss = 0.01525488
Iteration 20, loss = 0.01460470
Iteration 21, loss = 0.01394491
Iteration 22, loss = 0.01347658
Iteration 23, loss = 0.01288778
Iteration 24, loss = 0.01247497
Iteration 25, loss = 0.01189498
Iteration 26, loss = 0.01156774
Iteration 27, loss = 0.01109817
Iteration 28, loss = 0.01070903
Iteration 29, loss = 0.01024216
Iteration 30, loss = 0.00986348
Iteration 31, loss = 0.00953332
Iteration 32, loss = 0.00911484
Iteration 33, loss = 0.00888040
Iteration 34, loss = 0.00857246
Iteration 35, loss = 0.00830949
Iteration 36, loss = 0.00792756
Iteration 37, loss = 0.00766571
Iteration 38, loss = 0.00736499
Iteration 39, loss = 0.00719309
Iteration 40, loss = 0.00689767
Iteration 41, loss = 0.00660558
Iteration 42, loss = 0.00642451
Iteration 43, loss = 0.00625525
Iteration 44, loss = 0.00605197
Iteration 45, loss = 0.00577893
Iteration 46, loss = 0.00557168
Iteration 47, loss = 0.00543756
Iteration 48, loss = 0.00520585
Iteration 49, loss = 0.00502132
Iteration 50, loss = 0.00483369
Iteration 51, loss = 0.00477046
Iteration 52, loss = 0.00448320
Iteration 53, loss = 0.00437917
Iteration 54, loss = 0.00420414
Iteration 55, loss = 0.00404506
Iteration 56, loss = 0.00394575
Iteration 57, loss = 0.00394948
Iteration 58, loss = 0.00365733
Iteration 59, loss = 0.00361420
Iteration 60, loss = 0.00342762
Iteration 61, loss = 0.00338766
Iteration 62, loss = 0.00330141
Iteration 63, loss = 0.00311205
Iteration 64, loss = 0.00307310
Iteration 65, loss = 0.00293724
Iteration 66, loss = 0.00282571
Iteration 67, loss = 0.00268928
Iteration 68, loss = 0.00270605
Iteration 69, loss = 0.00258956
Iteration 70, loss = 0.00243004
Iteration 71, loss = 0.00236423
Iteration 72, loss = 0.00230948
Iteration 73, loss = 0.00228607
Iteration 74, loss = 0.00221988
Iteration 75, loss = 0.00208479
Iteration 76, loss = 0.00204615
Iteration 77, loss = 0.00201542
Iteration 78, loss = 0.00189413
Iteration 79, loss = 0.00191788
Iteration 80, loss = 0.00189869
Iteration 81, loss = 0.00175037
Iteration 82, loss = 0.00166758
Iteration 83, loss = 0.00167211
Iteration 84, loss = 0.00161511
Iteration 85, loss = 0.00159086
Iteration 86, loss = 0.00156328
Iteration 87, loss = 0.00154162
Iteration 88, loss = 0.00143496
Iteration 89, loss = 0.00138411
Iteration 90, loss = 0.00133198
Iteration 91, loss = 0.00133718
Iteration 92, loss = 0.00135469
Iteration 93, loss = 0.00124852
Iteration 94, loss = 0.00123151
Iteration 95, loss = 0.00121271
Iteration 96, loss = 0.00119399
Iteration 97, loss = 0.00121236
Iteration 98, loss = 0.00109357
Iteration 99, loss = 0.00110585
Iteration 100, loss = 0.00109332
Iteration 101, loss = 0.00104446
Iteration 102, loss = 0.00100485
Iteration 103, loss = 0.00104318
Iteration 104, loss = 0.00095069
Iteration 105, loss = 0.00100753
Iteration 106, loss = 0.00091784
Iteration 107, loss = 0.00095434
Iteration 108, loss = 0.00088574
Iteration 109, loss = 0.00089995
Iteration 110, loss = 0.00084709
Iteration 111, loss = 0.00088794
Iteration 112, loss = 0.00087767
Iteration 113, loss = 0.00082582
Iteration 114, loss = 0.00078047
Iteration 115, loss = 0.00074441
Iteration 116, loss = 0.00077312
Iteration 117, loss = 0.00086066
Iteration 118, loss = 0.00080738
Iteration 119, loss = 0.00068683
Iteration 120, loss = 0.00067535
Iteration 121, loss = 0.00070735
Iteration 122, loss = 0.00071603
Iteration 123, loss = 0.00067093
Iteration 124, loss = 0.00065339
Iteration 125, loss = 0.00073641
Iteration 126, loss = 0.00071733
Iteration 127, loss = 0.00067421
Iteration 128, loss = 0.00062607
Iteration 129, loss = 0.00062872
Iteration 130, loss = 0.00062005
Iteration 131, loss = 0.00072723
Iteration 132, loss = 0.00062826
Iteration 133, loss = 0.00058745
Iteration 134, loss = 0.00059369
Iteration 135, loss = 0.00057438
Iteration 136, loss = 0.00058505
Iteration 137, loss = 0.00065179
Iteration 138, loss = 0.00073214
Iteration 139, loss = 0.00063284
Iteration 140, loss = 0.00054205
Iteration 141, loss = 0.00052972
Iteration 142, loss = 0.00053636
Iteration 143, loss = 0.00053359
Iteration 144, loss = 0.00059437
Iteration 145, loss = 0.00074723
Iteration 146, loss = 0.00054983
Iteration 147, loss = 0.00051817
Iteration 148, loss = 0.00050746
Iteration 149, loss = 0.00055908
Iteration 150, loss = 0.00076752
Iteration 151, loss = 0.00054492
Iteration 152, loss = 0.00052111
Iteration 153, loss = 0.00050232
Iteration 154, loss = 0.00049499
Iteration 155, loss = 0.00050650
Iteration 156, loss = 0.00049865
Iteration 157, loss = 0.00052231
Iteration 158, loss = 0.00068199
Iteration 159, loss = 0.00072551
Iteration 160, loss = 0.00049908
Iteration 161, loss = 0.00048500
Iteration 162, loss = 0.00048056
Iteration 163, loss = 0.00048128
Iteration 164, loss = 0.00047893
Iteration 165, loss = 0.00049098
Iteration 166, loss = 0.00096966
Iteration 167, loss = 0.00051007
Iteration 168, loss = 0.00047545
Iteration 169, loss = 0.00047089
Iteration 170, loss = 0.00046756
Iteration 171, loss = 0.00046859
Iteration 172, loss = 0.00046915
Iteration 173, loss = 0.00048378
Iteration 174, loss = 0.00062489
Iteration 175, loss = 0.00069531
Iteration 176, loss = 0.00047735
Iteration 177, loss = 0.00046580
Iteration 178, loss = 0.00046158
Iteration 179, loss = 0.00045819
Iteration 180, loss = 0.00046470
Iteration 181, loss = 0.00086409
Iteration 182, loss = 0.00052705
Iteration 183, loss = 0.00046428
Iteration 184, loss = 0.00045628
Iteration 185, loss = 0.00045582
Iteration 186, loss = 0.00045369
Iteration 187, loss = 0.00045447
Iteration 188, loss = 0.00047556
Iteration 189, loss = 0.00080754
Iteration 190, loss = 0.00047438
Iteration 191, loss = 0.00045243
Iteration 192, loss = 0.00044667
Iteration 193, loss = 0.00045172
Iteration 194, loss = 0.00045106
Iteration 195, loss = 0.00045296
Iteration 196, loss = 0.00045365
Iteration 197, loss = 0.00045371
Iteration 198, loss = 0.00047218
Iteration 199, loss = 0.00079902
Iteration 200, loss = 0.00048374
Iteration 1, loss = 0.12914641
Iteration 2, loss = 0.06204362
Iteration 3, loss = 0.05206947
Iteration 4, loss = 0.04379729
Iteration 5, loss = 0.03783084
Iteration 6, loss = 0.03336768
Iteration 7, loss = 0.02993236
Iteration 8, loss = 0.02730084
Iteration 9, loss = 0.02534850
Iteration 10, loss = 0.02362961
Iteration 11, loss = 0.02220035
Iteration 12, loss = 0.02088263
Iteration 13, loss = 0.01979139
Iteration 14, loss = 0.01878310
Iteration 15, loss = 0.01795155
Iteration 16, loss = 0.01715060
Iteration 17, loss = 0.01637324
Iteration 18, loss = 0.01564616
Iteration 19, loss = 0.01508283
Iteration 20, loss = 0.01445543
Iteration 21, loss = 0.01378594
Iteration 22, loss = 0.01322519
Iteration 23, loss = 0.01281212
Iteration 24, loss = 0.01230766
Iteration 25, loss = 0.01183593
Iteration 26, loss = 0.01146007
Iteration 27, loss = 0.01105698
Iteration 28, loss = 0.01066335
Iteration 29, loss = 0.01017817
Iteration 30, loss = 0.00999170
Iteration 31, loss = 0.00957524
Iteration 32, loss = 0.00923604
Iteration 33, loss = 0.00885757
Iteration 34, loss = 0.00870309
Iteration 35, loss = 0.00835369
Iteration 36, loss = 0.00816258
Iteration 37, loss = 0.00779470
Iteration 38, loss = 0.00752661
Iteration 39, loss = 0.00725419
Iteration 40, loss = 0.00702333
Iteration 41, loss = 0.00682663
Iteration 42, loss = 0.00670704
Iteration 43, loss = 0.00655489
Iteration 44, loss = 0.00612209
Iteration 45, loss = 0.00601198
Iteration 46, loss = 0.00581431
Iteration 47, loss = 0.00561548
Iteration 48, loss = 0.00545213
Iteration 49, loss = 0.00528883
Iteration 50, loss = 0.00503977
Iteration 51, loss = 0.00489444
Iteration 52, loss = 0.00471507
Iteration 53, loss = 0.00456873
Iteration 54, loss = 0.00446260
Iteration 55, loss = 0.00434978
Iteration 56, loss = 0.00420012
Iteration 57, loss = 0.00407449
Iteration 58, loss = 0.00386579
Iteration 59, loss = 0.00372358
Iteration 60, loss = 0.00367866
Iteration 61, loss = 0.00358609
Iteration 62, loss = 0.00338507
Iteration 63, loss = 0.00325353
Iteration 64, loss = 0.00317159
Iteration 65, loss = 0.00308195
Iteration 66, loss = 0.00292318
Iteration 67, loss = 0.00293647
Iteration 68, loss = 0.00282445
Iteration 69, loss = 0.00271502
Iteration 70, loss = 0.00264222
Iteration 71, loss = 0.00254424
Iteration 72, loss = 0.00248451
Iteration 73, loss = 0.00234925
Iteration 74, loss = 0.00225560
Iteration 75, loss = 0.00222957
Iteration 76, loss = 0.00218236
Iteration 77, loss = 0.00216892
Iteration 78, loss = 0.00204563
Iteration 79, loss = 0.00195857
Iteration 80, loss = 0.00192252
Iteration 81, loss = 0.00187969
Iteration 82, loss = 0.00177195
Iteration 83, loss = 0.00171258
Iteration 84, loss = 0.00170934
Iteration 85, loss = 0.00164243
Iteration 86, loss = 0.00154917
Iteration 87, loss = 0.00158208
Iteration 88, loss = 0.00147730
Iteration 89, loss = 0.00149844
Iteration 90, loss = 0.00142954
Iteration 91, loss = 0.00142936
Iteration 92, loss = 0.00135392
Iteration 93, loss = 0.00125430
Iteration 94, loss = 0.00127455
Iteration 95, loss = 0.00131638
Iteration 96, loss = 0.00125468
Iteration 97, loss = 0.00113960
Iteration 98, loss = 0.00116413
Iteration 99, loss = 0.00108043
Iteration 100, loss = 0.00106548
Iteration 101, loss = 0.00103835
Iteration 102, loss = 0.00102606
Iteration 103, loss = 0.00103216
Iteration 104, loss = 0.00102235
Iteration 105, loss = 0.00089874
Iteration 106, loss = 0.00092444
Iteration 107, loss = 0.00093404
Iteration 108, loss = 0.00088522
Iteration 109, loss = 0.00091354
Iteration 110, loss = 0.00090205
Iteration 111, loss = 0.00088519
Iteration 112, loss = 0.00078385
Iteration 113, loss = 0.00078999
Iteration 114, loss = 0.00081852
Iteration 115, loss = 0.00077986
Iteration 116, loss = 0.00086482
Iteration 117, loss = 0.00082188
Iteration 118, loss = 0.00071537
Iteration 119, loss = 0.00070208
Iteration 120, loss = 0.00074709
Iteration 121, loss = 0.00070583
Iteration 122, loss = 0.00070544
Iteration 123, loss = 0.00073810
Iteration 124, loss = 0.00065369
Iteration 125, loss = 0.00077428
Iteration 126, loss = 0.00071686
Iteration 127, loss = 0.00063338
Iteration 128, loss = 0.00064912
Iteration 129, loss = 0.00064073
Iteration 130, loss = 0.00066720
Iteration 131, loss = 0.00065544
Iteration 132, loss = 0.00068258
Iteration 133, loss = 0.00069311
Iteration 134, loss = 0.00060545
Iteration 135, loss = 0.00057658
Iteration 136, loss = 0.00057160
Iteration 137, loss = 0.00057249
Iteration 138, loss = 0.00058586
Iteration 139, loss = 0.00107455
Iteration 140, loss = 0.00066152
Iteration 141, loss = 0.00054164
Iteration 142, loss = 0.00053163
Iteration 143, loss = 0.00052148
Iteration 144, loss = 0.00052932
Iteration 145, loss = 0.00053491
Iteration 146, loss = 0.00053513
Iteration 147, loss = 0.00096843
Iteration 148, loss = 0.00064310
Iteration 149, loss = 0.00051768
Iteration 150, loss = 0.00050844
Iteration 151, loss = 0.00050777
Iteration 152, loss = 0.00051210
Iteration 153, loss = 0.00050428
Iteration 154, loss = 0.00051889
Iteration 155, loss = 0.00080975
Iteration 156, loss = 0.00073932
Iteration 157, loss = 0.00050591
Iteration 158, loss = 0.00049377
Iteration 159, loss = 0.00049054
Iteration 160, loss = 0.00049610
Iteration 161, loss = 0.00048994
Iteration 162, loss = 0.00050429
Iteration 163, loss = 0.00066984
Iteration 164, loss = 0.00126439
Iteration 165, loss = 0.00051643
Iteration 166, loss = 0.00048733
Iteration 167, loss = 0.00048279
Iteration 168, loss = 0.00047811
Iteration 169, loss = 0.00047689
Iteration 170, loss = 0.00047917
Iteration 171, loss = 0.00048199
Iteration 172, loss = 0.00049832
Iteration 173, loss = 0.00089245
Iteration 174, loss = 0.00051554
Iteration 175, loss = 0.00047693
Iteration 176, loss = 0.00047028
Iteration 177, loss = 0.00046726
Iteration 178, loss = 0.00047080
Iteration 179, loss = 0.00049247
Iteration 180, loss = 0.00094358
Iteration 181, loss = 0.00053671
Iteration 182, loss = 0.00047425
Iteration 183, loss = 0.00046399
Iteration 184, loss = 0.00045983
Iteration 185, loss = 0.00046037
Iteration 186, loss = 0.00046050
Iteration 187, loss = 0.00046270
Iteration 188, loss = 0.00049139
Iteration 189, loss = 0.00086816
Iteration 190, loss = 0.00050757
Iteration 191, loss = 0.00046306
Iteration 192, loss = 0.00045664
Iteration 193, loss = 0.00045489
Iteration 194, loss = 0.00045853
Iteration 195, loss = 0.00046151
Iteration 196, loss = 0.00046733
Iteration 197, loss = 0.00046999
Iteration 198, loss = 0.00113926
Iteration 199, loss = 0.00054823
Iteration 200, loss = 0.00046453
Iteration 1, loss = 0.14336675
Iteration 2, loss = 0.06259303
Iteration 3, loss = 0.05246864
Iteration 4, loss = 0.04435638
Iteration 5, loss = 0.03807784
Iteration 6, loss = 0.03348994
Iteration 7, loss = 0.03001985
Iteration 8, loss = 0.02734353
Iteration 9, loss = 0.02527474
Iteration 10, loss = 0.02345698
Iteration 11, loss = 0.02199617
Iteration 12, loss = 0.02069171
Iteration 13, loss = 0.01966483
Iteration 14, loss = 0.01860731
Iteration 15, loss = 0.01763790
Iteration 16, loss = 0.01679773
Iteration 17, loss = 0.01607016
Iteration 18, loss = 0.01523745
Iteration 19, loss = 0.01449896
Iteration 20, loss = 0.01402369
Iteration 21, loss = 0.01324604
Iteration 22, loss = 0.01263607
Iteration 23, loss = 0.01209046
Iteration 24, loss = 0.01151779
Iteration 25, loss = 0.01111466
Iteration 26, loss = 0.01064074
Iteration 27, loss = 0.01007535
Iteration 28, loss = 0.00980332
Iteration 29, loss = 0.00941377
Iteration 30, loss = 0.00890450
Iteration 31, loss = 0.00864371
Iteration 32, loss = 0.00824497
Iteration 33, loss = 0.00791211
Iteration 34, loss = 0.00761380
Iteration 35, loss = 0.00726942
Iteration 36, loss = 0.00690680
Iteration 37, loss = 0.00670343
Iteration 38, loss = 0.00642683
Iteration 39, loss = 0.00612935
Iteration 40, loss = 0.00586626
Iteration 41, loss = 0.00569039
Iteration 42, loss = 0.00549120
Iteration 43, loss = 0.00528603
Iteration 44, loss = 0.00506089
Iteration 45, loss = 0.00478184
Iteration 46, loss = 0.00464603
Iteration 47, loss = 0.00449213
Iteration 48, loss = 0.00432561
Iteration 49, loss = 0.00411079
Iteration 50, loss = 0.00396279
Iteration 51, loss = 0.00390280
Iteration 52, loss = 0.00362176
Iteration 53, loss = 0.00350958
Iteration 54, loss = 0.00343679
Iteration 55, loss = 0.00329200
Iteration 56, loss = 0.00315367
Iteration 57, loss = 0.00300712
Iteration 58, loss = 0.00284148
Iteration 59, loss = 0.00278492
Iteration 60, loss = 0.00271985
Iteration 61, loss = 0.00254887
Iteration 62, loss = 0.00244344
Iteration 63, loss = 0.00238696
Iteration 64, loss = 0.00235283
Iteration 65, loss = 0.00223181
Iteration 66, loss = 0.00208531
Iteration 67, loss = 0.00206493
Iteration 68, loss = 0.00195347
Iteration 69, loss = 0.00192018
Iteration 70, loss = 0.00189028
Iteration 71, loss = 0.00175398
Iteration 72, loss = 0.00169464
Iteration 73, loss = 0.00162309
Iteration 74, loss = 0.00159978
Iteration 75, loss = 0.00156492
Iteration 76, loss = 0.00153399
Iteration 77, loss = 0.00141643
Iteration 78, loss = 0.00139602
Iteration 79, loss = 0.00132026
Iteration 80, loss = 0.00129444
Iteration 81, loss = 0.00131089
Iteration 82, loss = 0.00120935
Iteration 83, loss = 0.00115369
Iteration 84, loss = 0.00113838
Iteration 85, loss = 0.00117324
Iteration 86, loss = 0.00115256
Iteration 87, loss = 0.00108915
Iteration 88, loss = 0.00105242
Iteration 89, loss = 0.00098196
Iteration 90, loss = 0.00097674
Iteration 91, loss = 0.00091133
Iteration 92, loss = 0.00095951
Iteration 93, loss = 0.00098611
Iteration 94, loss = 0.00089928
Iteration 95, loss = 0.00085053
Iteration 96, loss = 0.00085968
Iteration 97, loss = 0.00091526
Iteration 98, loss = 0.00079276
Iteration 99, loss = 0.00074935
Iteration 100, loss = 0.00074226
Iteration 101, loss = 0.00081895
Iteration 102, loss = 0.00078199
Iteration 103, loss = 0.00076498
Iteration 104, loss = 0.00077631
Iteration 105, loss = 0.00071595
Iteration 106, loss = 0.00067627
Iteration 107, loss = 0.00068675
Iteration 108, loss = 0.00069191
Iteration 109, loss = 0.00072056
Iteration 110, loss = 0.00065063
Iteration 111, loss = 0.00063376
Iteration 112, loss = 0.00068218
Iteration 113, loss = 0.00073740
Iteration 114, loss = 0.00073644
Iteration 115, loss = 0.00058633
Iteration 116, loss = 0.00057099
Iteration 117, loss = 0.00057500
Iteration 118, loss = 0.00063822
Iteration 119, loss = 0.00058997
Iteration 120, loss = 0.00058661
Iteration 121, loss = 0.00057421
Iteration 122, loss = 0.00075518
Iteration 123, loss = 0.00063396
Iteration 124, loss = 0.00055216
Iteration 125, loss = 0.00052950
Iteration 126, loss = 0.00060687
Iteration 127, loss = 0.00067333
Iteration 128, loss = 0.00053028
Iteration 129, loss = 0.00051959
Iteration 130, loss = 0.00052383
Iteration 131, loss = 0.00053425
Iteration 132, loss = 0.00055834
Iteration 133, loss = 0.00078208
Iteration 134, loss = 0.00064738
Iteration 135, loss = 0.00051422
Iteration 136, loss = 0.00049869
Iteration 137, loss = 0.00049891
Iteration 138, loss = 0.00049874
Iteration 139, loss = 0.00050064
Iteration 140, loss = 0.00052062
Iteration 141, loss = 0.00055878
Iteration 142, loss = 0.00063687
Iteration 143, loss = 0.00050925
Iteration 144, loss = 0.00049256
Iteration 145, loss = 0.00048754
Iteration 146, loss = 0.00049405
Iteration 147, loss = 0.00053362
Iteration 148, loss = 0.00051140
Iteration 149, loss = 0.00049490
Iteration 150, loss = 0.00048737
Iteration 151, loss = 0.00085558
Iteration 152, loss = 0.00048891
Iteration 153, loss = 0.00046775
Iteration 154, loss = 0.00046489
Iteration 155, loss = 0.00046436
Iteration 156, loss = 0.00046846
Iteration 157, loss = 0.00047535
Iteration 158, loss = 0.00090204
Iteration 159, loss = 0.00050096
Iteration 160, loss = 0.00046816
Iteration 161, loss = 0.00046171
Iteration 162, loss = 0.00046050
Iteration 163, loss = 0.00045904
Iteration 164, loss = 0.00045692
Iteration 165, loss = 0.00046437
Iteration 166, loss = 0.00048609
Iteration 167, loss = 0.00050670
Iteration 168, loss = 0.00087188
Iteration 169, loss = 0.00052466
Iteration 170, loss = 0.00045881
Iteration 171, loss = 0.00045201
Iteration 172, loss = 0.00044826
Iteration 173, loss = 0.00044638
Iteration 174, loss = 0.00044896
Iteration 175, loss = 0.00047193
Iteration 176, loss = 0.00050254
Iteration 177, loss = 0.00046446
Iteration 178, loss = 0.00044608
Iteration 179, loss = 0.00046720
Iteration 180, loss = 0.00095263
Iteration 181, loss = 0.00051883
Iteration 182, loss = 0.00045266
Iteration 183, loss = 0.00044352
Iteration 184, loss = 0.00043914
Iteration 185, loss = 0.00043761
Iteration 186, loss = 0.00043765
Iteration 187, loss = 0.00044105
Iteration 188, loss = 0.00044065
Iteration 189, loss = 0.00044507
Iteration 190, loss = 0.00078889
Iteration 191, loss = 0.00047717
Iteration 192, loss = 0.00044000
Iteration 193, loss = 0.00043342
Iteration 194, loss = 0.00043098
Iteration 195, loss = 0.00043283
Iteration 196, loss = 0.00043322
Iteration 197, loss = 0.00043329
Iteration 198, loss = 0.00044610
Iteration 199, loss = 0.00058189
Iteration 200, loss = 0.00067308
Iteration 1, loss = 0.13441327
Iteration 2, loss = 0.06328232
Iteration 3, loss = 0.05261029
Iteration 4, loss = 0.04371133
Iteration 5, loss = 0.03771231
Iteration 6, loss = 0.03337815
Iteration 7, loss = 0.03003417
Iteration 8, loss = 0.02753106
Iteration 9, loss = 0.02540792
Iteration 10, loss = 0.02358435
Iteration 11, loss = 0.02214793
Iteration 12, loss = 0.02077660
Iteration 13, loss = 0.01978099
Iteration 14, loss = 0.01869644
Iteration 15, loss = 0.01760682
Iteration 16, loss = 0.01693362
Iteration 17, loss = 0.01613696
Iteration 18, loss = 0.01533914
Iteration 19, loss = 0.01479457
Iteration 20, loss = 0.01427301
Iteration 21, loss = 0.01366794
Iteration 22, loss = 0.01306417
Iteration 23, loss = 0.01247702
Iteration 24, loss = 0.01198551
Iteration 25, loss = 0.01153915
Iteration 26, loss = 0.01107132
Iteration 27, loss = 0.01076163
Iteration 28, loss = 0.01025615
Iteration 29, loss = 0.00992980
Iteration 30, loss = 0.00950543
Iteration 31, loss = 0.00913836
Iteration 32, loss = 0.00867698
Iteration 33, loss = 0.00840946
Iteration 34, loss = 0.00807834
Iteration 35, loss = 0.00788382
Iteration 36, loss = 0.00756848
Iteration 37, loss = 0.00730002
Iteration 38, loss = 0.00694794
Iteration 39, loss = 0.00673936
Iteration 40, loss = 0.00650829
Iteration 41, loss = 0.00627864
Iteration 42, loss = 0.00620393
Iteration 43, loss = 0.00585717
Iteration 44, loss = 0.00567837
Iteration 45, loss = 0.00543750
Iteration 46, loss = 0.00530174
Iteration 47, loss = 0.00509163
Iteration 48, loss = 0.00500864
Iteration 49, loss = 0.00469352
Iteration 50, loss = 0.00462634
Iteration 51, loss = 0.00432751
Iteration 52, loss = 0.00429139
Iteration 53, loss = 0.00417062
Iteration 54, loss = 0.00402796
Iteration 55, loss = 0.00390624
Iteration 56, loss = 0.00368351
Iteration 57, loss = 0.00358640
Iteration 58, loss = 0.00343989
Iteration 59, loss = 0.00339932
Iteration 60, loss = 0.00321724
Iteration 61, loss = 0.00312669
Iteration 62, loss = 0.00308545
Iteration 63, loss = 0.00296471
Iteration 64, loss = 0.00284571
Iteration 65, loss = 0.00270826
Iteration 66, loss = 0.00268177
Iteration 67, loss = 0.00253900
Iteration 68, loss = 0.00249748
Iteration 69, loss = 0.00239835
Iteration 70, loss = 0.00237324
Iteration 71, loss = 0.00234175
Iteration 72, loss = 0.00212692
Iteration 73, loss = 0.00210003
Iteration 74, loss = 0.00208056
Iteration 75, loss = 0.00195540
Iteration 76, loss = 0.00190072
Iteration 77, loss = 0.00185006
Iteration 78, loss = 0.00184586
Iteration 79, loss = 0.00168603
Iteration 80, loss = 0.00174285
Iteration 81, loss = 0.00170888
Iteration 82, loss = 0.00163340
Iteration 83, loss = 0.00153286
Iteration 84, loss = 0.00150363
Iteration 85, loss = 0.00152781
Iteration 86, loss = 0.00134274
Iteration 87, loss = 0.00136141
Iteration 88, loss = 0.00138177
Iteration 89, loss = 0.00128345
Iteration 90, loss = 0.00127246
Iteration 91, loss = 0.00134892
Iteration 92, loss = 0.00120204
Iteration 93, loss = 0.00114396
Iteration 94, loss = 0.00117365
Iteration 95, loss = 0.00119836
Iteration 96, loss = 0.00121544
Iteration 97, loss = 0.00102079
Iteration 98, loss = 0.00103278
Iteration 99, loss = 0.00099526
Iteration 100, loss = 0.00104878
Iteration 101, loss = 0.00099549
Iteration 102, loss = 0.00093885
Iteration 103, loss = 0.00099728
Iteration 104, loss = 0.00091729
Iteration 105, loss = 0.00089666
Iteration 106, loss = 0.00090629
Iteration 107, loss = 0.00088103
Iteration 108, loss = 0.00090937
Iteration 109, loss = 0.00085538
Iteration 110, loss = 0.00081247
Iteration 111, loss = 0.00093290
Iteration 112, loss = 0.00078428
Iteration 113, loss = 0.00076681
Iteration 114, loss = 0.00075290
Iteration 115, loss = 0.00085080
Iteration 116, loss = 0.00070114
Iteration 117, loss = 0.00071141
Iteration 118, loss = 0.00078322
Iteration 119, loss = 0.00082115
Iteration 120, loss = 0.00070243
Iteration 121, loss = 0.00068092
Iteration 122, loss = 0.00068198
Iteration 123, loss = 0.00071895
Iteration 124, loss = 0.00068764
Iteration 125, loss = 0.00064169
Iteration 126, loss = 0.00064274
Iteration 127, loss = 0.00100778
Iteration 128, loss = 0.00063309
Iteration 129, loss = 0.00058888
Iteration 130, loss = 0.00057241
Iteration 131, loss = 0.00058930
Iteration 132, loss = 0.00092273
Iteration 133, loss = 0.00070126
Iteration 134, loss = 0.00056153
Iteration 135, loss = 0.00054863
Iteration 136, loss = 0.00054630
Iteration 137, loss = 0.00084348
Iteration 138, loss = 0.00057382
Iteration 139, loss = 0.00054180
Iteration 140, loss = 0.00055046
Iteration 141, loss = 0.00055361
Iteration 142, loss = 0.00057659
Iteration 143, loss = 0.00082418
Iteration 144, loss = 0.00058658
Iteration 145, loss = 0.00053516
Iteration 146, loss = 0.00052409
Iteration 147, loss = 0.00051955
Iteration 148, loss = 0.00062631
Iteration 149, loss = 0.00058980
Iteration 150, loss = 0.00055926
Iteration 151, loss = 0.00052814
Iteration 152, loss = 0.00051416
Iteration 153, loss = 0.00055699
Iteration 154, loss = 0.00093954
Iteration 155, loss = 0.00060978
Iteration 156, loss = 0.00050159
Iteration 157, loss = 0.00049159
Iteration 158, loss = 0.00048839
Iteration 159, loss = 0.00048950
Iteration 160, loss = 0.00051770
Iteration 161, loss = 0.00067669
Iteration 162, loss = 0.00059312
Iteration 163, loss = 0.00048583
Iteration 164, loss = 0.00048042
Iteration 165, loss = 0.00048149
Iteration 166, loss = 0.00074432
Iteration 167, loss = 0.00064933
Iteration 168, loss = 0.00048934
Iteration 169, loss = 0.00047377
Iteration 170, loss = 0.00047125
Iteration 171, loss = 0.00046968
Iteration 172, loss = 0.00053393
Iteration 173, loss = 0.00092682
Iteration 174, loss = 0.00049036
Iteration 175, loss = 0.00047347
Iteration 176, loss = 0.00046664
Iteration 177, loss = 0.00046501
Iteration 178, loss = 0.00046689
Iteration 179, loss = 0.00046867
Iteration 180, loss = 0.00049820
Iteration 181, loss = 0.00114422
Iteration 182, loss = 0.00050275
Iteration 183, loss = 0.00047035
Iteration 184, loss = 0.00046228
Iteration 185, loss = 0.00045818
Iteration 186, loss = 0.00045634
Iteration 187, loss = 0.00045642
Iteration 188, loss = 0.00045931
Iteration 189, loss = 0.00046156
Iteration 190, loss = 0.00047446
Iteration 191, loss = 0.00097651
Iteration 192, loss = 0.00052746
Iteration 193, loss = 0.00046277
Iteration 194, loss = 0.00045067
Iteration 195, loss = 0.00044962
Iteration 196, loss = 0.00044777
Iteration 197, loss = 0.00044708
Iteration 198, loss = 0.00045103
Iteration 199, loss = 0.00056531
Iteration 200, loss = 0.00105281
Iteration 1, loss = 0.12331081
Iteration 2, loss = 0.06109227
Iteration 3, loss = 0.05050545
Iteration 4, loss = 0.04211184
Iteration 5, loss = 0.03621204
Iteration 6, loss = 0.03193696
Iteration 7, loss = 0.02894734
Iteration 8, loss = 0.02650681
Iteration 9, loss = 0.02455252
Iteration 10, loss = 0.02274537
Iteration 11, loss = 0.02137836
Iteration 12, loss = 0.02026394
Iteration 13, loss = 0.01905674
Iteration 14, loss = 0.01801348
Iteration 15, loss = 0.01706205
Iteration 16, loss = 0.01628871
Iteration 17, loss = 0.01555052
Iteration 18, loss = 0.01460844
Iteration 19, loss = 0.01405997
Iteration 20, loss = 0.01332390
Iteration 21, loss = 0.01278628
Iteration 22, loss = 0.01235238
Iteration 23, loss = 0.01176880
Iteration 24, loss = 0.01131615
Iteration 25, loss = 0.01066717
Iteration 26, loss = 0.01039018
Iteration 27, loss = 0.00995718
Iteration 28, loss = 0.00951085
Iteration 29, loss = 0.00912417
Iteration 30, loss = 0.00884977
Iteration 31, loss = 0.00842901
Iteration 32, loss = 0.00815222
Iteration 33, loss = 0.00776254
Iteration 34, loss = 0.00741807
Iteration 35, loss = 0.00717929
Iteration 36, loss = 0.00696160
Iteration 37, loss = 0.00671242
Iteration 38, loss = 0.00626982
Iteration 39, loss = 0.00622227
Iteration 40, loss = 0.00594138
Iteration 41, loss = 0.00568192
Iteration 42, loss = 0.00546975
Iteration 43, loss = 0.00534097
Iteration 44, loss = 0.00508891
Iteration 45, loss = 0.00492578
Iteration 46, loss = 0.00465454
Iteration 47, loss = 0.00453925
Iteration 48, loss = 0.00439172
Iteration 49, loss = 0.00412384
Iteration 50, loss = 0.00402346
Iteration 51, loss = 0.00389639
Iteration 52, loss = 0.00376828
Iteration 53, loss = 0.00360030
Iteration 54, loss = 0.00353120
Iteration 55, loss = 0.00334213
Iteration 56, loss = 0.00317840
Iteration 57, loss = 0.00304591
Iteration 58, loss = 0.00301378
Iteration 59, loss = 0.00281607
Iteration 60, loss = 0.00269633
Iteration 61, loss = 0.00259706
Iteration 62, loss = 0.00263611
Iteration 63, loss = 0.00244665
Iteration 64, loss = 0.00234516
Iteration 65, loss = 0.00228705
Iteration 66, loss = 0.00224830
Iteration 67, loss = 0.00212953
Iteration 68, loss = 0.00197479
Iteration 69, loss = 0.00199215
Iteration 70, loss = 0.00187192
Iteration 71, loss = 0.00180006
Iteration 72, loss = 0.00173854
Iteration 73, loss = 0.00172801
Iteration 74, loss = 0.00175734
Iteration 75, loss = 0.00150985
Iteration 76, loss = 0.00155917
Iteration 77, loss = 0.00141921
Iteration 78, loss = 0.00142768
Iteration 79, loss = 0.00140201
Iteration 80, loss = 0.00137068
Iteration 81, loss = 0.00137840
Iteration 82, loss = 0.00125036
Iteration 83, loss = 0.00122917
Iteration 84, loss = 0.00118065
Iteration 85, loss = 0.00118643
Iteration 86, loss = 0.00113904
Iteration 87, loss = 0.00110344
Iteration 88, loss = 0.00104977
Iteration 89, loss = 0.00099713
Iteration 90, loss = 0.00101018
Iteration 91, loss = 0.00101684
Iteration 92, loss = 0.00096672
Iteration 93, loss = 0.00096541
Iteration 94, loss = 0.00092447
Iteration 95, loss = 0.00098759
Iteration 96, loss = 0.00089014
Iteration 97, loss = 0.00082718
Iteration 98, loss = 0.00081287
Iteration 99, loss = 0.00079215
Iteration 100, loss = 0.00077618
Iteration 101, loss = 0.00088616
Iteration 102, loss = 0.00073836
Iteration 103, loss = 0.00073597
Iteration 104, loss = 0.00074223
Iteration 105, loss = 0.00076633
Iteration 106, loss = 0.00065880
Iteration 107, loss = 0.00073866
Iteration 108, loss = 0.00077184
Iteration 109, loss = 0.00064903
Iteration 110, loss = 0.00064531
Iteration 111, loss = 0.00063033
Iteration 112, loss = 0.00061937
Iteration 113, loss = 0.00067950
Iteration 114, loss = 0.00064503
Iteration 115, loss = 0.00068346
Iteration 116, loss = 0.00076738
Iteration 117, loss = 0.00056062
Iteration 118, loss = 0.00056281
Iteration 119, loss = 0.00055322
Iteration 120, loss = 0.00055771
Iteration 121, loss = 0.00057820
Iteration 122, loss = 0.00058159
Iteration 123, loss = 0.00067267
Iteration 124, loss = 0.00061615
Iteration 125, loss = 0.00053951
Iteration 126, loss = 0.00052830
Iteration 127, loss = 0.00051495
Iteration 128, loss = 0.00056399
Iteration 129, loss = 0.00094720
Iteration 130, loss = 0.00055043
Iteration 131, loss = 0.00050314
Iteration 132, loss = 0.00048826
Iteration 133, loss = 0.00048517
Iteration 134, loss = 0.00048731
Iteration 135, loss = 0.00049512
Iteration 136, loss = 0.00050951
Iteration 137, loss = 0.00053270
Iteration 138, loss = 0.00053289
Iteration 139, loss = 0.00065718
Iteration 140, loss = 0.00049958
Iteration 141, loss = 0.00048671
Iteration 142, loss = 0.00047244
Iteration 143, loss = 0.00046605
Iteration 144, loss = 0.00049441
Iteration 145, loss = 0.00081988
Iteration 146, loss = 0.00062851
Iteration 147, loss = 0.00046730
Iteration 148, loss = 0.00045457
Iteration 149, loss = 0.00045241
Iteration 150, loss = 0.00045319
Iteration 151, loss = 0.00045488
Iteration 152, loss = 0.00048352
Iteration 153, loss = 0.00082004
Iteration 154, loss = 0.00050516
Iteration 155, loss = 0.00045677
Iteration 156, loss = 0.00044695
Iteration 157, loss = 0.00044689
Iteration 158, loss = 0.00044709
Iteration 159, loss = 0.00045613
Iteration 160, loss = 0.00045525
Iteration 161, loss = 0.00062948
Iteration 162, loss = 0.00091008
Iteration 163, loss = 0.00046929
Iteration 164, loss = 0.00044741
Iteration 165, loss = 0.00044222
Iteration 166, loss = 0.00043804
Iteration 167, loss = 0.00043540
Iteration 168, loss = 0.00044298
Iteration 169, loss = 0.00043961
Iteration 170, loss = 0.00044337
Iteration 171, loss = 0.00075926
Iteration 172, loss = 0.00070203
Iteration 173, loss = 0.00045159
Iteration 174, loss = 0.00043548
Iteration 175, loss = 0.00043158
Iteration 176, loss = 0.00042957
Iteration 177, loss = 0.00042967
Iteration 178, loss = 0.00043359
Iteration 179, loss = 0.00072818
Iteration 180, loss = 0.00070101
Iteration 181, loss = 0.00044899
Iteration 182, loss = 0.00043288
Iteration 183, loss = 0.00042770
Iteration 184, loss = 0.00042637
Iteration 185, loss = 0.00042377
Iteration 186, loss = 0.00042523
Iteration 187, loss = 0.00042803
Iteration 188, loss = 0.00044657
Iteration 189, loss = 0.00069282
Iteration 190, loss = 0.00077183
Iteration 191, loss = 0.00045553
Iteration 192, loss = 0.00042692
Iteration 193, loss = 0.00042342
Iteration 194, loss = 0.00041923
Iteration 195, loss = 0.00041857
Iteration 196, loss = 0.00042065
Iteration 197, loss = 0.00042083
Iteration 198, loss = 0.00042739
Iteration 199, loss = 0.00043947
Iteration 200, loss = 0.00124701
Iteration 1, loss = 0.13302423
Iteration 2, loss = 0.06513202
Iteration 3, loss = 0.05490182
Iteration 4, loss = 0.04731365
Iteration 5, loss = 0.04134399
Iteration 6, loss = 0.03704657
Iteration 7, loss = 0.03366464
Iteration 8, loss = 0.03118049
Iteration 9, loss = 0.02903214
Iteration 10, loss = 0.02727162
Iteration 11, loss = 0.02570042
Iteration 12, loss = 0.02427506
Iteration 13, loss = 0.02312829
Iteration 14, loss = 0.02209566
Iteration 15, loss = 0.02114145
Iteration 16, loss = 0.02028774
Iteration 17, loss = 0.01957144
Iteration 18, loss = 0.01882891
Iteration 19, loss = 0.01820634
Iteration 20, loss = 0.01759266
Iteration 21, loss = 0.01702497
Iteration 22, loss = 0.01643927
Iteration 23, loss = 0.01598371
Iteration 24, loss = 0.01552768
Iteration 25, loss = 0.01505739
Iteration 26, loss = 0.01471358
Iteration 27, loss = 0.01431401
Iteration 28, loss = 0.01391565
Iteration 29, loss = 0.01353791
Iteration 30, loss = 0.01313255
Iteration 31, loss = 0.01285034
Iteration 32, loss = 0.01251024
Iteration 33, loss = 0.01218543
Iteration 34, loss = 0.01189259
Iteration 35, loss = 0.01153706
Iteration 36, loss = 0.01133648
Iteration 37, loss = 0.01107369
Iteration 38, loss = 0.01082264
Iteration 39, loss = 0.01058690
Iteration 40, loss = 0.01028976
Iteration 41, loss = 0.01008005
Iteration 42, loss = 0.00984705
Iteration 43, loss = 0.00967346
Iteration 44, loss = 0.00939848
Iteration 45, loss = 0.00922368
Iteration 46, loss = 0.00901957
Iteration 47, loss = 0.00881041
Iteration 48, loss = 0.00861384
Iteration 49, loss = 0.00835323
Iteration 50, loss = 0.00828293
Iteration 51, loss = 0.00803141
Iteration 52, loss = 0.00790180
Iteration 53, loss = 0.00775243
Iteration 54, loss = 0.00760351
Iteration 55, loss = 0.00742515
Iteration 56, loss = 0.00724304
Iteration 57, loss = 0.00708650
Iteration 58, loss = 0.00695269
Iteration 59, loss = 0.00674535
Iteration 60, loss = 0.00666967
Iteration 61, loss = 0.00655395
Iteration 62, loss = 0.00629968
Iteration 63, loss = 0.00624825
Iteration 64, loss = 0.00613872
Iteration 65, loss = 0.00597859
Iteration 66, loss = 0.00575467
Iteration 67, loss = 0.00574348
Iteration 68, loss = 0.00569992
Iteration 69, loss = 0.00553346
Iteration 70, loss = 0.00546408
Iteration 71, loss = 0.00531077
Iteration 72, loss = 0.00519283
Iteration 73, loss = 0.00513758
Iteration 74, loss = 0.00496835
Iteration 75, loss = 0.00491264
Iteration 76, loss = 0.00472848
Iteration 77, loss = 0.00474792
Iteration 78, loss = 0.00460821
Iteration 79, loss = 0.00449612
Iteration 80, loss = 0.00447680
Iteration 81, loss = 0.00432565
Iteration 82, loss = 0.00430598
Iteration 83, loss = 0.00422410
Iteration 84, loss = 0.00411718
Iteration 85, loss = 0.00404167
Iteration 86, loss = 0.00392413
Iteration 87, loss = 0.00387099
Iteration 88, loss = 0.00373469
Iteration 89, loss = 0.00374421
Iteration 90, loss = 0.00365716
Iteration 91, loss = 0.00359075
Iteration 92, loss = 0.00363037
Iteration 93, loss = 0.00345596
Iteration 94, loss = 0.00339052
Iteration 95, loss = 0.00336403
Iteration 96, loss = 0.00325289
Iteration 97, loss = 0.00323916
Iteration 98, loss = 0.00313500
Iteration 99, loss = 0.00309154
Iteration 100, loss = 0.00302598
Iteration 101, loss = 0.00295704
Iteration 102, loss = 0.00294932
Iteration 103, loss = 0.00286694
Iteration 104, loss = 0.00280068
Iteration 105, loss = 0.00276467
Iteration 106, loss = 0.00273205
Iteration 107, loss = 0.00272412
Iteration 108, loss = 0.00261234
Iteration 109, loss = 0.00259589
Iteration 110, loss = 0.00252868
Iteration 111, loss = 0.00251367
Iteration 112, loss = 0.00246325
Iteration 113, loss = 0.00240696
Iteration 114, loss = 0.00240357
Iteration 115, loss = 0.00234719
Iteration 116, loss = 0.00234631
Iteration 117, loss = 0.00227600
Iteration 118, loss = 0.00223229
Iteration 119, loss = 0.00220791
Iteration 120, loss = 0.00219736
Iteration 121, loss = 0.00213680
Iteration 122, loss = 0.00208060
Iteration 123, loss = 0.00211205
Iteration 124, loss = 0.00199428
Iteration 125, loss = 0.00207110
Iteration 126, loss = 0.00198066
Iteration 127, loss = 0.00192821
Iteration 128, loss = 0.00186878
Iteration 129, loss = 0.00193110
Iteration 130, loss = 0.00183776
Iteration 131, loss = 0.00184121
Iteration 132, loss = 0.00185277
Iteration 133, loss = 0.00177839
Iteration 134, loss = 0.00172836
Iteration 135, loss = 0.00177436
Iteration 136, loss = 0.00173671
Iteration 137, loss = 0.00168863
Iteration 138, loss = 0.00171063
Iteration 139, loss = 0.00164867
Iteration 140, loss = 0.00164095
Iteration 141, loss = 0.00160449
Iteration 142, loss = 0.00163524
Iteration 143, loss = 0.00165191
Iteration 144, loss = 0.00154575
Iteration 145, loss = 0.00151100
Iteration 146, loss = 0.00151196
Iteration 147, loss = 0.00150929
Iteration 148, loss = 0.00146500
Iteration 149, loss = 0.00145848
Iteration 150, loss = 0.00151233
Iteration 151, loss = 0.00145518
Iteration 152, loss = 0.00139006
Iteration 153, loss = 0.00141915
Iteration 154, loss = 0.00138649
Iteration 155, loss = 0.00136833
Iteration 156, loss = 0.00141787
Iteration 157, loss = 0.00137494
Iteration 158, loss = 0.00133942
Iteration 159, loss = 0.00134032
Iteration 160, loss = 0.00132188
Iteration 161, loss = 0.00133435
Iteration 162, loss = 0.00126650
Iteration 163, loss = 0.00125532
Iteration 164, loss = 0.00127436
Iteration 165, loss = 0.00130194
Iteration 166, loss = 0.00119943
Iteration 167, loss = 0.00127622
Iteration 168, loss = 0.00126393
Iteration 169, loss = 0.00121958
Iteration 170, loss = 0.00117786
Iteration 171, loss = 0.00116592
Iteration 172, loss = 0.00117402
Iteration 173, loss = 0.00117210
Iteration 174, loss = 0.00119540
Iteration 175, loss = 0.00120120
Iteration 176, loss = 0.00113268
Iteration 177, loss = 0.00112436
Iteration 178, loss = 0.00111990
Iteration 179, loss = 0.00111218
Iteration 180, loss = 0.00111915
Iteration 181, loss = 0.00113019
Iteration 182, loss = 0.00108085
Iteration 183, loss = 0.00107992
Iteration 184, loss = 0.00113303
Iteration 185, loss = 0.00114682
Iteration 186, loss = 0.00105946
Iteration 187, loss = 0.00105092
Iteration 188, loss = 0.00106498
Iteration 189, loss = 0.00109320
Iteration 190, loss = 0.00106162
Iteration 191, loss = 0.00104007
Iteration 192, loss = 0.00102216
Iteration 193, loss = 0.00108861
Iteration 194, loss = 0.00101942
Iteration 195, loss = 0.00102955
Iteration 196, loss = 0.00100400
Iteration 197, loss = 0.00103680
Iteration 198, loss = 0.00099895
Iteration 199, loss = 0.00102249
Iteration 200, loss = 0.00103931
Iteration 1, loss = 0.17213304
Iteration 2, loss = 0.07002270
Iteration 3, loss = 0.06027267
Iteration 4, loss = 0.05362826
Iteration 5, loss = 0.04704174
Iteration 6, loss = 0.04181978
Iteration 7, loss = 0.03797276
Iteration 8, loss = 0.03497775
Iteration 9, loss = 0.03255190
Iteration 10, loss = 0.03049790
Iteration 11, loss = 0.02866217
Iteration 12, loss = 0.02717194
Iteration 13, loss = 0.02581140
Iteration 14, loss = 0.02474187
Iteration 15, loss = 0.02353502
Iteration 16, loss = 0.02268155
Iteration 17, loss = 0.02168051
Iteration 18, loss = 0.02090866
Iteration 19, loss = 0.02017059
Iteration 20, loss = 0.01957340
Iteration 21, loss = 0.01882038
Iteration 22, loss = 0.01829536
Iteration 23, loss = 0.01765073
Iteration 24, loss = 0.01729452
Iteration 25, loss = 0.01677405
Iteration 26, loss = 0.01627217
Iteration 27, loss = 0.01587613
Iteration 28, loss = 0.01544758
Iteration 29, loss = 0.01503530
Iteration 30, loss = 0.01463643
Iteration 31, loss = 0.01433530
Iteration 32, loss = 0.01401186
Iteration 33, loss = 0.01360710
Iteration 34, loss = 0.01329850
Iteration 35, loss = 0.01298386
Iteration 36, loss = 0.01279509
Iteration 37, loss = 0.01243572
Iteration 38, loss = 0.01215664
Iteration 39, loss = 0.01179076
Iteration 40, loss = 0.01165577
Iteration 41, loss = 0.01127812
Iteration 42, loss = 0.01117384
Iteration 43, loss = 0.01080132
Iteration 44, loss = 0.01056500
Iteration 45, loss = 0.01050801
Iteration 46, loss = 0.01021429
Iteration 47, loss = 0.00999868
Iteration 48, loss = 0.00982402
Iteration 49, loss = 0.00951153
Iteration 50, loss = 0.00943768
Iteration 51, loss = 0.00923715
Iteration 52, loss = 0.00911229
Iteration 53, loss = 0.00896027
Iteration 54, loss = 0.00878125
Iteration 55, loss = 0.00858269
Iteration 56, loss = 0.00852049
Iteration 57, loss = 0.00827747
Iteration 58, loss = 0.00817600
Iteration 59, loss = 0.00800424
Iteration 60, loss = 0.00792531
Iteration 61, loss = 0.00773174
Iteration 62, loss = 0.00769568
Iteration 63, loss = 0.00745660
Iteration 64, loss = 0.00743449
Iteration 65, loss = 0.00730141
Iteration 66, loss = 0.00714238
Iteration 67, loss = 0.00698316
Iteration 68, loss = 0.00679675
Iteration 69, loss = 0.00677804
Iteration 70, loss = 0.00667978
Iteration 71, loss = 0.00661709
Iteration 72, loss = 0.00650828
Iteration 73, loss = 0.00635058
Iteration 74, loss = 0.00627364
Iteration 75, loss = 0.00618562
Iteration 76, loss = 0.00607983
Iteration 77, loss = 0.00597570
Iteration 78, loss = 0.00590219
Iteration 79, loss = 0.00587098
Iteration 80, loss = 0.00571778
Iteration 81, loss = 0.00563096
Iteration 82, loss = 0.00549149
Iteration 83, loss = 0.00536921
Iteration 84, loss = 0.00539826
Iteration 85, loss = 0.00523941
Iteration 86, loss = 0.00514046
Iteration 87, loss = 0.00507153
Iteration 88, loss = 0.00504559
Iteration 89, loss = 0.00501215
Iteration 90, loss = 0.00483171
Iteration 91, loss = 0.00487299
Iteration 92, loss = 0.00480289
Iteration 93, loss = 0.00464859
Iteration 94, loss = 0.00464471
Iteration 95, loss = 0.00457655
Iteration 96, loss = 0.00446776
Iteration 97, loss = 0.00448983
Iteration 98, loss = 0.00436770
Iteration 99, loss = 0.00432874
Iteration 100, loss = 0.00417255
Iteration 101, loss = 0.00417672
Iteration 102, loss = 0.00419626
Iteration 103, loss = 0.00408149
Iteration 104, loss = 0.00393842
Iteration 105, loss = 0.00395806
Iteration 106, loss = 0.00390686
Iteration 107, loss = 0.00383405
Iteration 108, loss = 0.00374919
Iteration 109, loss = 0.00375648
Iteration 110, loss = 0.00369401
Iteration 111, loss = 0.00363938
Iteration 112, loss = 0.00355984
Iteration 113, loss = 0.00348161
Iteration 114, loss = 0.00345995
Iteration 115, loss = 0.00339535
Iteration 116, loss = 0.00335962
Iteration 117, loss = 0.00332392
Iteration 118, loss = 0.00326948
Iteration 119, loss = 0.00317553
Iteration 120, loss = 0.00318491
Iteration 121, loss = 0.00314400
Iteration 122, loss = 0.00305673
Iteration 123, loss = 0.00306835
Iteration 124, loss = 0.00301542
Iteration 125, loss = 0.00290778
Iteration 126, loss = 0.00290140
Iteration 127, loss = 0.00290071
Iteration 128, loss = 0.00280866
Iteration 129, loss = 0.00280543
Iteration 130, loss = 0.00278067
Iteration 131, loss = 0.00270977
Iteration 132, loss = 0.00268957
Iteration 133, loss = 0.00270034
Iteration 134, loss = 0.00255404
Iteration 135, loss = 0.00256692
Iteration 136, loss = 0.00257278
Iteration 137, loss = 0.00253166
Iteration 138, loss = 0.00244222
Iteration 139, loss = 0.00241529
Iteration 140, loss = 0.00246348
Iteration 141, loss = 0.00236636
Iteration 142, loss = 0.00232563
Iteration 143, loss = 0.00230942
Iteration 144, loss = 0.00226926
Iteration 145, loss = 0.00225911
Iteration 146, loss = 0.00226294
Iteration 147, loss = 0.00224638
Iteration 148, loss = 0.00214001
Iteration 149, loss = 0.00222319
Iteration 150, loss = 0.00211700
Iteration 151, loss = 0.00216182
Iteration 152, loss = 0.00208342
Iteration 153, loss = 0.00206571
Iteration 154, loss = 0.00204666
Iteration 155, loss = 0.00201807
Iteration 156, loss = 0.00200251
Iteration 157, loss = 0.00204812
Iteration 158, loss = 0.00194182
Iteration 159, loss = 0.00192607
Iteration 160, loss = 0.00188693
Iteration 161, loss = 0.00193987
Iteration 162, loss = 0.00186784
Iteration 163, loss = 0.00182283
Iteration 164, loss = 0.00182819
Iteration 165, loss = 0.00175465
Iteration 166, loss = 0.00181866
Iteration 167, loss = 0.00178497
Iteration 168, loss = 0.00176962
Iteration 169, loss = 0.00174433
Iteration 170, loss = 0.00168708
Iteration 171, loss = 0.00169188
Iteration 172, loss = 0.00170088
Iteration 173, loss = 0.00167539
Iteration 174, loss = 0.00165650
Iteration 175, loss = 0.00162941
Iteration 176, loss = 0.00162058
Iteration 177, loss = 0.00164324
Iteration 178, loss = 0.00159930
Iteration 179, loss = 0.00162427
Iteration 180, loss = 0.00157747
Iteration 181, loss = 0.00153140
Iteration 182, loss = 0.00154863
Iteration 183, loss = 0.00159056
Iteration 184, loss = 0.00149955
Iteration 185, loss = 0.00155323
Iteration 186, loss = 0.00153709
Iteration 187, loss = 0.00143460
Iteration 188, loss = 0.00146137
Iteration 189, loss = 0.00157341
Iteration 190, loss = 0.00144509
Iteration 191, loss = 0.00145137
Iteration 192, loss = 0.00141800
Iteration 193, loss = 0.00139755
Iteration 194, loss = 0.00137799
Iteration 195, loss = 0.00145764
Iteration 196, loss = 0.00144351
Iteration 197, loss = 0.00141446
Iteration 198, loss = 0.00136638
Iteration 199, loss = 0.00138226
Iteration 200, loss = 0.00136459
Iteration 1, loss = 0.13281187
Iteration 2, loss = 0.06543541
Iteration 3, loss = 0.05603439
Iteration 4, loss = 0.04892521
Iteration 5, loss = 0.04264023
Iteration 6, loss = 0.03786377
Iteration 7, loss = 0.03435720
Iteration 8, loss = 0.03176476
Iteration 9, loss = 0.02972143
Iteration 10, loss = 0.02804531
Iteration 11, loss = 0.02663961
Iteration 12, loss = 0.02547110
Iteration 13, loss = 0.02452302
Iteration 14, loss = 0.02344790
Iteration 15, loss = 0.02256424
Iteration 16, loss = 0.02178116
Iteration 17, loss = 0.02099807
Iteration 18, loss = 0.02039370
Iteration 19, loss = 0.01967940
Iteration 20, loss = 0.01904846
Iteration 21, loss = 0.01857713
Iteration 22, loss = 0.01800544
Iteration 23, loss = 0.01753278
Iteration 24, loss = 0.01707291
Iteration 25, loss = 0.01648179
Iteration 26, loss = 0.01609432
Iteration 27, loss = 0.01572352
Iteration 28, loss = 0.01530601
Iteration 29, loss = 0.01498213
Iteration 30, loss = 0.01467655
Iteration 31, loss = 0.01424680
Iteration 32, loss = 0.01392999
Iteration 33, loss = 0.01369023
Iteration 34, loss = 0.01330655
Iteration 35, loss = 0.01305302
Iteration 36, loss = 0.01276889
Iteration 37, loss = 0.01250634
Iteration 38, loss = 0.01216087
Iteration 39, loss = 0.01184077
Iteration 40, loss = 0.01164923
Iteration 41, loss = 0.01150150
Iteration 42, loss = 0.01122122
Iteration 43, loss = 0.01094154
Iteration 44, loss = 0.01078166
Iteration 45, loss = 0.01065394
Iteration 46, loss = 0.01030774
Iteration 47, loss = 0.01016987
Iteration 48, loss = 0.00996955
Iteration 49, loss = 0.00985422
Iteration 50, loss = 0.00963276
Iteration 51, loss = 0.00945626
Iteration 52, loss = 0.00924209
Iteration 53, loss = 0.00907714
Iteration 54, loss = 0.00892409
Iteration 55, loss = 0.00878269
Iteration 56, loss = 0.00864257
Iteration 57, loss = 0.00841547
Iteration 58, loss = 0.00833583
Iteration 59, loss = 0.00819995
Iteration 60, loss = 0.00805661
Iteration 61, loss = 0.00793322
Iteration 62, loss = 0.00775893
Iteration 63, loss = 0.00758650
Iteration 64, loss = 0.00738593
Iteration 65, loss = 0.00744368
Iteration 66, loss = 0.00723261
Iteration 67, loss = 0.00705386
Iteration 68, loss = 0.00692266
Iteration 69, loss = 0.00696499
Iteration 70, loss = 0.00670321
Iteration 71, loss = 0.00672860
Iteration 72, loss = 0.00651196
Iteration 73, loss = 0.00641697
Iteration 74, loss = 0.00641985
Iteration 75, loss = 0.00624359
Iteration 76, loss = 0.00619062
Iteration 77, loss = 0.00604115
Iteration 78, loss = 0.00594049
Iteration 79, loss = 0.00585801
Iteration 80, loss = 0.00573754
Iteration 81, loss = 0.00559183
Iteration 82, loss = 0.00552412
Iteration 83, loss = 0.00547802
Iteration 84, loss = 0.00538232
Iteration 85, loss = 0.00533391
Iteration 86, loss = 0.00522627
Iteration 87, loss = 0.00517978
Iteration 88, loss = 0.00501904
Iteration 89, loss = 0.00504047
Iteration 90, loss = 0.00486297
Iteration 91, loss = 0.00480253
Iteration 92, loss = 0.00467582
Iteration 93, loss = 0.00461749
Iteration 94, loss = 0.00454723
Iteration 95, loss = 0.00446676
Iteration 96, loss = 0.00445315
Iteration 97, loss = 0.00440064
Iteration 98, loss = 0.00428358
Iteration 99, loss = 0.00420208
Iteration 100, loss = 0.00416712
Iteration 101, loss = 0.00413874
Iteration 102, loss = 0.00409846
Iteration 103, loss = 0.00402380
Iteration 104, loss = 0.00389998
Iteration 105, loss = 0.00385351
Iteration 106, loss = 0.00383699
Iteration 107, loss = 0.00373209
Iteration 108, loss = 0.00366766
Iteration 109, loss = 0.00363168
Iteration 110, loss = 0.00359423
Iteration 111, loss = 0.00356769
Iteration 112, loss = 0.00347519
Iteration 113, loss = 0.00342329
Iteration 114, loss = 0.00340534
Iteration 115, loss = 0.00333707
Iteration 116, loss = 0.00331871
Iteration 117, loss = 0.00320876
Iteration 118, loss = 0.00314848
Iteration 119, loss = 0.00315681
Iteration 120, loss = 0.00310700
Iteration 121, loss = 0.00306794
Iteration 122, loss = 0.00296901
Iteration 123, loss = 0.00297818
Iteration 124, loss = 0.00292900
Iteration 125, loss = 0.00292198
Iteration 126, loss = 0.00284843
Iteration 127, loss = 0.00274733
Iteration 128, loss = 0.00279879
Iteration 129, loss = 0.00272954
Iteration 130, loss = 0.00263772
Iteration 131, loss = 0.00254378
Iteration 132, loss = 0.00255414
Iteration 133, loss = 0.00261510
Iteration 134, loss = 0.00250533
Iteration 135, loss = 0.00250199
Iteration 136, loss = 0.00246163
Iteration 137, loss = 0.00243276
Iteration 138, loss = 0.00240975
Iteration 139, loss = 0.00239734
Iteration 140, loss = 0.00232905
Iteration 141, loss = 0.00230082
Iteration 142, loss = 0.00224376
Iteration 143, loss = 0.00227586
Iteration 144, loss = 0.00219042
Iteration 145, loss = 0.00215367
Iteration 146, loss = 0.00216145
Iteration 147, loss = 0.00221350
Iteration 148, loss = 0.00210144
Iteration 149, loss = 0.00206332
Iteration 150, loss = 0.00211108
Iteration 151, loss = 0.00197833
Iteration 152, loss = 0.00196649
Iteration 153, loss = 0.00194924
Iteration 154, loss = 0.00195569
Iteration 155, loss = 0.00191097
Iteration 156, loss = 0.00192156
Iteration 157, loss = 0.00194308
Iteration 158, loss = 0.00181632
Iteration 159, loss = 0.00182398
Iteration 160, loss = 0.00184847
Iteration 161, loss = 0.00180308
Iteration 162, loss = 0.00180079
Iteration 163, loss = 0.00177329
Iteration 164, loss = 0.00176949
Iteration 165, loss = 0.00169442
Iteration 166, loss = 0.00165329
Iteration 167, loss = 0.00173743
Iteration 168, loss = 0.00164666
Iteration 169, loss = 0.00164940
Iteration 170, loss = 0.00167658
Iteration 171, loss = 0.00166273
Iteration 172, loss = 0.00160902
Iteration 173, loss = 0.00161718
Iteration 174, loss = 0.00154068
Iteration 175, loss = 0.00152402
Iteration 176, loss = 0.00150844
Iteration 177, loss = 0.00157559
Iteration 178, loss = 0.00151935
Iteration 179, loss = 0.00150933
Iteration 180, loss = 0.00149871
Iteration 181, loss = 0.00148366
Iteration 182, loss = 0.00148188
Iteration 183, loss = 0.00144374
Iteration 184, loss = 0.00144973
Iteration 185, loss = 0.00140904
Iteration 186, loss = 0.00146523
Iteration 187, loss = 0.00142575
Iteration 188, loss = 0.00143448
Iteration 189, loss = 0.00135938
Iteration 190, loss = 0.00136185
Iteration 191, loss = 0.00132594
Iteration 192, loss = 0.00134342
Iteration 193, loss = 0.00135429
Iteration 194, loss = 0.00132268
Iteration 195, loss = 0.00127721
Iteration 196, loss = 0.00132985
Iteration 197, loss = 0.00133566
Iteration 198, loss = 0.00134846
Iteration 199, loss = 0.00124326
Iteration 200, loss = 0.00122009
Iteration 1, loss = 0.14352005
Iteration 2, loss = 0.06507350
Iteration 3, loss = 0.05449773
Iteration 4, loss = 0.04696328
Iteration 5, loss = 0.04135061
Iteration 6, loss = 0.03696615
Iteration 7, loss = 0.03373924
Iteration 8, loss = 0.03100239
Iteration 9, loss = 0.02892446
Iteration 10, loss = 0.02717053
Iteration 11, loss = 0.02567113
Iteration 12, loss = 0.02430590
Iteration 13, loss = 0.02311620
Iteration 14, loss = 0.02204215
Iteration 15, loss = 0.02102907
Iteration 16, loss = 0.02024071
Iteration 17, loss = 0.01934967
Iteration 18, loss = 0.01857130
Iteration 19, loss = 0.01801287
Iteration 20, loss = 0.01733775
Iteration 21, loss = 0.01676449
Iteration 22, loss = 0.01607724
Iteration 23, loss = 0.01557553
Iteration 24, loss = 0.01513919
Iteration 25, loss = 0.01469108
Iteration 26, loss = 0.01429489
Iteration 27, loss = 0.01383275
Iteration 28, loss = 0.01335251
Iteration 29, loss = 0.01308388
Iteration 30, loss = 0.01265815
Iteration 31, loss = 0.01233322
Iteration 32, loss = 0.01197758
Iteration 33, loss = 0.01174331
Iteration 34, loss = 0.01138826
Iteration 35, loss = 0.01107075
Iteration 36, loss = 0.01091487
Iteration 37, loss = 0.01052759
Iteration 38, loss = 0.01027709
Iteration 39, loss = 0.00995378
Iteration 40, loss = 0.00979131
Iteration 41, loss = 0.00954603
Iteration 42, loss = 0.00923197
Iteration 43, loss = 0.00902881
Iteration 44, loss = 0.00885853
Iteration 45, loss = 0.00852706
Iteration 46, loss = 0.00841586
Iteration 47, loss = 0.00813731
Iteration 48, loss = 0.00807800
Iteration 49, loss = 0.00776150
Iteration 50, loss = 0.00759275
Iteration 51, loss = 0.00751846
Iteration 52, loss = 0.00732989
Iteration 53, loss = 0.00712435
Iteration 54, loss = 0.00697666
Iteration 55, loss = 0.00685218
Iteration 56, loss = 0.00668620
Iteration 57, loss = 0.00648792
Iteration 58, loss = 0.00630089
Iteration 59, loss = 0.00620241
Iteration 60, loss = 0.00615010
Iteration 61, loss = 0.00591502
Iteration 62, loss = 0.00573742
Iteration 63, loss = 0.00559901
Iteration 64, loss = 0.00549715
Iteration 65, loss = 0.00538015
Iteration 66, loss = 0.00528390
Iteration 67, loss = 0.00511952
Iteration 68, loss = 0.00515132
Iteration 69, loss = 0.00492671
Iteration 70, loss = 0.00487663
Iteration 71, loss = 0.00470201
Iteration 72, loss = 0.00458898
Iteration 73, loss = 0.00447835
Iteration 74, loss = 0.00445816
Iteration 75, loss = 0.00423930
Iteration 76, loss = 0.00416248
Iteration 77, loss = 0.00421442
Iteration 78, loss = 0.00413936
Iteration 79, loss = 0.00402625
Iteration 80, loss = 0.00383763
Iteration 81, loss = 0.00384143
Iteration 82, loss = 0.00374072
Iteration 83, loss = 0.00367534
Iteration 84, loss = 0.00356926
Iteration 85, loss = 0.00343223
Iteration 86, loss = 0.00343594
Iteration 87, loss = 0.00338641
Iteration 88, loss = 0.00330495
Iteration 89, loss = 0.00322618
Iteration 90, loss = 0.00313261
Iteration 91, loss = 0.00307151
Iteration 92, loss = 0.00311787
Iteration 93, loss = 0.00293168
Iteration 94, loss = 0.00296339
Iteration 95, loss = 0.00283544
Iteration 96, loss = 0.00278208
Iteration 97, loss = 0.00273729
Iteration 98, loss = 0.00272198
Iteration 99, loss = 0.00260329
Iteration 100, loss = 0.00263166
Iteration 101, loss = 0.00257004
Iteration 102, loss = 0.00248012
Iteration 103, loss = 0.00246247
Iteration 104, loss = 0.00236748
Iteration 105, loss = 0.00241801
Iteration 106, loss = 0.00222387
Iteration 107, loss = 0.00231895
Iteration 108, loss = 0.00223504
Iteration 109, loss = 0.00220102
Iteration 110, loss = 0.00222373
Iteration 111, loss = 0.00211736
Iteration 112, loss = 0.00202759
Iteration 113, loss = 0.00198924
Iteration 114, loss = 0.00199219
Iteration 115, loss = 0.00195319
Iteration 116, loss = 0.00194149
Iteration 117, loss = 0.00197050
Iteration 118, loss = 0.00187958
Iteration 119, loss = 0.00182959
Iteration 120, loss = 0.00180501
Iteration 121, loss = 0.00181474
Iteration 122, loss = 0.00170054
Iteration 123, loss = 0.00172427
Iteration 124, loss = 0.00168736
Iteration 125, loss = 0.00168559
Iteration 126, loss = 0.00166565
Iteration 127, loss = 0.00161194
Iteration 128, loss = 0.00161927
Iteration 129, loss = 0.00151265
Iteration 130, loss = 0.00153101
Iteration 131, loss = 0.00157546
Iteration 132, loss = 0.00151963
Iteration 133, loss = 0.00149457
Iteration 134, loss = 0.00148720
Iteration 135, loss = 0.00143802
Iteration 136, loss = 0.00141563
Iteration 137, loss = 0.00148434
Iteration 138, loss = 0.00136473
Iteration 139, loss = 0.00142455
Iteration 140, loss = 0.00131038
Iteration 141, loss = 0.00131162
Iteration 142, loss = 0.00131472
Iteration 143, loss = 0.00128561
Iteration 144, loss = 0.00131806
Iteration 145, loss = 0.00129453
Iteration 146, loss = 0.00126474
Iteration 147, loss = 0.00125105
Iteration 148, loss = 0.00121865
Iteration 149, loss = 0.00124573
Iteration 150, loss = 0.00123207
Iteration 151, loss = 0.00123911
Iteration 152, loss = 0.00119852
Iteration 153, loss = 0.00118804
Iteration 154, loss = 0.00113299
Iteration 155, loss = 0.00116803
Iteration 156, loss = 0.00116487
Iteration 157, loss = 0.00113445
Iteration 158, loss = 0.00112092
Iteration 159, loss = 0.00113635
Iteration 160, loss = 0.00110636
Iteration 161, loss = 0.00113803
Iteration 162, loss = 0.00110771
Iteration 163, loss = 0.00105750
Iteration 164, loss = 0.00104205
Iteration 165, loss = 0.00109738
Iteration 166, loss = 0.00111573
Iteration 167, loss = 0.00106851
Iteration 168, loss = 0.00104025
Iteration 169, loss = 0.00103713
Iteration 170, loss = 0.00100111
Iteration 171, loss = 0.00102400
Iteration 172, loss = 0.00101795
Iteration 173, loss = 0.00102782
Iteration 174, loss = 0.00106258
Iteration 175, loss = 0.00107278
Iteration 176, loss = 0.00097775
Iteration 177, loss = 0.00096628
Iteration 178, loss = 0.00096699
Iteration 179, loss = 0.00100289
Iteration 180, loss = 0.00101385
Iteration 181, loss = 0.00095637
Iteration 182, loss = 0.00097079
Iteration 183, loss = 0.00098809
Iteration 184, loss = 0.00098915
Iteration 185, loss = 0.00100446
Iteration 186, loss = 0.00097119
Iteration 187, loss = 0.00090793
Iteration 188, loss = 0.00091122
Iteration 189, loss = 0.00093582
Iteration 190, loss = 0.00105216
Iteration 191, loss = 0.00091792
Iteration 192, loss = 0.00092921
Iteration 193, loss = 0.00092476
Iteration 194, loss = 0.00090342
Iteration 195, loss = 0.00091938
Iteration 196, loss = 0.00094511
Iteration 197, loss = 0.00097909
Iteration 198, loss = 0.00094107
Iteration 199, loss = 0.00087111
Iteration 200, loss = 0.00088242
Iteration 1, loss = 0.14557993
Iteration 2, loss = 0.06477885
Iteration 3, loss = 0.05394278
Iteration 4, loss = 0.04699595
Iteration 5, loss = 0.04177094
Iteration 6, loss = 0.03772850
Iteration 7, loss = 0.03433336
Iteration 8, loss = 0.03161157
Iteration 9, loss = 0.02919109
Iteration 10, loss = 0.02723585
Iteration 11, loss = 0.02557428
Iteration 12, loss = 0.02404089
Iteration 13, loss = 0.02277786
Iteration 14, loss = 0.02172963
Iteration 15, loss = 0.02065624
Iteration 16, loss = 0.01971517
Iteration 17, loss = 0.01901785
Iteration 18, loss = 0.01828144
Iteration 19, loss = 0.01756223
Iteration 20, loss = 0.01699688
Iteration 21, loss = 0.01643821
Iteration 22, loss = 0.01586460
Iteration 23, loss = 0.01539556
Iteration 24, loss = 0.01488564
Iteration 25, loss = 0.01440443
Iteration 26, loss = 0.01390792
Iteration 27, loss = 0.01359867
Iteration 28, loss = 0.01314852
Iteration 29, loss = 0.01268108
Iteration 30, loss = 0.01243433
Iteration 31, loss = 0.01209647
Iteration 32, loss = 0.01172406
Iteration 33, loss = 0.01131387
Iteration 34, loss = 0.01093866
Iteration 35, loss = 0.01073023
Iteration 36, loss = 0.01046441
Iteration 37, loss = 0.01025594
Iteration 38, loss = 0.00987407
Iteration 39, loss = 0.00965796
Iteration 40, loss = 0.00946387
Iteration 41, loss = 0.00921806
Iteration 42, loss = 0.00881901
Iteration 43, loss = 0.00869471
Iteration 44, loss = 0.00851407
Iteration 45, loss = 0.00835100
Iteration 46, loss = 0.00801943
Iteration 47, loss = 0.00792299
Iteration 48, loss = 0.00772421
Iteration 49, loss = 0.00760840
Iteration 50, loss = 0.00737079
Iteration 51, loss = 0.00719912
Iteration 52, loss = 0.00694974
Iteration 53, loss = 0.00682319
Iteration 54, loss = 0.00661369
Iteration 55, loss = 0.00654543
Iteration 56, loss = 0.00633519
Iteration 57, loss = 0.00613026
Iteration 58, loss = 0.00601787
Iteration 59, loss = 0.00601218
Iteration 60, loss = 0.00580618
Iteration 61, loss = 0.00562322
Iteration 62, loss = 0.00554037
Iteration 63, loss = 0.00536247
Iteration 64, loss = 0.00521882
Iteration 65, loss = 0.00511932
Iteration 66, loss = 0.00497263
Iteration 67, loss = 0.00492696
Iteration 68, loss = 0.00480134
Iteration 69, loss = 0.00469697
Iteration 70, loss = 0.00456451
Iteration 71, loss = 0.00446766
Iteration 72, loss = 0.00444038
Iteration 73, loss = 0.00432148
Iteration 74, loss = 0.00425121
Iteration 75, loss = 0.00424641
Iteration 76, loss = 0.00401435
Iteration 77, loss = 0.00397645
Iteration 78, loss = 0.00378495
Iteration 79, loss = 0.00376235
Iteration 80, loss = 0.00367865
Iteration 81, loss = 0.00363827
Iteration 82, loss = 0.00359706
Iteration 83, loss = 0.00344110
Iteration 84, loss = 0.00337753
Iteration 85, loss = 0.00341871
Iteration 86, loss = 0.00323374
Iteration 87, loss = 0.00318248
Iteration 88, loss = 0.00315852
Iteration 89, loss = 0.00299238
Iteration 90, loss = 0.00301936
Iteration 91, loss = 0.00291752
Iteration 92, loss = 0.00284423
Iteration 93, loss = 0.00291673
Iteration 94, loss = 0.00279855
Iteration 95, loss = 0.00272690
Iteration 96, loss = 0.00263012
Iteration 97, loss = 0.00256269
Iteration 98, loss = 0.00264053
Iteration 99, loss = 0.00249164
Iteration 100, loss = 0.00243845
Iteration 101, loss = 0.00248258
Iteration 102, loss = 0.00234994
Iteration 103, loss = 0.00232903
Iteration 104, loss = 0.00226462
Iteration 105, loss = 0.00232105
Iteration 106, loss = 0.00220829
Iteration 107, loss = 0.00218972
Iteration 108, loss = 0.00216781
Iteration 109, loss = 0.00215726
Iteration 110, loss = 0.00202011
Iteration 111, loss = 0.00208365
Iteration 112, loss = 0.00194154
Iteration 113, loss = 0.00195894
Iteration 114, loss = 0.00187883
Iteration 115, loss = 0.00190698
Iteration 116, loss = 0.00178946
Iteration 117, loss = 0.00187275
Iteration 118, loss = 0.00180440
Iteration 119, loss = 0.00172321
Iteration 120, loss = 0.00173825
Iteration 121, loss = 0.00173224
Iteration 122, loss = 0.00172168
Iteration 123, loss = 0.00165133
Iteration 124, loss = 0.00158049
Iteration 125, loss = 0.00160679
Iteration 126, loss = 0.00158213
Iteration 127, loss = 0.00152516
Iteration 128, loss = 0.00149388
Iteration 129, loss = 0.00160393
Iteration 130, loss = 0.00147611
Iteration 131, loss = 0.00149422
Iteration 132, loss = 0.00143646
Iteration 133, loss = 0.00145786
Iteration 134, loss = 0.00143959
Iteration 135, loss = 0.00136053
Iteration 136, loss = 0.00138797
Iteration 137, loss = 0.00138470
Iteration 138, loss = 0.00135044
Iteration 139, loss = 0.00131565
Iteration 140, loss = 0.00127279
Iteration 141, loss = 0.00128939
Iteration 142, loss = 0.00131122
Iteration 143, loss = 0.00127158
Iteration 144, loss = 0.00122883
Iteration 145, loss = 0.00125869
Iteration 146, loss = 0.00124355
Iteration 147, loss = 0.00127485
Iteration 148, loss = 0.00122971
Iteration 149, loss = 0.00122051
Iteration 150, loss = 0.00120887
Iteration 151, loss = 0.00114376
Iteration 152, loss = 0.00116027
Iteration 153, loss = 0.00118261
Iteration 154, loss = 0.00114447
Iteration 155, loss = 0.00109418
Iteration 156, loss = 0.00114954
Iteration 157, loss = 0.00112885
Iteration 158, loss = 0.00107299
Iteration 159, loss = 0.00108576
Iteration 160, loss = 0.00107741
Iteration 161, loss = 0.00111679
Iteration 162, loss = 0.00106948
Iteration 163, loss = 0.00107760
Iteration 164, loss = 0.00101804
Iteration 165, loss = 0.00105357
Iteration 166, loss = 0.00103211
Iteration 167, loss = 0.00102841
Iteration 168, loss = 0.00106705
Iteration 169, loss = 0.00108136
Iteration 170, loss = 0.00104682
Iteration 171, loss = 0.00099757
Iteration 172, loss = 0.00096591
Iteration 173, loss = 0.00102393
Iteration 174, loss = 0.00098623
Iteration 175, loss = 0.00098850
Iteration 176, loss = 0.00099096
Iteration 177, loss = 0.00099862
Iteration 178, loss = 0.00096217
Iteration 179, loss = 0.00097832
Iteration 180, loss = 0.00096402
Iteration 181, loss = 0.00099867
Iteration 182, loss = 0.00092462
Iteration 183, loss = 0.00092695
Iteration 184, loss = 0.00097846
Iteration 185, loss = 0.00095989
Iteration 186, loss = 0.00091128
Iteration 187, loss = 0.00096276
Iteration 188, loss = 0.00099131
Iteration 189, loss = 0.00090646
Iteration 190, loss = 0.00090352
Iteration 191, loss = 0.00090213
Iteration 192, loss = 0.00114050
Iteration 193, loss = 0.00091215
Iteration 194, loss = 0.00086465
Iteration 195, loss = 0.00086084
Iteration 196, loss = 0.00087239
Iteration 197, loss = 0.00091186
Iteration 198, loss = 0.00090279
Iteration 199, loss = 0.00090242
Iteration 200, loss = 0.00090368
Iteration 1, loss = 0.14722372
Iteration 2, loss = 0.06497539
Iteration 3, loss = 0.05498234
Iteration 4, loss = 0.04772096
Iteration 5, loss = 0.04178697
Iteration 6, loss = 0.03726865
Iteration 7, loss = 0.03374909
Iteration 8, loss = 0.03093681
Iteration 9, loss = 0.02860093
Iteration 10, loss = 0.02682407
Iteration 11, loss = 0.02523288
Iteration 12, loss = 0.02388227
Iteration 13, loss = 0.02276789
Iteration 14, loss = 0.02171766
Iteration 15, loss = 0.02082674
Iteration 16, loss = 0.02003070
Iteration 17, loss = 0.01930623
Iteration 18, loss = 0.01849292
Iteration 19, loss = 0.01800062
Iteration 20, loss = 0.01730940
Iteration 21, loss = 0.01685635
Iteration 22, loss = 0.01615994
Iteration 23, loss = 0.01572820
Iteration 24, loss = 0.01525812
Iteration 25, loss = 0.01482463
Iteration 26, loss = 0.01430578
Iteration 27, loss = 0.01405689
Iteration 28, loss = 0.01364888
Iteration 29, loss = 0.01310341
Iteration 30, loss = 0.01286335
Iteration 31, loss = 0.01252730
Iteration 32, loss = 0.01225126
Iteration 33, loss = 0.01201572
Iteration 34, loss = 0.01160904
Iteration 35, loss = 0.01116829
Iteration 36, loss = 0.01102056
Iteration 37, loss = 0.01076695
Iteration 38, loss = 0.01048320
Iteration 39, loss = 0.01022813
Iteration 40, loss = 0.01000864
Iteration 41, loss = 0.00968512
Iteration 42, loss = 0.00955442
Iteration 43, loss = 0.00941094
Iteration 44, loss = 0.00918298
Iteration 45, loss = 0.00884271
Iteration 46, loss = 0.00865194
Iteration 47, loss = 0.00849497
Iteration 48, loss = 0.00830708
Iteration 49, loss = 0.00793149
Iteration 50, loss = 0.00791831
Iteration 51, loss = 0.00766302
Iteration 52, loss = 0.00753545
Iteration 53, loss = 0.00727830
Iteration 54, loss = 0.00730581
Iteration 55, loss = 0.00702335
Iteration 56, loss = 0.00691740
Iteration 57, loss = 0.00673940
Iteration 58, loss = 0.00653577
Iteration 59, loss = 0.00636426
Iteration 60, loss = 0.00621138
Iteration 61, loss = 0.00608003
Iteration 62, loss = 0.00601132
Iteration 63, loss = 0.00590470
Iteration 64, loss = 0.00568343
Iteration 65, loss = 0.00558511
Iteration 66, loss = 0.00537558
Iteration 67, loss = 0.00536081
Iteration 68, loss = 0.00523894
Iteration 69, loss = 0.00515537
Iteration 70, loss = 0.00500244
Iteration 71, loss = 0.00489802
Iteration 72, loss = 0.00478292
Iteration 73, loss = 0.00478325
Iteration 74, loss = 0.00468778
Iteration 75, loss = 0.00449184
Iteration 76, loss = 0.00436732
Iteration 77, loss = 0.00430457
Iteration 78, loss = 0.00420184
Iteration 79, loss = 0.00409276
Iteration 80, loss = 0.00404491
Iteration 81, loss = 0.00407915
Iteration 82, loss = 0.00390501
Iteration 83, loss = 0.00381211
Iteration 84, loss = 0.00364184
Iteration 85, loss = 0.00369823
Iteration 86, loss = 0.00352032
Iteration 87, loss = 0.00354257
Iteration 88, loss = 0.00349720
Iteration 89, loss = 0.00329718
Iteration 90, loss = 0.00324836
Iteration 91, loss = 0.00320163
Iteration 92, loss = 0.00311135
Iteration 93, loss = 0.00308158
Iteration 94, loss = 0.00301672
Iteration 95, loss = 0.00294240
Iteration 96, loss = 0.00293766
Iteration 97, loss = 0.00283106
Iteration 98, loss = 0.00282495
Iteration 99, loss = 0.00273932
Iteration 100, loss = 0.00268055
Iteration 101, loss = 0.00269890
Iteration 102, loss = 0.00264346
Iteration 103, loss = 0.00249592
Iteration 104, loss = 0.00248487
Iteration 105, loss = 0.00242251
Iteration 106, loss = 0.00239042
Iteration 107, loss = 0.00236214
Iteration 108, loss = 0.00237369
Iteration 109, loss = 0.00227526
Iteration 110, loss = 0.00218479
Iteration 111, loss = 0.00218043
Iteration 112, loss = 0.00217577
Iteration 113, loss = 0.00209067
Iteration 114, loss = 0.00215071
Iteration 115, loss = 0.00201945
Iteration 116, loss = 0.00199585
Iteration 117, loss = 0.00192774
Iteration 118, loss = 0.00205202
Iteration 119, loss = 0.00188474
Iteration 120, loss = 0.00186300
Iteration 121, loss = 0.00182099
Iteration 122, loss = 0.00179859
Iteration 123, loss = 0.00177162
Iteration 124, loss = 0.00176806
Iteration 125, loss = 0.00172397
Iteration 126, loss = 0.00172596
Iteration 127, loss = 0.00177031
Iteration 128, loss = 0.00169720
Iteration 129, loss = 0.00160126
Iteration 130, loss = 0.00161735
Iteration 131, loss = 0.00154730
Iteration 132, loss = 0.00157538
Iteration 133, loss = 0.00156474
Iteration 134, loss = 0.00152608
Iteration 135, loss = 0.00147010
Iteration 136, loss = 0.00148311
Iteration 137, loss = 0.00157219
Iteration 138, loss = 0.00144556
Iteration 139, loss = 0.00138021
Iteration 140, loss = 0.00137677
Iteration 141, loss = 0.00143488
Iteration 142, loss = 0.00141404
Iteration 143, loss = 0.00133082
Iteration 144, loss = 0.00131314
Iteration 145, loss = 0.00132688
Iteration 146, loss = 0.00137740
Iteration 147, loss = 0.00129106
Iteration 148, loss = 0.00131749
Iteration 149, loss = 0.00124378
Iteration 150, loss = 0.00127724
Iteration 151, loss = 0.00122669
Iteration 152, loss = 0.00124091
Iteration 153, loss = 0.00121848
Iteration 154, loss = 0.00121179
Iteration 155, loss = 0.00120626
Iteration 156, loss = 0.00119536
Iteration 157, loss = 0.00117146
Iteration 158, loss = 0.00115800
Iteration 159, loss = 0.00115343
Iteration 160, loss = 0.00117147
Iteration 161, loss = 0.00114869
Iteration 162, loss = 0.00113217
Iteration 163, loss = 0.00110943
Iteration 164, loss = 0.00111322
Iteration 165, loss = 0.00112171
Iteration 166, loss = 0.00112239
Iteration 167, loss = 0.00106716
Iteration 168, loss = 0.00110312
Iteration 169, loss = 0.00106059
Iteration 170, loss = 0.00106641
Iteration 171, loss = 0.00110632
Iteration 172, loss = 0.00115628
Iteration 173, loss = 0.00102546
Iteration 174, loss = 0.00105041
Iteration 175, loss = 0.00104100
Iteration 176, loss = 0.00104850
Iteration 177, loss = 0.00100344
Iteration 178, loss = 0.00101537
Iteration 179, loss = 0.00101120
Iteration 180, loss = 0.00099722
Iteration 181, loss = 0.00116328
Iteration 182, loss = 0.00110390
Iteration 183, loss = 0.00099086
Iteration 184, loss = 0.00095358
Iteration 185, loss = 0.00097665
Iteration 186, loss = 0.00094995
Iteration 187, loss = 0.00099274
Iteration 188, loss = 0.00103240
Iteration 189, loss = 0.00098530
Iteration 190, loss = 0.00097505
Iteration 191, loss = 0.00093967
Iteration 192, loss = 0.00095912
Iteration 193, loss = 0.00097318
Iteration 194, loss = 0.00097758
Iteration 195, loss = 0.00093367
Iteration 196, loss = 0.00093329
Iteration 197, loss = 0.00093606
Iteration 198, loss = 0.00099630
Iteration 199, loss = 0.00126745
Iteration 200, loss = 0.00092524
Iteration 1, loss = 0.13655558
Iteration 2, loss = 0.06423381
Iteration 3, loss = 0.05468224
Iteration 4, loss = 0.04703902
Iteration 5, loss = 0.04137791
Iteration 6, loss = 0.03697712
Iteration 7, loss = 0.03346797
Iteration 8, loss = 0.03065089
Iteration 9, loss = 0.02829730
Iteration 10, loss = 0.02650659
Iteration 11, loss = 0.02484377
Iteration 12, loss = 0.02338614
Iteration 13, loss = 0.02217334
Iteration 14, loss = 0.02100194
Iteration 15, loss = 0.02005707
Iteration 16, loss = 0.01918640
Iteration 17, loss = 0.01847162
Iteration 18, loss = 0.01757130
Iteration 19, loss = 0.01679248
Iteration 20, loss = 0.01624251
Iteration 21, loss = 0.01554272
Iteration 22, loss = 0.01505980
Iteration 23, loss = 0.01443714
Iteration 24, loss = 0.01388728
Iteration 25, loss = 0.01352763
Iteration 26, loss = 0.01296260
Iteration 27, loss = 0.01260244
Iteration 28, loss = 0.01215962
Iteration 29, loss = 0.01167575
Iteration 30, loss = 0.01140246
Iteration 31, loss = 0.01099046
Iteration 32, loss = 0.01066249
Iteration 33, loss = 0.01029972
Iteration 34, loss = 0.01004810
Iteration 35, loss = 0.00975251
Iteration 36, loss = 0.00943365
Iteration 37, loss = 0.00908312
Iteration 38, loss = 0.00894482
Iteration 39, loss = 0.00863016
Iteration 40, loss = 0.00839875
Iteration 41, loss = 0.00809794
Iteration 42, loss = 0.00793589
Iteration 43, loss = 0.00764285
Iteration 44, loss = 0.00744409
Iteration 45, loss = 0.00729061
Iteration 46, loss = 0.00704415
Iteration 47, loss = 0.00689197
Iteration 48, loss = 0.00665218
Iteration 49, loss = 0.00648479
Iteration 50, loss = 0.00642413
Iteration 51, loss = 0.00624921
Iteration 52, loss = 0.00597984
Iteration 53, loss = 0.00596157
Iteration 54, loss = 0.00572014
Iteration 55, loss = 0.00560664
Iteration 56, loss = 0.00544825
Iteration 57, loss = 0.00524956
Iteration 58, loss = 0.00516347
Iteration 59, loss = 0.00502827
Iteration 60, loss = 0.00490392
Iteration 61, loss = 0.00477018
Iteration 62, loss = 0.00470089
Iteration 63, loss = 0.00455501
Iteration 64, loss = 0.00442901
Iteration 65, loss = 0.00444381
Iteration 66, loss = 0.00420350
Iteration 67, loss = 0.00414971
Iteration 68, loss = 0.00402869
Iteration 69, loss = 0.00400505
Iteration 70, loss = 0.00381166
Iteration 71, loss = 0.00379247
Iteration 72, loss = 0.00371112
Iteration 73, loss = 0.00357801
Iteration 74, loss = 0.00351436
Iteration 75, loss = 0.00348804
Iteration 76, loss = 0.00335943
Iteration 77, loss = 0.00328830
Iteration 78, loss = 0.00313967
Iteration 79, loss = 0.00307417
Iteration 80, loss = 0.00306278
Iteration 81, loss = 0.00300227
Iteration 82, loss = 0.00293678
Iteration 83, loss = 0.00279528
Iteration 84, loss = 0.00277759
Iteration 85, loss = 0.00275261
Iteration 86, loss = 0.00265866
Iteration 87, loss = 0.00263171
Iteration 88, loss = 0.00253190
Iteration 89, loss = 0.00247184
Iteration 90, loss = 0.00242192
Iteration 91, loss = 0.00232960
Iteration 92, loss = 0.00233399
Iteration 93, loss = 0.00234886
Iteration 94, loss = 0.00229002
Iteration 95, loss = 0.00218386
Iteration 96, loss = 0.00213540
Iteration 97, loss = 0.00204950
Iteration 98, loss = 0.00205073
Iteration 99, loss = 0.00206388
Iteration 100, loss = 0.00195895
Iteration 101, loss = 0.00192497
Iteration 102, loss = 0.00188082
Iteration 103, loss = 0.00194171
Iteration 104, loss = 0.00180585
Iteration 105, loss = 0.00176769
Iteration 106, loss = 0.00176096
Iteration 107, loss = 0.00170659
Iteration 108, loss = 0.00165978
Iteration 109, loss = 0.00166457
Iteration 110, loss = 0.00165565
Iteration 111, loss = 0.00160325
Iteration 112, loss = 0.00163564
Iteration 113, loss = 0.00153813
Iteration 114, loss = 0.00150926
Iteration 115, loss = 0.00151345
Iteration 116, loss = 0.00149488
Iteration 117, loss = 0.00147714
Iteration 118, loss = 0.00145064
Iteration 119, loss = 0.00136803
Iteration 120, loss = 0.00139977
Iteration 121, loss = 0.00136171
Iteration 122, loss = 0.00135528
Iteration 123, loss = 0.00134384
Iteration 124, loss = 0.00134770
Iteration 125, loss = 0.00133118
Iteration 126, loss = 0.00129653
Iteration 127, loss = 0.00127218
Iteration 128, loss = 0.00126869
Iteration 129, loss = 0.00122886
Iteration 130, loss = 0.00124716
Iteration 131, loss = 0.00120979
Iteration 132, loss = 0.00116673
Iteration 133, loss = 0.00121339
Iteration 134, loss = 0.00125081
Iteration 135, loss = 0.00115179
Iteration 136, loss = 0.00113459
Iteration 137, loss = 0.00109439
Iteration 138, loss = 0.00119322
Iteration 139, loss = 0.00114564
Iteration 140, loss = 0.00111210
Iteration 141, loss = 0.00106004
Iteration 142, loss = 0.00108513
Iteration 143, loss = 0.00119584
Iteration 144, loss = 0.00109839
Iteration 145, loss = 0.00105715
Iteration 146, loss = 0.00109038
Iteration 147, loss = 0.00105003
Iteration 148, loss = 0.00103519
Iteration 149, loss = 0.00101549
Iteration 150, loss = 0.00102316
Iteration 151, loss = 0.00103652
Iteration 152, loss = 0.00103613
Iteration 153, loss = 0.00099381
Iteration 154, loss = 0.00101884
Iteration 155, loss = 0.00103890
Iteration 156, loss = 0.00101706
Iteration 157, loss = 0.00099398
Iteration 158, loss = 0.00104737
Iteration 159, loss = 0.00097763
Iteration 160, loss = 0.00094290
Iteration 161, loss = 0.00096248
Iteration 162, loss = 0.00096204
Iteration 163, loss = 0.00096558
Iteration 164, loss = 0.00098352
Iteration 165, loss = 0.00095644
Iteration 166, loss = 0.00093448
Iteration 167, loss = 0.00093990
Iteration 168, loss = 0.00096822
Iteration 169, loss = 0.00099871
Iteration 170, loss = 0.00092245
Iteration 171, loss = 0.00090635
Iteration 172, loss = 0.00094068
Iteration 173, loss = 0.00092334
Iteration 174, loss = 0.00091596
Iteration 175, loss = 0.00108225
Iteration 176, loss = 0.00087582
Iteration 177, loss = 0.00087136
Iteration 178, loss = 0.00087274
Iteration 179, loss = 0.00087675
Iteration 180, loss = 0.00098697
Iteration 181, loss = 0.00102520
Iteration 182, loss = 0.00088006
Iteration 183, loss = 0.00085164
Iteration 184, loss = 0.00084581
Iteration 185, loss = 0.00086756
Iteration 186, loss = 0.00115901
Iteration 187, loss = 0.00087501
Iteration 188, loss = 0.00085725
Iteration 189, loss = 0.00083828
Iteration 190, loss = 0.00084202
Iteration 191, loss = 0.00083467
Iteration 192, loss = 0.00100980
Iteration 193, loss = 0.00097317
Iteration 194, loss = 0.00084672
Iteration 195, loss = 0.00082913
Iteration 196, loss = 0.00083191
Iteration 197, loss = 0.00083306
Iteration 198, loss = 0.00085359
Iteration 199, loss = 0.00095054
Iteration 200, loss = 0.00108197
Iteration 1, loss = 0.13563511
Iteration 2, loss = 0.06350523
Iteration 3, loss = 0.05383304
Iteration 4, loss = 0.04564765
Iteration 5, loss = 0.03958677
Iteration 6, loss = 0.03530711
Iteration 7, loss = 0.03198260
Iteration 8, loss = 0.02941261
Iteration 9, loss = 0.02715262
Iteration 10, loss = 0.02541639
Iteration 11, loss = 0.02373259
Iteration 12, loss = 0.02244463
Iteration 13, loss = 0.02111053
Iteration 14, loss = 0.02000320
Iteration 15, loss = 0.01919255
Iteration 16, loss = 0.01832243
Iteration 17, loss = 0.01741579
Iteration 18, loss = 0.01675133
Iteration 19, loss = 0.01600813
Iteration 20, loss = 0.01528214
Iteration 21, loss = 0.01479958
Iteration 22, loss = 0.01423514
Iteration 23, loss = 0.01363180
Iteration 24, loss = 0.01312102
Iteration 25, loss = 0.01268035
Iteration 26, loss = 0.01226221
Iteration 27, loss = 0.01175516
Iteration 28, loss = 0.01147105
Iteration 29, loss = 0.01110837
Iteration 30, loss = 0.01060863
Iteration 31, loss = 0.01029801
Iteration 32, loss = 0.01003173
Iteration 33, loss = 0.00965971
Iteration 34, loss = 0.00934310
Iteration 35, loss = 0.00902947
Iteration 36, loss = 0.00874469
Iteration 37, loss = 0.00847959
Iteration 38, loss = 0.00821654
Iteration 39, loss = 0.00790331
Iteration 40, loss = 0.00762707
Iteration 41, loss = 0.00746676
Iteration 42, loss = 0.00722644
Iteration 43, loss = 0.00697180
Iteration 44, loss = 0.00675276
Iteration 45, loss = 0.00660897
Iteration 46, loss = 0.00633511
Iteration 47, loss = 0.00615542
Iteration 48, loss = 0.00607062
Iteration 49, loss = 0.00580829
Iteration 50, loss = 0.00560792
Iteration 51, loss = 0.00546143
Iteration 52, loss = 0.00539741
Iteration 53, loss = 0.00508118
Iteration 54, loss = 0.00506827
Iteration 55, loss = 0.00485693
Iteration 56, loss = 0.00469895
Iteration 57, loss = 0.00464638
Iteration 58, loss = 0.00446536
Iteration 59, loss = 0.00429663
Iteration 60, loss = 0.00417043
Iteration 61, loss = 0.00403589
Iteration 62, loss = 0.00399032
Iteration 63, loss = 0.00379600
Iteration 64, loss = 0.00375767
Iteration 65, loss = 0.00358818
Iteration 66, loss = 0.00346749
Iteration 67, loss = 0.00343547
Iteration 68, loss = 0.00332553
Iteration 69, loss = 0.00324569
Iteration 70, loss = 0.00315969
Iteration 71, loss = 0.00300245
Iteration 72, loss = 0.00298806
Iteration 73, loss = 0.00291679
Iteration 74, loss = 0.00278343
Iteration 75, loss = 0.00268056
Iteration 76, loss = 0.00262122
Iteration 77, loss = 0.00254121
Iteration 78, loss = 0.00265243
Iteration 79, loss = 0.00243921
Iteration 80, loss = 0.00235677
Iteration 81, loss = 0.00234463
Iteration 82, loss = 0.00222338
Iteration 83, loss = 0.00223070
Iteration 84, loss = 0.00212763
Iteration 85, loss = 0.00210404
Iteration 86, loss = 0.00206256
Iteration 87, loss = 0.00202663
Iteration 88, loss = 0.00198256
Iteration 89, loss = 0.00194081
Iteration 90, loss = 0.00187929
Iteration 91, loss = 0.00191233
Iteration 92, loss = 0.00177072
Iteration 93, loss = 0.00173266
Iteration 94, loss = 0.00169271
Iteration 95, loss = 0.00168043
Iteration 96, loss = 0.00169697
Iteration 97, loss = 0.00164050
Iteration 98, loss = 0.00159961
Iteration 99, loss = 0.00155349
Iteration 100, loss = 0.00157532
Iteration 101, loss = 0.00151820
Iteration 102, loss = 0.00147594
Iteration 103, loss = 0.00144680
Iteration 104, loss = 0.00142748
Iteration 105, loss = 0.00147167
Iteration 106, loss = 0.00145586
Iteration 107, loss = 0.00138865
Iteration 108, loss = 0.00128138
Iteration 109, loss = 0.00130161
Iteration 110, loss = 0.00129819
Iteration 111, loss = 0.00128311
Iteration 112, loss = 0.00130420
Iteration 113, loss = 0.00126003
Iteration 114, loss = 0.00127060
Iteration 115, loss = 0.00132648
Iteration 116, loss = 0.00118122
Iteration 117, loss = 0.00116017
Iteration 118, loss = 0.00117722
Iteration 119, loss = 0.00116973
Iteration 120, loss = 0.00125497
Iteration 121, loss = 0.00120217
Iteration 122, loss = 0.00108758
Iteration 123, loss = 0.00110041
Iteration 124, loss = 0.00107532
Iteration 125, loss = 0.00104690
Iteration 126, loss = 0.00112185
Iteration 127, loss = 0.00116221
Iteration 128, loss = 0.00108212
Iteration 129, loss = 0.00102982
Iteration 130, loss = 0.00102822
Iteration 131, loss = 0.00115596
Iteration 132, loss = 0.00107298
Iteration 133, loss = 0.00098618
Iteration 134, loss = 0.00099073
Iteration 135, loss = 0.00097715
Iteration 136, loss = 0.00101111
Iteration 137, loss = 0.00102998
Iteration 138, loss = 0.00101319
Iteration 139, loss = 0.00128467
Iteration 140, loss = 0.00093688
Iteration 141, loss = 0.00092176
Iteration 142, loss = 0.00091617
Iteration 143, loss = 0.00094571
Iteration 144, loss = 0.00099643
Iteration 145, loss = 0.00102500
Iteration 146, loss = 0.00093772
Iteration 147, loss = 0.00090138
Iteration 148, loss = 0.00091520
Iteration 149, loss = 0.00093789
Iteration 150, loss = 0.00093831
Iteration 151, loss = 0.00092817
Iteration 152, loss = 0.00097564
Iteration 153, loss = 0.00091829
Iteration 154, loss = 0.00089801
Iteration 155, loss = 0.00091520
Iteration 156, loss = 0.00092198
Iteration 157, loss = 0.00088124
Iteration 158, loss = 0.00101262
Iteration 159, loss = 0.00091457
Iteration 160, loss = 0.00085632
Iteration 161, loss = 0.00085882
Iteration 162, loss = 0.00087779
Iteration 163, loss = 0.00091916
Iteration 164, loss = 0.00086239
Iteration 165, loss = 0.00101711
Iteration 166, loss = 0.00099378
Iteration 167, loss = 0.00083094
Iteration 168, loss = 0.00082580
Iteration 169, loss = 0.00082112
Iteration 170, loss = 0.00086779
Iteration 171, loss = 0.00086100
Iteration 172, loss = 0.00090705
Iteration 173, loss = 0.00087381
Iteration 174, loss = 0.00081877
Iteration 175, loss = 0.00084080
Iteration 176, loss = 0.00084105
Iteration 177, loss = 0.00089934
Iteration 178, loss = 0.00091979
Iteration 179, loss = 0.00090610
Iteration 180, loss = 0.00081271
Iteration 181, loss = 0.00079759
Iteration 182, loss = 0.00082951
Iteration 183, loss = 0.00080573
Iteration 184, loss = 0.00084232
Iteration 185, loss = 0.00089899
Iteration 186, loss = 0.00098713
Iteration 187, loss = 0.00079970
Iteration 188, loss = 0.00078459
Iteration 189, loss = 0.00078144
Iteration 190, loss = 0.00078790
Iteration 191, loss = 0.00082290
Iteration 192, loss = 0.00088801
Iteration 193, loss = 0.00116252
Iteration 194, loss = 0.00079827
Iteration 195, loss = 0.00077198
Iteration 196, loss = 0.00079023
Iteration 197, loss = 0.00077044
Iteration 198, loss = 0.00077584
Iteration 199, loss = 0.00081000
Iteration 200, loss = 0.00114275
Iteration 1, loss = 0.12984299
Iteration 2, loss = 0.06270316
Iteration 3, loss = 0.05249569
Iteration 4, loss = 0.04449802
Iteration 5, loss = 0.03881713
Iteration 6, loss = 0.03456041
Iteration 7, loss = 0.03148212
Iteration 8, loss = 0.02907815
Iteration 9, loss = 0.02690908
Iteration 10, loss = 0.02515525
Iteration 11, loss = 0.02374565
Iteration 12, loss = 0.02237631
Iteration 13, loss = 0.02125827
Iteration 14, loss = 0.02012384
Iteration 15, loss = 0.01909958
Iteration 16, loss = 0.01813351
Iteration 17, loss = 0.01735599
Iteration 18, loss = 0.01674732
Iteration 19, loss = 0.01599501
Iteration 20, loss = 0.01522972
Iteration 21, loss = 0.01485932
Iteration 22, loss = 0.01415383
Iteration 23, loss = 0.01376763
Iteration 24, loss = 0.01315047
Iteration 25, loss = 0.01271394
Iteration 26, loss = 0.01222327
Iteration 27, loss = 0.01189556
Iteration 28, loss = 0.01135769
Iteration 29, loss = 0.01107663
Iteration 30, loss = 0.01080454
Iteration 31, loss = 0.01039067
Iteration 32, loss = 0.00994334
Iteration 33, loss = 0.00980925
Iteration 34, loss = 0.00938675
Iteration 35, loss = 0.00909170
Iteration 36, loss = 0.00878616
Iteration 37, loss = 0.00847143
Iteration 38, loss = 0.00829033
Iteration 39, loss = 0.00795310
Iteration 40, loss = 0.00780164
Iteration 41, loss = 0.00754638
Iteration 42, loss = 0.00733252
Iteration 43, loss = 0.00709490
Iteration 44, loss = 0.00669765
Iteration 45, loss = 0.00676721
Iteration 46, loss = 0.00651627
Iteration 47, loss = 0.00635706
Iteration 48, loss = 0.00605235
Iteration 49, loss = 0.00593392
Iteration 50, loss = 0.00573890
Iteration 51, loss = 0.00555584
Iteration 52, loss = 0.00543136
Iteration 53, loss = 0.00519368
Iteration 54, loss = 0.00514220
Iteration 55, loss = 0.00495672
Iteration 56, loss = 0.00470375
Iteration 57, loss = 0.00465246
Iteration 58, loss = 0.00457875
Iteration 59, loss = 0.00445921
Iteration 60, loss = 0.00423339
Iteration 61, loss = 0.00421442
Iteration 62, loss = 0.00413273
Iteration 63, loss = 0.00389015
Iteration 64, loss = 0.00388100
Iteration 65, loss = 0.00373136
Iteration 66, loss = 0.00373038
Iteration 67, loss = 0.00351613
Iteration 68, loss = 0.00342311
Iteration 69, loss = 0.00329134
Iteration 70, loss = 0.00325803
Iteration 71, loss = 0.00315801
Iteration 72, loss = 0.00312060
Iteration 73, loss = 0.00293892
Iteration 74, loss = 0.00288486
Iteration 75, loss = 0.00286980
Iteration 76, loss = 0.00274781
Iteration 77, loss = 0.00269235
Iteration 78, loss = 0.00262593
Iteration 79, loss = 0.00260095
Iteration 80, loss = 0.00249270
Iteration 81, loss = 0.00248718
Iteration 82, loss = 0.00245965
Iteration 83, loss = 0.00227989
Iteration 84, loss = 0.00231373
Iteration 85, loss = 0.00221354
Iteration 86, loss = 0.00212981
Iteration 87, loss = 0.00210586
Iteration 88, loss = 0.00212970
Iteration 89, loss = 0.00204324
Iteration 90, loss = 0.00201486
Iteration 91, loss = 0.00187859
Iteration 92, loss = 0.00189560
Iteration 93, loss = 0.00187591
Iteration 94, loss = 0.00182926
Iteration 95, loss = 0.00175991
Iteration 96, loss = 0.00173518
Iteration 97, loss = 0.00169076
Iteration 98, loss = 0.00172640
Iteration 99, loss = 0.00164937
Iteration 100, loss = 0.00156001
Iteration 101, loss = 0.00156400
Iteration 102, loss = 0.00159377
Iteration 103, loss = 0.00152070
Iteration 104, loss = 0.00158339
Iteration 105, loss = 0.00145945
Iteration 106, loss = 0.00142123
Iteration 107, loss = 0.00141330
Iteration 108, loss = 0.00137913
Iteration 109, loss = 0.00138196
Iteration 110, loss = 0.00135061
Iteration 111, loss = 0.00134652
Iteration 112, loss = 0.00138161
Iteration 113, loss = 0.00131676
Iteration 114, loss = 0.00127949
Iteration 115, loss = 0.00128066
Iteration 116, loss = 0.00121960
Iteration 117, loss = 0.00118851
Iteration 118, loss = 0.00118599
Iteration 119, loss = 0.00121848
Iteration 120, loss = 0.00124298
Iteration 121, loss = 0.00111847
Iteration 122, loss = 0.00115687
Iteration 123, loss = 0.00112488
Iteration 124, loss = 0.00116022
Iteration 125, loss = 0.00113730
Iteration 126, loss = 0.00113527
Iteration 127, loss = 0.00114492
Iteration 128, loss = 0.00111464
Iteration 129, loss = 0.00107814
Iteration 130, loss = 0.00102128
Iteration 131, loss = 0.00108458
Iteration 132, loss = 0.00104970
Iteration 133, loss = 0.00103341
Iteration 134, loss = 0.00110106
Iteration 135, loss = 0.00102664
Iteration 136, loss = 0.00105097
Iteration 137, loss = 0.00100373
Iteration 138, loss = 0.00095596
Iteration 139, loss = 0.00099273
Iteration 140, loss = 0.00098364
Iteration 141, loss = 0.00101520
Iteration 142, loss = 0.00096849
Iteration 143, loss = 0.00097993
Iteration 144, loss = 0.00109802
Iteration 145, loss = 0.00103110
Iteration 146, loss = 0.00089751
Iteration 147, loss = 0.00088887
Iteration 148, loss = 0.00095963
Iteration 149, loss = 0.00098407
Iteration 150, loss = 0.00090866
Iteration 151, loss = 0.00090597
Iteration 152, loss = 0.00089710
Iteration 153, loss = 0.00092510
Iteration 154, loss = 0.00095608
Iteration 155, loss = 0.00107643
Iteration 156, loss = 0.00095928
Iteration 157, loss = 0.00090516
Iteration 158, loss = 0.00086333
Iteration 159, loss = 0.00086492
Iteration 160, loss = 0.00100645
Iteration 161, loss = 0.00085900
Iteration 162, loss = 0.00088595
Iteration 163, loss = 0.00085995
Iteration 164, loss = 0.00086609
Iteration 165, loss = 0.00107308
Iteration 166, loss = 0.00100390
Iteration 167, loss = 0.00083614
Iteration 168, loss = 0.00081743
Iteration 169, loss = 0.00083136
Iteration 170, loss = 0.00083657
Iteration 171, loss = 0.00085688
Iteration 172, loss = 0.00096359
Iteration 173, loss = 0.00084629
Iteration 174, loss = 0.00085788
Iteration 175, loss = 0.00087793
Iteration 176, loss = 0.00087046
Iteration 177, loss = 0.00082397
Iteration 178, loss = 0.00081060
Iteration 179, loss = 0.00081949
Iteration 180, loss = 0.00088049
Iteration 181, loss = 0.00103273
Iteration 182, loss = 0.00085452
Iteration 183, loss = 0.00078822
Iteration 184, loss = 0.00079597
Iteration 185, loss = 0.00081438
Iteration 186, loss = 0.00088865
Iteration 187, loss = 0.00093601
Iteration 188, loss = 0.00081082
Iteration 189, loss = 0.00077760
Iteration 190, loss = 0.00079553
Iteration 191, loss = 0.00080028
Iteration 192, loss = 0.00086279
Iteration 193, loss = 0.00089886
Iteration 194, loss = 0.00084640
Iteration 195, loss = 0.00078431
Iteration 196, loss = 0.00077475
Iteration 197, loss = 0.00078152
Iteration 198, loss = 0.00081195
Iteration 199, loss = 0.00099701
Iteration 200, loss = 0.00080827
Iteration 1, loss = 0.14232213
Iteration 2, loss = 0.06251930
Iteration 3, loss = 0.05199741
Iteration 4, loss = 0.04408995
Iteration 5, loss = 0.03820993
Iteration 6, loss = 0.03378737
Iteration 7, loss = 0.03062546
Iteration 8, loss = 0.02787022
Iteration 9, loss = 0.02578017
Iteration 10, loss = 0.02389222
Iteration 11, loss = 0.02236490
Iteration 12, loss = 0.02084403
Iteration 13, loss = 0.01974781
Iteration 14, loss = 0.01869171
Iteration 15, loss = 0.01777630
Iteration 16, loss = 0.01690719
Iteration 17, loss = 0.01606508
Iteration 18, loss = 0.01537772
Iteration 19, loss = 0.01465680
Iteration 20, loss = 0.01403281
Iteration 21, loss = 0.01354201
Iteration 22, loss = 0.01307128
Iteration 23, loss = 0.01253873
Iteration 24, loss = 0.01193886
Iteration 25, loss = 0.01170281
Iteration 26, loss = 0.01118338
Iteration 27, loss = 0.01081940
Iteration 28, loss = 0.01042463
Iteration 29, loss = 0.01003344
Iteration 30, loss = 0.00969162
Iteration 31, loss = 0.00952839
Iteration 32, loss = 0.00896979
Iteration 33, loss = 0.00873124
Iteration 34, loss = 0.00847876
Iteration 35, loss = 0.00812964
Iteration 36, loss = 0.00794585
Iteration 37, loss = 0.00768054
Iteration 38, loss = 0.00727366
Iteration 39, loss = 0.00712679
Iteration 40, loss = 0.00690276
Iteration 41, loss = 0.00661401
Iteration 42, loss = 0.00648985
Iteration 43, loss = 0.00614068
Iteration 44, loss = 0.00597219
Iteration 45, loss = 0.00586534
Iteration 46, loss = 0.00561677
Iteration 47, loss = 0.00545324
Iteration 48, loss = 0.00532301
Iteration 49, loss = 0.00506304
Iteration 50, loss = 0.00498525
Iteration 51, loss = 0.00475758
Iteration 52, loss = 0.00464438
Iteration 53, loss = 0.00455478
Iteration 54, loss = 0.00438625
Iteration 55, loss = 0.00428362
Iteration 56, loss = 0.00409493
Iteration 57, loss = 0.00395613
Iteration 58, loss = 0.00381171
Iteration 59, loss = 0.00366929
Iteration 60, loss = 0.00356470
Iteration 61, loss = 0.00350523
Iteration 62, loss = 0.00339220
Iteration 63, loss = 0.00330765
Iteration 64, loss = 0.00315436
Iteration 65, loss = 0.00317387
Iteration 66, loss = 0.00303260
Iteration 67, loss = 0.00299965
Iteration 68, loss = 0.00279804
Iteration 69, loss = 0.00270435
Iteration 70, loss = 0.00265345
Iteration 71, loss = 0.00260988
Iteration 72, loss = 0.00251482
Iteration 73, loss = 0.00246337
Iteration 74, loss = 0.00234048
Iteration 75, loss = 0.00236685
Iteration 76, loss = 0.00227261
Iteration 77, loss = 0.00220693
Iteration 78, loss = 0.00211279
Iteration 79, loss = 0.00209304
Iteration 80, loss = 0.00208609
Iteration 81, loss = 0.00198811
Iteration 82, loss = 0.00197109
Iteration 83, loss = 0.00189905
Iteration 84, loss = 0.00178764
Iteration 85, loss = 0.00183888
Iteration 86, loss = 0.00183062
Iteration 87, loss = 0.00175019
Iteration 88, loss = 0.00173437
Iteration 89, loss = 0.00172667
Iteration 90, loss = 0.00163980
Iteration 91, loss = 0.00160994
Iteration 92, loss = 0.00151839
Iteration 93, loss = 0.00149733
Iteration 94, loss = 0.00162031
Iteration 95, loss = 0.00145734
Iteration 96, loss = 0.00147395
Iteration 97, loss = 0.00138813
Iteration 98, loss = 0.00140087
Iteration 99, loss = 0.00141429
Iteration 100, loss = 0.00139569
Iteration 101, loss = 0.00132912
Iteration 102, loss = 0.00144666
Iteration 103, loss = 0.00126693
Iteration 104, loss = 0.00126376
Iteration 105, loss = 0.00130383
Iteration 106, loss = 0.00126952
Iteration 107, loss = 0.00124373
Iteration 108, loss = 0.00125184
Iteration 109, loss = 0.00114975
Iteration 110, loss = 0.00119687
Iteration 111, loss = 0.00115635
Iteration 112, loss = 0.00112697
Iteration 113, loss = 0.00122918
Iteration 114, loss = 0.00120044
Iteration 115, loss = 0.00107409
Iteration 116, loss = 0.00110174
Iteration 117, loss = 0.00111205
Iteration 118, loss = 0.00117428
Iteration 119, loss = 0.00104693
Iteration 120, loss = 0.00102723
Iteration 121, loss = 0.00103810
Iteration 122, loss = 0.00114167
Iteration 123, loss = 0.00112659
Iteration 124, loss = 0.00099189
Iteration 125, loss = 0.00097521
Iteration 126, loss = 0.00102384
Iteration 127, loss = 0.00107152
Iteration 128, loss = 0.00097419
Iteration 129, loss = 0.00101037
Iteration 130, loss = 0.00109008
Iteration 131, loss = 0.00097266
Iteration 132, loss = 0.00093526
Iteration 133, loss = 0.00092715
Iteration 134, loss = 0.00099404
Iteration 135, loss = 0.00099096
Iteration 136, loss = 0.00111478
Iteration 137, loss = 0.00095336
Iteration 138, loss = 0.00089781
Iteration 139, loss = 0.00092049
Iteration 140, loss = 0.00089736
Iteration 141, loss = 0.00093164
Iteration 142, loss = 0.00107003
Iteration 143, loss = 0.00089587
Iteration 144, loss = 0.00088113
Iteration 145, loss = 0.00091913
Iteration 146, loss = 0.00111206
Iteration 147, loss = 0.00109626
Iteration 148, loss = 0.00086057
Iteration 149, loss = 0.00084608
Iteration 150, loss = 0.00085897
Iteration 151, loss = 0.00085347
Iteration 152, loss = 0.00092496
Iteration 153, loss = 0.00132132
Iteration 154, loss = 0.00087493
Iteration 155, loss = 0.00083809
Iteration 156, loss = 0.00082651
Iteration 157, loss = 0.00082596
Iteration 158, loss = 0.00085048
Iteration 159, loss = 0.00140034
Iteration 160, loss = 0.00088494
Iteration 161, loss = 0.00083026
Iteration 162, loss = 0.00081462
Iteration 163, loss = 0.00082425
Iteration 164, loss = 0.00083428
Iteration 165, loss = 0.00082851
Iteration 166, loss = 0.00083549
Iteration 167, loss = 0.00089421
Iteration 168, loss = 0.00115820
Iteration 169, loss = 0.00084893
Iteration 170, loss = 0.00081348
Iteration 171, loss = 0.00081775
Iteration 172, loss = 0.00080904
Iteration 173, loss = 0.00081457
Iteration 174, loss = 0.00117194
Iteration 175, loss = 0.00094140
Iteration 176, loss = 0.00082020
Iteration 177, loss = 0.00079421
Iteration 178, loss = 0.00079194
Iteration 179, loss = 0.00080301
Iteration 180, loss = 0.00087975
Iteration 181, loss = 0.00119313
Iteration 182, loss = 0.00082624
Iteration 183, loss = 0.00078662
Iteration 184, loss = 0.00077999
Iteration 185, loss = 0.00078163
Iteration 186, loss = 0.00078488
Iteration 187, loss = 0.00098608
Iteration 188, loss = 0.00115302
Iteration 189, loss = 0.00080084
Iteration 190, loss = 0.00077873
Iteration 191, loss = 0.00077429
Iteration 192, loss = 0.00077636
Iteration 193, loss = 0.00078354
Iteration 194, loss = 0.00089532
Iteration 195, loss = 0.00099318
Iteration 196, loss = 0.00078196
Iteration 197, loss = 0.00077507
Iteration 198, loss = 0.00077372
Iteration 199, loss = 0.00078002
Iteration 200, loss = 0.00079855
Iteration 1, loss = 0.12679600
Iteration 2, loss = 0.06182565
Iteration 3, loss = 0.05186470
Iteration 4, loss = 0.04323180
Iteration 5, loss = 0.03708572
Iteration 6, loss = 0.03280615
Iteration 7, loss = 0.02969391
Iteration 8, loss = 0.02739281
Iteration 9, loss = 0.02532255
Iteration 10, loss = 0.02379768
Iteration 11, loss = 0.02228907
Iteration 12, loss = 0.02111267
Iteration 13, loss = 0.01998936
Iteration 14, loss = 0.01904916
Iteration 15, loss = 0.01807779
Iteration 16, loss = 0.01731503
Iteration 17, loss = 0.01655677
Iteration 18, loss = 0.01599941
Iteration 19, loss = 0.01531646
Iteration 20, loss = 0.01461043
Iteration 21, loss = 0.01406432
Iteration 22, loss = 0.01354200
Iteration 23, loss = 0.01305201
Iteration 24, loss = 0.01261807
Iteration 25, loss = 0.01200592
Iteration 26, loss = 0.01168025
Iteration 27, loss = 0.01125974
Iteration 28, loss = 0.01087038
Iteration 29, loss = 0.01050081
Iteration 30, loss = 0.01011704
Iteration 31, loss = 0.00978519
Iteration 32, loss = 0.00938070
Iteration 33, loss = 0.00929115
Iteration 34, loss = 0.00888663
Iteration 35, loss = 0.00868669
Iteration 36, loss = 0.00821332
Iteration 37, loss = 0.00811728
Iteration 38, loss = 0.00772914
Iteration 39, loss = 0.00761020
Iteration 40, loss = 0.00735363
Iteration 41, loss = 0.00721757
Iteration 42, loss = 0.00689481
Iteration 43, loss = 0.00658804
Iteration 44, loss = 0.00644882
Iteration 45, loss = 0.00630675
Iteration 46, loss = 0.00606090
Iteration 47, loss = 0.00575076
Iteration 48, loss = 0.00568967
Iteration 49, loss = 0.00542180
Iteration 50, loss = 0.00536630
Iteration 51, loss = 0.00512491
Iteration 52, loss = 0.00507687
Iteration 53, loss = 0.00491344
Iteration 54, loss = 0.00477072
Iteration 55, loss = 0.00452243
Iteration 56, loss = 0.00445661
Iteration 57, loss = 0.00430524
Iteration 58, loss = 0.00413061
Iteration 59, loss = 0.00413124
Iteration 60, loss = 0.00395855
Iteration 61, loss = 0.00387990
Iteration 62, loss = 0.00374953
Iteration 63, loss = 0.00365398
Iteration 64, loss = 0.00354297
Iteration 65, loss = 0.00339297
Iteration 66, loss = 0.00336049
Iteration 67, loss = 0.00328745
Iteration 68, loss = 0.00315686
Iteration 69, loss = 0.00299959
Iteration 70, loss = 0.00297155
Iteration 71, loss = 0.00294880
Iteration 72, loss = 0.00277526
Iteration 73, loss = 0.00273338
Iteration 74, loss = 0.00270346
Iteration 75, loss = 0.00266464
Iteration 76, loss = 0.00256283
Iteration 77, loss = 0.00252556
Iteration 78, loss = 0.00238022
Iteration 79, loss = 0.00230749
Iteration 80, loss = 0.00225042
Iteration 81, loss = 0.00223433
Iteration 82, loss = 0.00225457
Iteration 83, loss = 0.00215614
Iteration 84, loss = 0.00207325
Iteration 85, loss = 0.00203761
Iteration 86, loss = 0.00195021
Iteration 87, loss = 0.00202663
Iteration 88, loss = 0.00193010
Iteration 89, loss = 0.00178665
Iteration 90, loss = 0.00190891
Iteration 91, loss = 0.00179683
Iteration 92, loss = 0.00170767
Iteration 93, loss = 0.00165480
Iteration 94, loss = 0.00165018
Iteration 95, loss = 0.00160848
Iteration 96, loss = 0.00170014
Iteration 97, loss = 0.00165228
Iteration 98, loss = 0.00153856
Iteration 99, loss = 0.00159921
Iteration 100, loss = 0.00153489
Iteration 101, loss = 0.00152257
Iteration 102, loss = 0.00146425
Iteration 103, loss = 0.00142429
Iteration 104, loss = 0.00141866
Iteration 105, loss = 0.00149130
Iteration 106, loss = 0.00138930
Iteration 107, loss = 0.00133949
Iteration 108, loss = 0.00130877
Iteration 109, loss = 0.00137691
Iteration 110, loss = 0.00126928
Iteration 111, loss = 0.00133172
Iteration 112, loss = 0.00137059
Iteration 113, loss = 0.00121700
Iteration 114, loss = 0.00113773
Iteration 115, loss = 0.00118917
Iteration 116, loss = 0.00125805
Iteration 117, loss = 0.00127807
Iteration 118, loss = 0.00115551
Iteration 119, loss = 0.00115411
Iteration 120, loss = 0.00117622
Iteration 121, loss = 0.00113298
Iteration 122, loss = 0.00111614
Iteration 123, loss = 0.00109217
Iteration 124, loss = 0.00121785
Iteration 125, loss = 0.00108580
Iteration 126, loss = 0.00108384
Iteration 127, loss = 0.00105541
Iteration 128, loss = 0.00109427
Iteration 129, loss = 0.00123528
Iteration 130, loss = 0.00101580
Iteration 131, loss = 0.00097718
Iteration 132, loss = 0.00100546
Iteration 133, loss = 0.00100431
Iteration 134, loss = 0.00104881
Iteration 135, loss = 0.00096045
Iteration 136, loss = 0.00101594
Iteration 137, loss = 0.00113938
Iteration 138, loss = 0.00099481
Iteration 139, loss = 0.00094074
Iteration 140, loss = 0.00098606
Iteration 141, loss = 0.00096553
Iteration 142, loss = 0.00092370
Iteration 143, loss = 0.00114741
Iteration 144, loss = 0.00112550
Iteration 145, loss = 0.00090255
Iteration 146, loss = 0.00088368
Iteration 147, loss = 0.00093651
Iteration 148, loss = 0.00093621
Iteration 149, loss = 0.00096866
Iteration 150, loss = 0.00091816
Iteration 151, loss = 0.00088731
Iteration 152, loss = 0.00114714
Iteration 153, loss = 0.00090267
Iteration 154, loss = 0.00086674
Iteration 155, loss = 0.00086111
Iteration 156, loss = 0.00087021
Iteration 157, loss = 0.00094282
Iteration 158, loss = 0.00133111
Iteration 159, loss = 0.00086714
Iteration 160, loss = 0.00083242
Iteration 161, loss = 0.00082503
Iteration 162, loss = 0.00084116
Iteration 163, loss = 0.00092177
Iteration 164, loss = 0.00092409
Iteration 165, loss = 0.00093744
Iteration 166, loss = 0.00083948
Iteration 167, loss = 0.00081972
Iteration 168, loss = 0.00090693
Iteration 169, loss = 0.00117600
Iteration 170, loss = 0.00083369
Iteration 171, loss = 0.00080928
Iteration 172, loss = 0.00081060
Iteration 173, loss = 0.00083741
Iteration 174, loss = 0.00165127
Iteration 175, loss = 0.00084251
Iteration 176, loss = 0.00081226
Iteration 177, loss = 0.00079977
Iteration 178, loss = 0.00079745
Iteration 179, loss = 0.00079844
Iteration 180, loss = 0.00079445
Iteration 181, loss = 0.00105633
Iteration 182, loss = 0.00116002
Iteration 183, loss = 0.00081555
Iteration 184, loss = 0.00079018
Iteration 185, loss = 0.00078555
Iteration 186, loss = 0.00079465
Iteration 187, loss = 0.00080125
Iteration 188, loss = 0.00083048
Iteration 189, loss = 0.00114795
Iteration 190, loss = 0.00085582
Iteration 191, loss = 0.00078818
Iteration 192, loss = 0.00078392
Iteration 193, loss = 0.00080154
Iteration 194, loss = 0.00104597
Iteration 195, loss = 0.00109256
Iteration 196, loss = 0.00078824
Iteration 197, loss = 0.00077173
Iteration 198, loss = 0.00076685
Iteration 199, loss = 0.00077139
Iteration 200, loss = 0.00078729
Iteration 1, loss = 0.12906625
Iteration 2, loss = 0.06236942
Iteration 3, loss = 0.05233885
Iteration 4, loss = 0.04417047
Iteration 5, loss = 0.03794773
Iteration 6, loss = 0.03338191
Iteration 7, loss = 0.03007307
Iteration 8, loss = 0.02757653
Iteration 9, loss = 0.02557621
Iteration 10, loss = 0.02387178
Iteration 11, loss = 0.02255640
Iteration 12, loss = 0.02116083
Iteration 13, loss = 0.02019050
Iteration 14, loss = 0.01912067
Iteration 15, loss = 0.01822254
Iteration 16, loss = 0.01737446
Iteration 17, loss = 0.01660207
Iteration 18, loss = 0.01582391
Iteration 19, loss = 0.01527457
Iteration 20, loss = 0.01457097
Iteration 21, loss = 0.01400160
Iteration 22, loss = 0.01350126
Iteration 23, loss = 0.01295579
Iteration 24, loss = 0.01238177
Iteration 25, loss = 0.01191100
Iteration 26, loss = 0.01156736
Iteration 27, loss = 0.01114729
Iteration 28, loss = 0.01069174
Iteration 29, loss = 0.01035912
Iteration 30, loss = 0.01001043
Iteration 31, loss = 0.00961021
Iteration 32, loss = 0.00931147
Iteration 33, loss = 0.00907743
Iteration 34, loss = 0.00872490
Iteration 35, loss = 0.00852189
Iteration 36, loss = 0.00807619
Iteration 37, loss = 0.00781613
Iteration 38, loss = 0.00758043
Iteration 39, loss = 0.00740916
Iteration 40, loss = 0.00718776
Iteration 41, loss = 0.00695936
Iteration 42, loss = 0.00674258
Iteration 43, loss = 0.00652972
Iteration 44, loss = 0.00623819
Iteration 45, loss = 0.00612968
Iteration 46, loss = 0.00589769
Iteration 47, loss = 0.00576407
Iteration 48, loss = 0.00562329
Iteration 49, loss = 0.00533193
Iteration 50, loss = 0.00521541
Iteration 51, loss = 0.00510252
Iteration 52, loss = 0.00489525
Iteration 53, loss = 0.00478835
Iteration 54, loss = 0.00456388
Iteration 55, loss = 0.00442725
Iteration 56, loss = 0.00436785
Iteration 57, loss = 0.00423785
Iteration 58, loss = 0.00402586
Iteration 59, loss = 0.00390027
Iteration 60, loss = 0.00391588
Iteration 61, loss = 0.00374431
Iteration 62, loss = 0.00363840
Iteration 63, loss = 0.00352994
Iteration 64, loss = 0.00340267
Iteration 65, loss = 0.00331057
Iteration 66, loss = 0.00321432
Iteration 67, loss = 0.00307077
Iteration 68, loss = 0.00300748
Iteration 69, loss = 0.00300810
Iteration 70, loss = 0.00289703
Iteration 71, loss = 0.00275793
Iteration 72, loss = 0.00270806
Iteration 73, loss = 0.00258271
Iteration 74, loss = 0.00252777
Iteration 75, loss = 0.00248142
Iteration 76, loss = 0.00240272
Iteration 77, loss = 0.00231631
Iteration 78, loss = 0.00227902
Iteration 79, loss = 0.00227668
Iteration 80, loss = 0.00219526
Iteration 81, loss = 0.00213769
Iteration 82, loss = 0.00205402
Iteration 83, loss = 0.00201983
Iteration 84, loss = 0.00193539
Iteration 85, loss = 0.00202184
Iteration 86, loss = 0.00188501
Iteration 87, loss = 0.00180856
Iteration 88, loss = 0.00180079
Iteration 89, loss = 0.00182850
Iteration 90, loss = 0.00174237
Iteration 91, loss = 0.00165648
Iteration 92, loss = 0.00165394
Iteration 93, loss = 0.00171150
Iteration 94, loss = 0.00156436
Iteration 95, loss = 0.00154629
Iteration 96, loss = 0.00149656
Iteration 97, loss = 0.00149161
Iteration 98, loss = 0.00149759
Iteration 99, loss = 0.00152128
Iteration 100, loss = 0.00147837
Iteration 101, loss = 0.00145527
Iteration 102, loss = 0.00139084
Iteration 103, loss = 0.00129547
Iteration 104, loss = 0.00134241
Iteration 105, loss = 0.00135861
Iteration 106, loss = 0.00129487
Iteration 107, loss = 0.00133096
Iteration 108, loss = 0.00123521
Iteration 109, loss = 0.00131597
Iteration 110, loss = 0.00120871
Iteration 111, loss = 0.00120260
Iteration 112, loss = 0.00125072
Iteration 113, loss = 0.00130022
Iteration 114, loss = 0.00113313
Iteration 115, loss = 0.00114586
Iteration 116, loss = 0.00111498
Iteration 117, loss = 0.00122164
Iteration 118, loss = 0.00132084
Iteration 119, loss = 0.00108759
Iteration 120, loss = 0.00103199
Iteration 121, loss = 0.00106714
Iteration 122, loss = 0.00112636
Iteration 123, loss = 0.00103776
Iteration 124, loss = 0.00104061
Iteration 125, loss = 0.00115409
Iteration 126, loss = 0.00108921
Iteration 127, loss = 0.00107629
Iteration 128, loss = 0.00097677
Iteration 129, loss = 0.00100398
Iteration 130, loss = 0.00100446
Iteration 131, loss = 0.00104100
Iteration 132, loss = 0.00104899
Iteration 133, loss = 0.00105197
Iteration 134, loss = 0.00096828
Iteration 135, loss = 0.00092297
Iteration 136, loss = 0.00093650
Iteration 137, loss = 0.00100973
Iteration 138, loss = 0.00114792
Iteration 139, loss = 0.00126298
Iteration 140, loss = 0.00092006
Iteration 141, loss = 0.00087705
Iteration 142, loss = 0.00088001
Iteration 143, loss = 0.00089267
Iteration 144, loss = 0.00097006
Iteration 145, loss = 0.00111361
Iteration 146, loss = 0.00099167
Iteration 147, loss = 0.00087392
Iteration 148, loss = 0.00086626
Iteration 149, loss = 0.00092692
Iteration 150, loss = 0.00107125
Iteration 151, loss = 0.00105623
Iteration 152, loss = 0.00086421
Iteration 153, loss = 0.00084776
Iteration 154, loss = 0.00085902
Iteration 155, loss = 0.00085070
Iteration 156, loss = 0.00115448
Iteration 157, loss = 0.00103217
Iteration 158, loss = 0.00084460
Iteration 159, loss = 0.00082617
Iteration 160, loss = 0.00082253
Iteration 161, loss = 0.00086297
Iteration 162, loss = 0.00095369
Iteration 163, loss = 0.00097393
Iteration 164, loss = 0.00083296
Iteration 165, loss = 0.00082389
Iteration 166, loss = 0.00084336
Iteration 167, loss = 0.00084356
Iteration 168, loss = 0.00124365
Iteration 169, loss = 0.00093784
Iteration 170, loss = 0.00082003
Iteration 171, loss = 0.00080496
Iteration 172, loss = 0.00080043
Iteration 173, loss = 0.00080449
Iteration 174, loss = 0.00080963
Iteration 175, loss = 0.00088685
Iteration 176, loss = 0.00107432
Iteration 177, loss = 0.00087060
Iteration 178, loss = 0.00081257
Iteration 179, loss = 0.00079678
Iteration 180, loss = 0.00079710
Iteration 181, loss = 0.00090366
Iteration 182, loss = 0.00151501
Iteration 183, loss = 0.00081914
Iteration 184, loss = 0.00078870
Iteration 185, loss = 0.00077878
Iteration 186, loss = 0.00077661
Iteration 187, loss = 0.00077642
Iteration 188, loss = 0.00077949
Iteration 189, loss = 0.00081242
Iteration 190, loss = 0.00158988
Iteration 191, loss = 0.00085152
Iteration 192, loss = 0.00078405
Iteration 193, loss = 0.00077729
Iteration 194, loss = 0.00076920
Iteration 195, loss = 0.00076783
Iteration 196, loss = 0.00076958
Iteration 197, loss = 0.00077867
Iteration 198, loss = 0.00085386
Iteration 199, loss = 0.00098783
Iteration 200, loss = 0.00120625
Iteration 1, loss = 0.12327658
Iteration 2, loss = 0.05954620
Iteration 3, loss = 0.04855991
Iteration 4, loss = 0.04047994
Iteration 5, loss = 0.03508425
Iteration 6, loss = 0.03126201
Iteration 7, loss = 0.02837286
Iteration 8, loss = 0.02611442
Iteration 9, loss = 0.02433682
Iteration 10, loss = 0.02268401
Iteration 11, loss = 0.02138935
Iteration 12, loss = 0.02019060
Iteration 13, loss = 0.01902291
Iteration 14, loss = 0.01807307
Iteration 15, loss = 0.01718639
Iteration 16, loss = 0.01637425
Iteration 17, loss = 0.01559624
Iteration 18, loss = 0.01491610
Iteration 19, loss = 0.01425683
Iteration 20, loss = 0.01355631
Iteration 21, loss = 0.01304914
Iteration 22, loss = 0.01240567
Iteration 23, loss = 0.01201677
Iteration 24, loss = 0.01143211
Iteration 25, loss = 0.01102081
Iteration 26, loss = 0.01053750
Iteration 27, loss = 0.01017937
Iteration 28, loss = 0.00968658
Iteration 29, loss = 0.00939567
Iteration 30, loss = 0.00902407
Iteration 31, loss = 0.00866850
Iteration 32, loss = 0.00838572
Iteration 33, loss = 0.00797683
Iteration 34, loss = 0.00783277
Iteration 35, loss = 0.00746730
Iteration 36, loss = 0.00724671
Iteration 37, loss = 0.00708734
Iteration 38, loss = 0.00664270
Iteration 39, loss = 0.00641937
Iteration 40, loss = 0.00624096
Iteration 41, loss = 0.00604432
Iteration 42, loss = 0.00581431
Iteration 43, loss = 0.00564313
Iteration 44, loss = 0.00535002
Iteration 45, loss = 0.00526231
Iteration 46, loss = 0.00502969
Iteration 47, loss = 0.00493194
Iteration 48, loss = 0.00470657
Iteration 49, loss = 0.00446697
Iteration 50, loss = 0.00435041
Iteration 51, loss = 0.00418581
Iteration 52, loss = 0.00408913
Iteration 53, loss = 0.00392957
Iteration 54, loss = 0.00382116
Iteration 55, loss = 0.00371843
Iteration 56, loss = 0.00359408
Iteration 57, loss = 0.00344895
Iteration 58, loss = 0.00338041
Iteration 59, loss = 0.00320998
Iteration 60, loss = 0.00310147
Iteration 61, loss = 0.00299259
Iteration 62, loss = 0.00290661
Iteration 63, loss = 0.00277759
Iteration 64, loss = 0.00270389
Iteration 65, loss = 0.00278799
Iteration 66, loss = 0.00263109
Iteration 67, loss = 0.00252141
Iteration 68, loss = 0.00240998
Iteration 69, loss = 0.00230687
Iteration 70, loss = 0.00231501
Iteration 71, loss = 0.00235192
Iteration 72, loss = 0.00211591
Iteration 73, loss = 0.00208385
Iteration 74, loss = 0.00209364
Iteration 75, loss = 0.00198494
Iteration 76, loss = 0.00197052
Iteration 77, loss = 0.00179229
Iteration 78, loss = 0.00190863
Iteration 79, loss = 0.00178500
Iteration 80, loss = 0.00174439
Iteration 81, loss = 0.00170715
Iteration 82, loss = 0.00163122
Iteration 83, loss = 0.00163095
Iteration 84, loss = 0.00161228
Iteration 85, loss = 0.00160976
Iteration 86, loss = 0.00151729
Iteration 87, loss = 0.00149961
Iteration 88, loss = 0.00150327
Iteration 89, loss = 0.00142691
Iteration 90, loss = 0.00151485
Iteration 91, loss = 0.00140469
Iteration 92, loss = 0.00130968
Iteration 93, loss = 0.00129911
Iteration 94, loss = 0.00130897
Iteration 95, loss = 0.00136938
Iteration 96, loss = 0.00125103
Iteration 97, loss = 0.00128594
Iteration 98, loss = 0.00120743
Iteration 99, loss = 0.00125905
Iteration 100, loss = 0.00123472
Iteration 101, loss = 0.00122865
Iteration 102, loss = 0.00125412
Iteration 103, loss = 0.00111044
Iteration 104, loss = 0.00116095
Iteration 105, loss = 0.00107124
Iteration 106, loss = 0.00107957
Iteration 107, loss = 0.00115795
Iteration 108, loss = 0.00109191
Iteration 109, loss = 0.00105046
Iteration 110, loss = 0.00107649
Iteration 111, loss = 0.00113502
Iteration 112, loss = 0.00108498
Iteration 113, loss = 0.00099363
Iteration 114, loss = 0.00096593
Iteration 115, loss = 0.00098601
Iteration 116, loss = 0.00099939
Iteration 117, loss = 0.00107997
Iteration 118, loss = 0.00140238
Iteration 119, loss = 0.00093828
Iteration 120, loss = 0.00090711
Iteration 121, loss = 0.00090753
Iteration 122, loss = 0.00090865
Iteration 123, loss = 0.00094821
Iteration 124, loss = 0.00102485
Iteration 125, loss = 0.00127810
Iteration 126, loss = 0.00090304
Iteration 127, loss = 0.00088175
Iteration 128, loss = 0.00088592
Iteration 129, loss = 0.00089221
Iteration 130, loss = 0.00091871
Iteration 131, loss = 0.00092187
Iteration 132, loss = 0.00105435
Iteration 133, loss = 0.00096280
Iteration 134, loss = 0.00093542
Iteration 135, loss = 0.00084276
Iteration 136, loss = 0.00085483
Iteration 137, loss = 0.00091726
Iteration 138, loss = 0.00085594
Iteration 139, loss = 0.00110280
Iteration 140, loss = 0.00094533
Iteration 141, loss = 0.00083189
Iteration 142, loss = 0.00087475
Iteration 143, loss = 0.00090221
Iteration 144, loss = 0.00083182
Iteration 145, loss = 0.00082856
Iteration 146, loss = 0.00085113
Iteration 147, loss = 0.00089352
Iteration 148, loss = 0.00121459
Iteration 149, loss = 0.00083056
Iteration 150, loss = 0.00079903
Iteration 151, loss = 0.00079111
Iteration 152, loss = 0.00079838
Iteration 153, loss = 0.00095144
Iteration 154, loss = 0.00117628
Iteration 155, loss = 0.00083033
Iteration 156, loss = 0.00079207
Iteration 157, loss = 0.00078087
Iteration 158, loss = 0.00078648
Iteration 159, loss = 0.00078421
Iteration 160, loss = 0.00081213
Iteration 161, loss = 0.00133028
Iteration 162, loss = 0.00082402
Iteration 163, loss = 0.00077910
Iteration 164, loss = 0.00077503
Iteration 165, loss = 0.00077377
Iteration 166, loss = 0.00078063
Iteration 167, loss = 0.00087005
Iteration 168, loss = 0.00121130
Iteration 169, loss = 0.00080244
Iteration 170, loss = 0.00077271
Iteration 171, loss = 0.00076163
Iteration 172, loss = 0.00076477
Iteration 173, loss = 0.00079004
Iteration 174, loss = 0.00090680
Iteration 175, loss = 0.00086955
Iteration 176, loss = 0.00076810
Iteration 177, loss = 0.00075998
Iteration 178, loss = 0.00075920
Iteration 179, loss = 0.00078577
Iteration 180, loss = 0.00151894
Iteration 181, loss = 0.00080792
Iteration 182, loss = 0.00076080
Iteration 183, loss = 0.00074831
Iteration 184, loss = 0.00074951
Iteration 185, loss = 0.00074356
Iteration 186, loss = 0.00074578
Iteration 187, loss = 0.00075564
Iteration 188, loss = 0.00081910
Iteration 189, loss = 0.00103974
Iteration 190, loss = 0.00117715
Iteration 191, loss = 0.00076723
Iteration 192, loss = 0.00074583
Iteration 193, loss = 0.00073974
Iteration 194, loss = 0.00073651
Iteration 195, loss = 0.00073718
Iteration 196, loss = 0.00073911
Iteration 197, loss = 0.00075626
Iteration 198, loss = 0.00116260
Iteration 199, loss = 0.00077353
Iteration 200, loss = 0.00073741
Iteration 1, loss = 0.12061544
Iteration 2, loss = 0.05948421
Iteration 3, loss = 0.04870836
Iteration 4, loss = 0.04052141
Iteration 5, loss = 0.03496629
Iteration 6, loss = 0.03087487
Iteration 7, loss = 0.02795228
Iteration 8, loss = 0.02561635
Iteration 9, loss = 0.02365653
Iteration 10, loss = 0.02211662
Iteration 11, loss = 0.02079071
Iteration 12, loss = 0.01961333
Iteration 13, loss = 0.01850873
Iteration 14, loss = 0.01756927
Iteration 15, loss = 0.01666289
Iteration 16, loss = 0.01589420
Iteration 17, loss = 0.01506104
Iteration 18, loss = 0.01446462
Iteration 19, loss = 0.01370159
Iteration 20, loss = 0.01325491
Iteration 21, loss = 0.01249538
Iteration 22, loss = 0.01217501
Iteration 23, loss = 0.01157621
Iteration 24, loss = 0.01117911
Iteration 25, loss = 0.01068689
Iteration 26, loss = 0.01028796
Iteration 27, loss = 0.00994479
Iteration 28, loss = 0.00950850
Iteration 29, loss = 0.00927226
Iteration 30, loss = 0.00888732
Iteration 31, loss = 0.00861942
Iteration 32, loss = 0.00818844
Iteration 33, loss = 0.00800477
Iteration 34, loss = 0.00769752
Iteration 35, loss = 0.00740706
Iteration 36, loss = 0.00719571
Iteration 37, loss = 0.00693848
Iteration 38, loss = 0.00672242
Iteration 39, loss = 0.00647051
Iteration 40, loss = 0.00627577
Iteration 41, loss = 0.00607401
Iteration 42, loss = 0.00589284
Iteration 43, loss = 0.00568222
Iteration 44, loss = 0.00543282
Iteration 45, loss = 0.00529627
Iteration 46, loss = 0.00511274
Iteration 47, loss = 0.00495598
Iteration 48, loss = 0.00478030
Iteration 49, loss = 0.00459120
Iteration 50, loss = 0.00449402
Iteration 51, loss = 0.00439312
Iteration 52, loss = 0.00420416
Iteration 53, loss = 0.00404860
Iteration 54, loss = 0.00402111
Iteration 55, loss = 0.00378621
Iteration 56, loss = 0.00370347
Iteration 57, loss = 0.00363425
Iteration 58, loss = 0.00341088
Iteration 59, loss = 0.00331592
Iteration 60, loss = 0.00334378
Iteration 61, loss = 0.00306066
Iteration 62, loss = 0.00303583
Iteration 63, loss = 0.00293478
Iteration 64, loss = 0.00291487
Iteration 65, loss = 0.00279009
Iteration 66, loss = 0.00271093
Iteration 67, loss = 0.00262722
Iteration 68, loss = 0.00252361
Iteration 69, loss = 0.00247908
Iteration 70, loss = 0.00242355
Iteration 71, loss = 0.00230428
Iteration 72, loss = 0.00230054
Iteration 73, loss = 0.00218011
Iteration 74, loss = 0.00216547
Iteration 75, loss = 0.00208888
Iteration 76, loss = 0.00201492
Iteration 77, loss = 0.00195396
Iteration 78, loss = 0.00191844
Iteration 79, loss = 0.00188953
Iteration 80, loss = 0.00175452
Iteration 81, loss = 0.00178515
Iteration 82, loss = 0.00177285
Iteration 83, loss = 0.00174340
Iteration 84, loss = 0.00158727
Iteration 85, loss = 0.00162037
Iteration 86, loss = 0.00160978
Iteration 87, loss = 0.00158566
Iteration 88, loss = 0.00152289
Iteration 89, loss = 0.00161894
Iteration 90, loss = 0.00147538
Iteration 91, loss = 0.00141661
Iteration 92, loss = 0.00140496
Iteration 93, loss = 0.00136324
Iteration 94, loss = 0.00135619
Iteration 95, loss = 0.00138051
Iteration 96, loss = 0.00133034
Iteration 97, loss = 0.00141554
Iteration 98, loss = 0.00131310
Iteration 99, loss = 0.00119493
Iteration 100, loss = 0.00120848
Iteration 101, loss = 0.00120600
Iteration 102, loss = 0.00116485
Iteration 103, loss = 0.00117719
Iteration 104, loss = 0.00122173
Iteration 105, loss = 0.00109228
Iteration 106, loss = 0.00111571
Iteration 107, loss = 0.00119471
Iteration 108, loss = 0.00121141
Iteration 109, loss = 0.00105506
Iteration 110, loss = 0.00103127
Iteration 111, loss = 0.00108212
Iteration 112, loss = 0.00109549
Iteration 113, loss = 0.00102553
Iteration 114, loss = 0.00102078
Iteration 115, loss = 0.00103421
Iteration 116, loss = 0.00109733
Iteration 117, loss = 0.00100969
Iteration 118, loss = 0.00097550
Iteration 119, loss = 0.00098011
Iteration 120, loss = 0.00113572
Iteration 121, loss = 0.00101700
Iteration 122, loss = 0.00094820
Iteration 123, loss = 0.00091748
Iteration 124, loss = 0.00091550
Iteration 125, loss = 0.00116297
Iteration 126, loss = 0.00098655
Iteration 127, loss = 0.00088962
Iteration 128, loss = 0.00086326
Iteration 129, loss = 0.00104310
Iteration 130, loss = 0.00095510
Iteration 131, loss = 0.00087084
Iteration 132, loss = 0.00086511
Iteration 133, loss = 0.00089084
Iteration 134, loss = 0.00089476
Iteration 135, loss = 0.00088777
Iteration 136, loss = 0.00117277
Iteration 137, loss = 0.00092998
Iteration 138, loss = 0.00082637
Iteration 139, loss = 0.00082969
Iteration 140, loss = 0.00085853
Iteration 141, loss = 0.00086440
Iteration 142, loss = 0.00090036
Iteration 143, loss = 0.00088811
Iteration 144, loss = 0.00100670
Iteration 145, loss = 0.00082204
Iteration 146, loss = 0.00081035
Iteration 147, loss = 0.00085332
Iteration 148, loss = 0.00089335
Iteration 149, loss = 0.00086814
Iteration 150, loss = 0.00098867
Iteration 151, loss = 0.00080863
Iteration 152, loss = 0.00079834
Iteration 153, loss = 0.00078644
Iteration 154, loss = 0.00080049
Iteration 155, loss = 0.00101448
Iteration 156, loss = 0.00118871
Iteration 157, loss = 0.00080244
Iteration 158, loss = 0.00077647
Iteration 159, loss = 0.00076609
Iteration 160, loss = 0.00077150
Iteration 161, loss = 0.00076853
Iteration 162, loss = 0.00080092
Iteration 163, loss = 0.00139038
Iteration 164, loss = 0.00083698
Iteration 165, loss = 0.00077700
Iteration 166, loss = 0.00076266
Iteration 167, loss = 0.00075959
Iteration 168, loss = 0.00075786
Iteration 169, loss = 0.00076778
Iteration 170, loss = 0.00076973
Iteration 171, loss = 0.00106487
Iteration 172, loss = 0.00138471
Iteration 173, loss = 0.00079815
Iteration 174, loss = 0.00075566
Iteration 175, loss = 0.00074825
Iteration 176, loss = 0.00074963
Iteration 177, loss = 0.00074484
Iteration 178, loss = 0.00074857
Iteration 179, loss = 0.00075591
Iteration 180, loss = 0.00079076
Iteration 181, loss = 0.00132883
Iteration 182, loss = 0.00077256
Iteration 183, loss = 0.00074439
Iteration 184, loss = 0.00073954
Iteration 185, loss = 0.00073643
Iteration 186, loss = 0.00073829
Iteration 187, loss = 0.00075875
Iteration 188, loss = 0.00081137
Iteration 189, loss = 0.00136294
Iteration 190, loss = 0.00078543
Iteration 191, loss = 0.00073690
Iteration 192, loss = 0.00072868
Iteration 193, loss = 0.00072557
Iteration 194, loss = 0.00072598
Iteration 195, loss = 0.00072734
Iteration 196, loss = 0.00075669
Iteration 197, loss = 0.00126428
Iteration 198, loss = 0.00085788
Iteration 199, loss = 0.00073793
Iteration 200, loss = 0.00072538
Iteration 1, loss = 0.12522370
Iteration 2, loss = 0.05878197
Iteration 3, loss = 0.04825269
Iteration 4, loss = 0.04148287
Iteration 5, loss = 0.03644702
Iteration 6, loss = 0.03257061
Iteration 7, loss = 0.02943424
Iteration 8, loss = 0.02695002
Iteration 9, loss = 0.02485726
Iteration 10, loss = 0.02311048
Iteration 11, loss = 0.02174908
Iteration 12, loss = 0.02035734
Iteration 13, loss = 0.01926979
Iteration 14, loss = 0.01821093
Iteration 15, loss = 0.01722471
Iteration 16, loss = 0.01650263
Iteration 17, loss = 0.01567617
Iteration 18, loss = 0.01487677
Iteration 19, loss = 0.01425139
Iteration 20, loss = 0.01360987
Iteration 21, loss = 0.01308667
Iteration 22, loss = 0.01233433
Iteration 23, loss = 0.01201848
Iteration 24, loss = 0.01151022
Iteration 25, loss = 0.01102526
Iteration 26, loss = 0.01073974
Iteration 27, loss = 0.01025502
Iteration 28, loss = 0.00982695
Iteration 29, loss = 0.00945139
Iteration 30, loss = 0.00915987
Iteration 31, loss = 0.00883914
Iteration 32, loss = 0.00838635
Iteration 33, loss = 0.00816826
Iteration 34, loss = 0.00788707
Iteration 35, loss = 0.00763255
Iteration 36, loss = 0.00724200
Iteration 37, loss = 0.00709586
Iteration 38, loss = 0.00681194
Iteration 39, loss = 0.00660897
Iteration 40, loss = 0.00635204
Iteration 41, loss = 0.00612776
Iteration 42, loss = 0.00599098
Iteration 43, loss = 0.00564674
Iteration 44, loss = 0.00556881
Iteration 45, loss = 0.00524840
Iteration 46, loss = 0.00508617
Iteration 47, loss = 0.00494303
Iteration 48, loss = 0.00478344
Iteration 49, loss = 0.00473602
Iteration 50, loss = 0.00449352
Iteration 51, loss = 0.00432289
Iteration 52, loss = 0.00425064
Iteration 53, loss = 0.00401947
Iteration 54, loss = 0.00399153
Iteration 55, loss = 0.00376258
Iteration 56, loss = 0.00372085
Iteration 57, loss = 0.00358004
Iteration 58, loss = 0.00347480
Iteration 59, loss = 0.00334195
Iteration 60, loss = 0.00325740
Iteration 61, loss = 0.00313910
Iteration 62, loss = 0.00308329
Iteration 63, loss = 0.00293280
Iteration 64, loss = 0.00279060
Iteration 65, loss = 0.00282061
Iteration 66, loss = 0.00269866
Iteration 67, loss = 0.00266070
Iteration 68, loss = 0.00252535
Iteration 69, loss = 0.00246969
Iteration 70, loss = 0.00235945
Iteration 71, loss = 0.00231832
Iteration 72, loss = 0.00224059
Iteration 73, loss = 0.00219061
Iteration 74, loss = 0.00214185
Iteration 75, loss = 0.00206391
Iteration 76, loss = 0.00202361
Iteration 77, loss = 0.00198219
Iteration 78, loss = 0.00190633
Iteration 79, loss = 0.00189655
Iteration 80, loss = 0.00181527
Iteration 81, loss = 0.00179419
Iteration 82, loss = 0.00178239
Iteration 83, loss = 0.00166843
Iteration 84, loss = 0.00162344
Iteration 85, loss = 0.00172782
Iteration 86, loss = 0.00151143
Iteration 87, loss = 0.00157743
Iteration 88, loss = 0.00150755
Iteration 89, loss = 0.00148182
Iteration 90, loss = 0.00151220
Iteration 91, loss = 0.00140879
Iteration 92, loss = 0.00140929
Iteration 93, loss = 0.00139532
Iteration 94, loss = 0.00136852
Iteration 95, loss = 0.00136907
Iteration 96, loss = 0.00132136
Iteration 97, loss = 0.00128106
Iteration 98, loss = 0.00125867
Iteration 99, loss = 0.00121171
Iteration 100, loss = 0.00132232
Iteration 101, loss = 0.00117836
Iteration 102, loss = 0.00120616
Iteration 103, loss = 0.00115638
Iteration 104, loss = 0.00124310
Iteration 105, loss = 0.00126433
Iteration 106, loss = 0.00108121
Iteration 107, loss = 0.00110558
Iteration 108, loss = 0.00105274
Iteration 109, loss = 0.00110136
Iteration 110, loss = 0.00107077
Iteration 111, loss = 0.00111591
Iteration 112, loss = 0.00105058
Iteration 113, loss = 0.00106769
Iteration 114, loss = 0.00100657
Iteration 115, loss = 0.00105116
Iteration 116, loss = 0.00108192
Iteration 117, loss = 0.00096224
Iteration 118, loss = 0.00094547
Iteration 119, loss = 0.00106862
Iteration 120, loss = 0.00112033
Iteration 121, loss = 0.00103197
Iteration 122, loss = 0.00093583
Iteration 123, loss = 0.00092904
Iteration 124, loss = 0.00094205
Iteration 125, loss = 0.00105444
Iteration 126, loss = 0.00095863
Iteration 127, loss = 0.00090664
Iteration 128, loss = 0.00092347
Iteration 129, loss = 0.00099937
Iteration 130, loss = 0.00125883
Iteration 131, loss = 0.00090045
Iteration 132, loss = 0.00085206
Iteration 133, loss = 0.00085633
Iteration 134, loss = 0.00085985
Iteration 135, loss = 0.00086148
Iteration 136, loss = 0.00090656
Iteration 137, loss = 0.00112796
Iteration 138, loss = 0.00090450
Iteration 139, loss = 0.00083700
Iteration 140, loss = 0.00082751
Iteration 141, loss = 0.00083908
Iteration 142, loss = 0.00091830
Iteration 143, loss = 0.00099092
Iteration 144, loss = 0.00087761
Iteration 145, loss = 0.00085000
Iteration 146, loss = 0.00082335
Iteration 147, loss = 0.00127633
Iteration 148, loss = 0.00108999
Iteration 149, loss = 0.00082281
Iteration 150, loss = 0.00080004
Iteration 151, loss = 0.00079568
Iteration 152, loss = 0.00079811
Iteration 153, loss = 0.00081144
Iteration 154, loss = 0.00083271
Iteration 155, loss = 0.00084610
Iteration 156, loss = 0.00081851
Iteration 157, loss = 0.00120845
Iteration 158, loss = 0.00102051
Iteration 159, loss = 0.00080778
Iteration 160, loss = 0.00078976
Iteration 161, loss = 0.00077992
Iteration 162, loss = 0.00077592
Iteration 163, loss = 0.00083152
Iteration 164, loss = 0.00108131
Iteration 165, loss = 0.00082463
Iteration 166, loss = 0.00077755
Iteration 167, loss = 0.00077254
Iteration 168, loss = 0.00077661
Iteration 169, loss = 0.00078711
Iteration 170, loss = 0.00105910
Iteration 171, loss = 0.00092058
Iteration 172, loss = 0.00078371
Iteration 173, loss = 0.00077107
Iteration 174, loss = 0.00076750
Iteration 175, loss = 0.00076258
Iteration 176, loss = 0.00078258
Iteration 177, loss = 0.00121054
Iteration 178, loss = 0.00081310
Iteration 179, loss = 0.00077052
Iteration 180, loss = 0.00076313
Iteration 181, loss = 0.00075300
Iteration 182, loss = 0.00077788
Iteration 183, loss = 0.00077719
Iteration 184, loss = 0.00102079
Iteration 185, loss = 0.00084240
Iteration 186, loss = 0.00076595
Iteration 187, loss = 0.00074691
Iteration 188, loss = 0.00075013
Iteration 189, loss = 0.00075037
Iteration 190, loss = 0.00079035
Iteration 191, loss = 0.00092828
Iteration 192, loss = 0.00101331
Iteration 193, loss = 0.00077388
Iteration 194, loss = 0.00074803
Iteration 195, loss = 0.00075271
Iteration 196, loss = 0.00073931
Iteration 197, loss = 0.00076285
Iteration 198, loss = 0.00100637
Iteration 199, loss = 0.00117413
Iteration 200, loss = 0.00075603
Iteration 1, loss = 0.16118620
Iteration 2, loss = 0.06871100
Iteration 3, loss = 0.05864905
Iteration 4, loss = 0.05275047
Iteration 5, loss = 0.04717174
Iteration 6, loss = 0.04242487
Iteration 7, loss = 0.03841099
Iteration 8, loss = 0.03525256
Iteration 9, loss = 0.03261068
Iteration 10, loss = 0.03028563
Iteration 11, loss = 0.02845471
Iteration 12, loss = 0.02692972
Iteration 13, loss = 0.02552083
Iteration 14, loss = 0.02437995
Iteration 15, loss = 0.02344389
Iteration 16, loss = 0.02245670
Iteration 17, loss = 0.02165787
Iteration 18, loss = 0.02085448
Iteration 19, loss = 0.02026331
Iteration 20, loss = 0.01960142
Iteration 21, loss = 0.01891209
Iteration 22, loss = 0.01842167
Iteration 23, loss = 0.01785080
Iteration 24, loss = 0.01734716
Iteration 25, loss = 0.01692159
Iteration 26, loss = 0.01651821
Iteration 27, loss = 0.01599693
Iteration 28, loss = 0.01558379
Iteration 29, loss = 0.01520256
Iteration 30, loss = 0.01482764
Iteration 31, loss = 0.01453849
Iteration 32, loss = 0.01416181
Iteration 33, loss = 0.01375938
Iteration 34, loss = 0.01354576
Iteration 35, loss = 0.01316179
Iteration 36, loss = 0.01277538
Iteration 37, loss = 0.01252986
Iteration 38, loss = 0.01225692
Iteration 39, loss = 0.01199095
Iteration 40, loss = 0.01170411
Iteration 41, loss = 0.01147163
Iteration 42, loss = 0.01126397
Iteration 43, loss = 0.01100834
Iteration 44, loss = 0.01082142
Iteration 45, loss = 0.01049424
Iteration 46, loss = 0.01038780
Iteration 47, loss = 0.01013497
Iteration 48, loss = 0.00990468
Iteration 49, loss = 0.00976058
Iteration 50, loss = 0.00956771
Iteration 51, loss = 0.00937553
Iteration 52, loss = 0.00915624
Iteration 53, loss = 0.00902933
Iteration 54, loss = 0.00887477
Iteration 55, loss = 0.00867111
Iteration 56, loss = 0.00858374
Iteration 57, loss = 0.00839280
Iteration 58, loss = 0.00830819
Iteration 59, loss = 0.00810597
Iteration 60, loss = 0.00794757
Iteration 61, loss = 0.00784375
Iteration 62, loss = 0.00776028
Iteration 63, loss = 0.00761740
Iteration 64, loss = 0.00743082
Iteration 65, loss = 0.00740891
Iteration 66, loss = 0.00715958
Iteration 67, loss = 0.00713250
Iteration 68, loss = 0.00703469
Iteration 69, loss = 0.00690234
Iteration 70, loss = 0.00673680
Iteration 71, loss = 0.00667861
Iteration 72, loss = 0.00652215
Iteration 73, loss = 0.00646997
Iteration 74, loss = 0.00633194
Iteration 75, loss = 0.00628585
Iteration 76, loss = 0.00615873
Iteration 77, loss = 0.00607531
Iteration 78, loss = 0.00604608
Iteration 79, loss = 0.00590909
Iteration 80, loss = 0.00583139
Iteration 81, loss = 0.00575381
Iteration 82, loss = 0.00571346
Iteration 83, loss = 0.00559698
Iteration 84, loss = 0.00554329
Iteration 85, loss = 0.00536373
Iteration 86, loss = 0.00536537
Iteration 87, loss = 0.00529104
Iteration 88, loss = 0.00518319
Iteration 89, loss = 0.00518397
Iteration 90, loss = 0.00500791
Iteration 91, loss = 0.00500627
Iteration 92, loss = 0.00492681
Iteration 93, loss = 0.00481859
Iteration 94, loss = 0.00480346
Iteration 95, loss = 0.00473418
Iteration 96, loss = 0.00461694
Iteration 97, loss = 0.00458172
Iteration 98, loss = 0.00451885
Iteration 99, loss = 0.00448540
Iteration 100, loss = 0.00444861
Iteration 101, loss = 0.00439738
Iteration 102, loss = 0.00428040
Iteration 103, loss = 0.00431062
Iteration 104, loss = 0.00418815
Iteration 105, loss = 0.00411001
Iteration 106, loss = 0.00412794
Iteration 107, loss = 0.00411110
Iteration 108, loss = 0.00400897
Iteration 109, loss = 0.00389730
Iteration 110, loss = 0.00391336
Iteration 111, loss = 0.00385261
Iteration 112, loss = 0.00377161
Iteration 113, loss = 0.00377456
Iteration 114, loss = 0.00367713
Iteration 115, loss = 0.00365020
Iteration 116, loss = 0.00364263
Iteration 117, loss = 0.00365643
Iteration 118, loss = 0.00351005
Iteration 119, loss = 0.00353575
Iteration 120, loss = 0.00342186
Iteration 121, loss = 0.00345167
Iteration 122, loss = 0.00337549
Iteration 123, loss = 0.00340242
Iteration 124, loss = 0.00328477
Iteration 125, loss = 0.00325948
Iteration 126, loss = 0.00322381
Iteration 127, loss = 0.00318796
Iteration 128, loss = 0.00318898
Iteration 129, loss = 0.00307391
Iteration 130, loss = 0.00308506
Iteration 131, loss = 0.00311704
Iteration 132, loss = 0.00300759
Iteration 133, loss = 0.00305458
Iteration 134, loss = 0.00301088
Iteration 135, loss = 0.00297052
Iteration 136, loss = 0.00288987
Iteration 137, loss = 0.00289510
Iteration 138, loss = 0.00284535
Iteration 139, loss = 0.00281006
Iteration 140, loss = 0.00279772
Iteration 141, loss = 0.00288423
Iteration 142, loss = 0.00272941
Iteration 143, loss = 0.00278060
Iteration 144, loss = 0.00268121
Iteration 145, loss = 0.00270054
Iteration 146, loss = 0.00269915
Iteration 147, loss = 0.00266492
Iteration 148, loss = 0.00266995
Iteration 149, loss = 0.00257586
Iteration 150, loss = 0.00258427
Iteration 151, loss = 0.00254810
Iteration 152, loss = 0.00254214
Iteration 153, loss = 0.00253260
Iteration 154, loss = 0.00248252
Iteration 155, loss = 0.00249188
Iteration 156, loss = 0.00242398
Iteration 157, loss = 0.00242465
Iteration 158, loss = 0.00244359
Iteration 159, loss = 0.00236121
Iteration 160, loss = 0.00234091
Iteration 161, loss = 0.00236594
Iteration 162, loss = 0.00236285
Iteration 163, loss = 0.00228509
Iteration 164, loss = 0.00229120
Iteration 165, loss = 0.00237730
Iteration 166, loss = 0.00225220
Iteration 167, loss = 0.00226121
Iteration 168, loss = 0.00225122
Iteration 169, loss = 0.00219657
Iteration 170, loss = 0.00222361
Iteration 171, loss = 0.00217309
Iteration 172, loss = 0.00226555
Iteration 173, loss = 0.00218137
Iteration 174, loss = 0.00218040
Iteration 175, loss = 0.00211015
Iteration 176, loss = 0.00212018
Iteration 177, loss = 0.00217068
Iteration 178, loss = 0.00209648
Iteration 179, loss = 0.00210983
Iteration 180, loss = 0.00209999
Iteration 181, loss = 0.00211519
Iteration 182, loss = 0.00208053
Iteration 183, loss = 0.00205072
Iteration 184, loss = 0.00205542
Iteration 185, loss = 0.00200288
Iteration 186, loss = 0.00201528
Iteration 187, loss = 0.00202109
Iteration 188, loss = 0.00201769
Iteration 189, loss = 0.00201274
Iteration 190, loss = 0.00199507
Iteration 191, loss = 0.00200231
Iteration 192, loss = 0.00195923
Iteration 193, loss = 0.00197588
Iteration 194, loss = 0.00197756
Iteration 195, loss = 0.00191176
Iteration 196, loss = 0.00189935
Iteration 197, loss = 0.00193914
Iteration 198, loss = 0.00193704
Iteration 199, loss = 0.00192206
Iteration 200, loss = 0.00194073
Iteration 1, loss = 0.14401358
Iteration 2, loss = 0.06722537
Iteration 3, loss = 0.05736767
Iteration 4, loss = 0.05046736
Iteration 5, loss = 0.04457923
Iteration 6, loss = 0.03974281
Iteration 7, loss = 0.03602406
Iteration 8, loss = 0.03310760
Iteration 9, loss = 0.03086237
Iteration 10, loss = 0.02896294
Iteration 11, loss = 0.02748564
Iteration 12, loss = 0.02608934
Iteration 13, loss = 0.02503103
Iteration 14, loss = 0.02401728
Iteration 15, loss = 0.02300902
Iteration 16, loss = 0.02227771
Iteration 17, loss = 0.02158252
Iteration 18, loss = 0.02073651
Iteration 19, loss = 0.02014864
Iteration 20, loss = 0.01968540
Iteration 21, loss = 0.01886307
Iteration 22, loss = 0.01845074
Iteration 23, loss = 0.01794292
Iteration 24, loss = 0.01742552
Iteration 25, loss = 0.01691765
Iteration 26, loss = 0.01651478
Iteration 27, loss = 0.01617205
Iteration 28, loss = 0.01572141
Iteration 29, loss = 0.01532826
Iteration 30, loss = 0.01502899
Iteration 31, loss = 0.01462312
Iteration 32, loss = 0.01434920
Iteration 33, loss = 0.01402554
Iteration 34, loss = 0.01364317
Iteration 35, loss = 0.01335951
Iteration 36, loss = 0.01310957
Iteration 37, loss = 0.01292818
Iteration 38, loss = 0.01259521
Iteration 39, loss = 0.01229687
Iteration 40, loss = 0.01207751
Iteration 41, loss = 0.01186284
Iteration 42, loss = 0.01172703
Iteration 43, loss = 0.01139005
Iteration 44, loss = 0.01124781
Iteration 45, loss = 0.01099664
Iteration 46, loss = 0.01077264
Iteration 47, loss = 0.01061429
Iteration 48, loss = 0.01040981
Iteration 49, loss = 0.01016043
Iteration 50, loss = 0.01008445
Iteration 51, loss = 0.00983548
Iteration 52, loss = 0.00966716
Iteration 53, loss = 0.00947133
Iteration 54, loss = 0.00938723
Iteration 55, loss = 0.00922840
Iteration 56, loss = 0.00899101
Iteration 57, loss = 0.00886934
Iteration 58, loss = 0.00869438
Iteration 59, loss = 0.00854690
Iteration 60, loss = 0.00842203
Iteration 61, loss = 0.00828496
Iteration 62, loss = 0.00817353
Iteration 63, loss = 0.00805869
Iteration 64, loss = 0.00788981
Iteration 65, loss = 0.00769004
Iteration 66, loss = 0.00756559
Iteration 67, loss = 0.00749010
Iteration 68, loss = 0.00739005
Iteration 69, loss = 0.00728045
Iteration 70, loss = 0.00714523
Iteration 71, loss = 0.00695777
Iteration 72, loss = 0.00691159
Iteration 73, loss = 0.00681396
Iteration 74, loss = 0.00661602
Iteration 75, loss = 0.00663557
Iteration 76, loss = 0.00660653
Iteration 77, loss = 0.00640776
Iteration 78, loss = 0.00630820
Iteration 79, loss = 0.00625863
Iteration 80, loss = 0.00615741
Iteration 81, loss = 0.00601274
Iteration 82, loss = 0.00593503
Iteration 83, loss = 0.00597665
Iteration 84, loss = 0.00575666
Iteration 85, loss = 0.00561426
Iteration 86, loss = 0.00557595
Iteration 87, loss = 0.00554403
Iteration 88, loss = 0.00545797
Iteration 89, loss = 0.00535077
Iteration 90, loss = 0.00532436
Iteration 91, loss = 0.00522976
Iteration 92, loss = 0.00517795
Iteration 93, loss = 0.00508846
Iteration 94, loss = 0.00503111
Iteration 95, loss = 0.00494188
Iteration 96, loss = 0.00488841
Iteration 97, loss = 0.00480933
Iteration 98, loss = 0.00467580
Iteration 99, loss = 0.00474100
Iteration 100, loss = 0.00462292
Iteration 101, loss = 0.00458739
Iteration 102, loss = 0.00441307
Iteration 103, loss = 0.00443648
Iteration 104, loss = 0.00436832
Iteration 105, loss = 0.00430779
Iteration 106, loss = 0.00423766
Iteration 107, loss = 0.00426885
Iteration 108, loss = 0.00417248
Iteration 109, loss = 0.00406713
Iteration 110, loss = 0.00406062
Iteration 111, loss = 0.00399376
Iteration 112, loss = 0.00387162
Iteration 113, loss = 0.00389154
Iteration 114, loss = 0.00381506
Iteration 115, loss = 0.00382041
Iteration 116, loss = 0.00377711
Iteration 117, loss = 0.00371827
Iteration 118, loss = 0.00363429
Iteration 119, loss = 0.00365798
Iteration 120, loss = 0.00355879
Iteration 121, loss = 0.00354290
Iteration 122, loss = 0.00348286
Iteration 123, loss = 0.00343876
Iteration 124, loss = 0.00339154
Iteration 125, loss = 0.00338577
Iteration 126, loss = 0.00327512
Iteration 127, loss = 0.00331776
Iteration 128, loss = 0.00324561
Iteration 129, loss = 0.00316509
Iteration 130, loss = 0.00321182
Iteration 131, loss = 0.00314983
Iteration 132, loss = 0.00312414
Iteration 133, loss = 0.00306931
Iteration 134, loss = 0.00309087
Iteration 135, loss = 0.00301073
Iteration 136, loss = 0.00300444
Iteration 137, loss = 0.00296197
Iteration 138, loss = 0.00290812
Iteration 139, loss = 0.00287698
Iteration 140, loss = 0.00294557
Iteration 141, loss = 0.00283615
Iteration 142, loss = 0.00279538
Iteration 143, loss = 0.00274030
Iteration 144, loss = 0.00278373
Iteration 145, loss = 0.00278495
Iteration 146, loss = 0.00268629
Iteration 147, loss = 0.00264274
Iteration 148, loss = 0.00269238
Iteration 149, loss = 0.00265553
Iteration 150, loss = 0.00254474
Iteration 151, loss = 0.00256910
Iteration 152, loss = 0.00256988
Iteration 153, loss = 0.00254389
Iteration 154, loss = 0.00257121
Iteration 155, loss = 0.00253463
Iteration 156, loss = 0.00242905
Iteration 157, loss = 0.00243522
Iteration 158, loss = 0.00243908
Iteration 159, loss = 0.00238348
Iteration 160, loss = 0.00242055
Iteration 161, loss = 0.00241312
Iteration 162, loss = 0.00233674
Iteration 163, loss = 0.00228873
Iteration 164, loss = 0.00233362
Iteration 165, loss = 0.00235383
Iteration 166, loss = 0.00227784
Iteration 167, loss = 0.00227877
Iteration 168, loss = 0.00223516
Iteration 169, loss = 0.00225734
Iteration 170, loss = 0.00220995
Iteration 171, loss = 0.00220866
Iteration 172, loss = 0.00218829
Iteration 173, loss = 0.00216358
Iteration 174, loss = 0.00220294
Iteration 175, loss = 0.00212830
Iteration 176, loss = 0.00215016
Iteration 177, loss = 0.00210221
Iteration 178, loss = 0.00206576
Iteration 179, loss = 0.00215533
Iteration 180, loss = 0.00208781
Iteration 181, loss = 0.00204220
Iteration 182, loss = 0.00211475
Iteration 183, loss = 0.00202862
Iteration 184, loss = 0.00213141
Iteration 185, loss = 0.00198523
Iteration 186, loss = 0.00204279
Iteration 187, loss = 0.00193691
Iteration 188, loss = 0.00200402
Iteration 189, loss = 0.00196568
Iteration 190, loss = 0.00198088
Iteration 191, loss = 0.00192357
Iteration 192, loss = 0.00196737
Iteration 193, loss = 0.00195050
Iteration 194, loss = 0.00191055
Iteration 195, loss = 0.00193924
Iteration 196, loss = 0.00189698
Iteration 197, loss = 0.00192917
Iteration 198, loss = 0.00189965
Iteration 199, loss = 0.00188187
Iteration 200, loss = 0.00191317
Iteration 1, loss = 0.14548801
Iteration 2, loss = 0.06693804
Iteration 3, loss = 0.05684290
Iteration 4, loss = 0.05023214
Iteration 5, loss = 0.04426459
Iteration 6, loss = 0.03971033
Iteration 7, loss = 0.03636915
Iteration 8, loss = 0.03368300
Iteration 9, loss = 0.03160878
Iteration 10, loss = 0.02976778
Iteration 11, loss = 0.02822784
Iteration 12, loss = 0.02674817
Iteration 13, loss = 0.02568774
Iteration 14, loss = 0.02447249
Iteration 15, loss = 0.02364240
Iteration 16, loss = 0.02278957
Iteration 17, loss = 0.02195496
Iteration 18, loss = 0.02120745
Iteration 19, loss = 0.02052660
Iteration 20, loss = 0.01998495
Iteration 21, loss = 0.01949127
Iteration 22, loss = 0.01878868
Iteration 23, loss = 0.01840185
Iteration 24, loss = 0.01790490
Iteration 25, loss = 0.01746282
Iteration 26, loss = 0.01701394
Iteration 27, loss = 0.01658623
Iteration 28, loss = 0.01623932
Iteration 29, loss = 0.01583708
Iteration 30, loss = 0.01551955
Iteration 31, loss = 0.01518625
Iteration 32, loss = 0.01481252
Iteration 33, loss = 0.01444556
Iteration 34, loss = 0.01419993
Iteration 35, loss = 0.01393828
Iteration 36, loss = 0.01362743
Iteration 37, loss = 0.01347970
Iteration 38, loss = 0.01312329
Iteration 39, loss = 0.01288390
Iteration 40, loss = 0.01258421
Iteration 41, loss = 0.01246178
Iteration 42, loss = 0.01212416
Iteration 43, loss = 0.01195456
Iteration 44, loss = 0.01169640
Iteration 45, loss = 0.01149189
Iteration 46, loss = 0.01125473
Iteration 47, loss = 0.01121343
Iteration 48, loss = 0.01091960
Iteration 49, loss = 0.01073183
Iteration 50, loss = 0.01055053
Iteration 51, loss = 0.01043051
Iteration 52, loss = 0.01016730
Iteration 53, loss = 0.01008446
Iteration 54, loss = 0.00991629
Iteration 55, loss = 0.00969026
Iteration 56, loss = 0.00958596
Iteration 57, loss = 0.00950556
Iteration 58, loss = 0.00916036
Iteration 59, loss = 0.00918170
Iteration 60, loss = 0.00897382
Iteration 61, loss = 0.00881773
Iteration 62, loss = 0.00873948
Iteration 63, loss = 0.00859500
Iteration 64, loss = 0.00846417
Iteration 65, loss = 0.00826073
Iteration 66, loss = 0.00828925
Iteration 67, loss = 0.00809522
Iteration 68, loss = 0.00804220
Iteration 69, loss = 0.00782745
Iteration 70, loss = 0.00766415
Iteration 71, loss = 0.00769338
Iteration 72, loss = 0.00752723
Iteration 73, loss = 0.00740458
Iteration 74, loss = 0.00738546
Iteration 75, loss = 0.00727329
Iteration 76, loss = 0.00711686
Iteration 77, loss = 0.00699662
Iteration 78, loss = 0.00697308
Iteration 79, loss = 0.00683979
Iteration 80, loss = 0.00669097
Iteration 81, loss = 0.00673982
Iteration 82, loss = 0.00658516
Iteration 83, loss = 0.00642064
Iteration 84, loss = 0.00644040
Iteration 85, loss = 0.00633286
Iteration 86, loss = 0.00623898
Iteration 87, loss = 0.00618186
Iteration 88, loss = 0.00612731
Iteration 89, loss = 0.00601637
Iteration 90, loss = 0.00604879
Iteration 91, loss = 0.00586527
Iteration 92, loss = 0.00576561
Iteration 93, loss = 0.00575344
Iteration 94, loss = 0.00560230
Iteration 95, loss = 0.00557105
Iteration 96, loss = 0.00556059
Iteration 97, loss = 0.00548580
Iteration 98, loss = 0.00545150
Iteration 99, loss = 0.00531560
Iteration 100, loss = 0.00526811
Iteration 101, loss = 0.00519682
Iteration 102, loss = 0.00521696
Iteration 103, loss = 0.00506033
Iteration 104, loss = 0.00515663
Iteration 105, loss = 0.00496138
Iteration 106, loss = 0.00491385
Iteration 107, loss = 0.00486819
Iteration 108, loss = 0.00478470
Iteration 109, loss = 0.00474660
Iteration 110, loss = 0.00470307
Iteration 111, loss = 0.00453283
Iteration 112, loss = 0.00457069
Iteration 113, loss = 0.00458894
Iteration 114, loss = 0.00459589
Iteration 115, loss = 0.00442118
Iteration 116, loss = 0.00447485
Iteration 117, loss = 0.00441173
Iteration 118, loss = 0.00443126
Iteration 119, loss = 0.00422363
Iteration 120, loss = 0.00428747
Iteration 121, loss = 0.00412701
Iteration 122, loss = 0.00413885
Iteration 123, loss = 0.00412546
Iteration 124, loss = 0.00399383
Iteration 125, loss = 0.00403468
Iteration 126, loss = 0.00397658
Iteration 127, loss = 0.00392225
Iteration 128, loss = 0.00391043
Iteration 129, loss = 0.00387114
Iteration 130, loss = 0.00388260
Iteration 131, loss = 0.00377444
Iteration 132, loss = 0.00379015
Iteration 133, loss = 0.00370496
Iteration 134, loss = 0.00365611
Iteration 135, loss = 0.00371343
Iteration 136, loss = 0.00358886
Iteration 137, loss = 0.00351273
Iteration 138, loss = 0.00348929
Iteration 139, loss = 0.00355536
Iteration 140, loss = 0.00353213
Iteration 141, loss = 0.00339120
Iteration 142, loss = 0.00334776
Iteration 143, loss = 0.00336338
Iteration 144, loss = 0.00342754
Iteration 145, loss = 0.00326898
Iteration 146, loss = 0.00322672
Iteration 147, loss = 0.00332805
Iteration 148, loss = 0.00324938
Iteration 149, loss = 0.00319769
Iteration 150, loss = 0.00323414
Iteration 151, loss = 0.00310419
Iteration 152, loss = 0.00308517
Iteration 153, loss = 0.00310265
Iteration 154, loss = 0.00305650
Iteration 155, loss = 0.00304020
Iteration 156, loss = 0.00305224
Iteration 157, loss = 0.00301791
Iteration 158, loss = 0.00286576
Iteration 159, loss = 0.00291753
Iteration 160, loss = 0.00293488
Iteration 161, loss = 0.00291169
Iteration 162, loss = 0.00284462
Iteration 163, loss = 0.00283557
Iteration 164, loss = 0.00282147
Iteration 165, loss = 0.00280712
Iteration 166, loss = 0.00274625
Iteration 167, loss = 0.00273344
Iteration 168, loss = 0.00271829
Iteration 169, loss = 0.00271359
Iteration 170, loss = 0.00272331
Iteration 171, loss = 0.00271263
Iteration 172, loss = 0.00266896
Iteration 173, loss = 0.00271596
Iteration 174, loss = 0.00259976
Iteration 175, loss = 0.00263315
Iteration 176, loss = 0.00254241
Iteration 177, loss = 0.00251765
Iteration 178, loss = 0.00259571
Iteration 179, loss = 0.00252632
Iteration 180, loss = 0.00250525
Iteration 181, loss = 0.00249097
Iteration 182, loss = 0.00245057
Iteration 183, loss = 0.00251439
Iteration 184, loss = 0.00247385
Iteration 185, loss = 0.00239794
Iteration 186, loss = 0.00239595
Iteration 187, loss = 0.00242413
Iteration 188, loss = 0.00242651
Iteration 189, loss = 0.00243302
Iteration 190, loss = 0.00236885
Iteration 191, loss = 0.00231560
Iteration 192, loss = 0.00234027
Iteration 193, loss = 0.00232391
Iteration 194, loss = 0.00229866
Iteration 195, loss = 0.00224561
Iteration 196, loss = 0.00229538
Iteration 197, loss = 0.00229874
Iteration 198, loss = 0.00224143
Iteration 199, loss = 0.00225272
Iteration 200, loss = 0.00228393
Iteration 1, loss = 0.15075833
Iteration 2, loss = 0.06586488
Iteration 3, loss = 0.05580008
Iteration 4, loss = 0.04828759
Iteration 5, loss = 0.04253715
Iteration 6, loss = 0.03825795
Iteration 7, loss = 0.03491656
Iteration 8, loss = 0.03235833
Iteration 9, loss = 0.03007305
Iteration 10, loss = 0.02807635
Iteration 11, loss = 0.02648269
Iteration 12, loss = 0.02501309
Iteration 13, loss = 0.02381649
Iteration 14, loss = 0.02262448
Iteration 15, loss = 0.02165981
Iteration 16, loss = 0.02075634
Iteration 17, loss = 0.01983536
Iteration 18, loss = 0.01918632
Iteration 19, loss = 0.01839505
Iteration 20, loss = 0.01778188
Iteration 21, loss = 0.01724700
Iteration 22, loss = 0.01668501
Iteration 23, loss = 0.01608993
Iteration 24, loss = 0.01570085
Iteration 25, loss = 0.01524873
Iteration 26, loss = 0.01477355
Iteration 27, loss = 0.01440150
Iteration 28, loss = 0.01387006
Iteration 29, loss = 0.01348907
Iteration 30, loss = 0.01319320
Iteration 31, loss = 0.01281789
Iteration 32, loss = 0.01254618
Iteration 33, loss = 0.01220268
Iteration 34, loss = 0.01189248
Iteration 35, loss = 0.01163723
Iteration 36, loss = 0.01128577
Iteration 37, loss = 0.01113103
Iteration 38, loss = 0.01079334
Iteration 39, loss = 0.01054204
Iteration 40, loss = 0.01026757
Iteration 41, loss = 0.01002678
Iteration 42, loss = 0.00980974
Iteration 43, loss = 0.00954299
Iteration 44, loss = 0.00935068
Iteration 45, loss = 0.00912857
Iteration 46, loss = 0.00902420
Iteration 47, loss = 0.00874602
Iteration 48, loss = 0.00859179
Iteration 49, loss = 0.00836798
Iteration 50, loss = 0.00821771
Iteration 51, loss = 0.00796590
Iteration 52, loss = 0.00784014
Iteration 53, loss = 0.00759154
Iteration 54, loss = 0.00744901
Iteration 55, loss = 0.00736246
Iteration 56, loss = 0.00721718
Iteration 57, loss = 0.00706660
Iteration 58, loss = 0.00685648
Iteration 59, loss = 0.00670590
Iteration 60, loss = 0.00664388
Iteration 61, loss = 0.00642350
Iteration 62, loss = 0.00629197
Iteration 63, loss = 0.00621829
Iteration 64, loss = 0.00612067
Iteration 65, loss = 0.00588102
Iteration 66, loss = 0.00584713
Iteration 67, loss = 0.00567088
Iteration 68, loss = 0.00560999
Iteration 69, loss = 0.00554436
Iteration 70, loss = 0.00546055
Iteration 71, loss = 0.00530658
Iteration 72, loss = 0.00520900
Iteration 73, loss = 0.00506303
Iteration 74, loss = 0.00491958
Iteration 75, loss = 0.00489630
Iteration 76, loss = 0.00487160
Iteration 77, loss = 0.00477282
Iteration 78, loss = 0.00464713
Iteration 79, loss = 0.00447241
Iteration 80, loss = 0.00449140
Iteration 81, loss = 0.00439658
Iteration 82, loss = 0.00433428
Iteration 83, loss = 0.00423117
Iteration 84, loss = 0.00417006
Iteration 85, loss = 0.00419665
Iteration 86, loss = 0.00403700
Iteration 87, loss = 0.00398411
Iteration 88, loss = 0.00380093
Iteration 89, loss = 0.00379792
Iteration 90, loss = 0.00384184
Iteration 91, loss = 0.00375612
Iteration 92, loss = 0.00369095
Iteration 93, loss = 0.00354542
Iteration 94, loss = 0.00353600
Iteration 95, loss = 0.00350411
Iteration 96, loss = 0.00343468
Iteration 97, loss = 0.00338209
Iteration 98, loss = 0.00331918
Iteration 99, loss = 0.00330245
Iteration 100, loss = 0.00329151
Iteration 101, loss = 0.00318060
Iteration 102, loss = 0.00309772
Iteration 103, loss = 0.00302448
Iteration 104, loss = 0.00302835
Iteration 105, loss = 0.00305186
Iteration 106, loss = 0.00289805
Iteration 107, loss = 0.00291510
Iteration 108, loss = 0.00288735
Iteration 109, loss = 0.00279182
Iteration 110, loss = 0.00282887
Iteration 111, loss = 0.00271879
Iteration 112, loss = 0.00269588
Iteration 113, loss = 0.00266090
Iteration 114, loss = 0.00260130
Iteration 115, loss = 0.00263320
Iteration 116, loss = 0.00257938
Iteration 117, loss = 0.00257769
Iteration 118, loss = 0.00247302
Iteration 119, loss = 0.00245916
Iteration 120, loss = 0.00242799
Iteration 121, loss = 0.00244532
Iteration 122, loss = 0.00244192
Iteration 123, loss = 0.00234346
Iteration 124, loss = 0.00236502
Iteration 125, loss = 0.00231122
Iteration 126, loss = 0.00229113
Iteration 127, loss = 0.00226964
Iteration 128, loss = 0.00221337
Iteration 129, loss = 0.00222547
Iteration 130, loss = 0.00217032
Iteration 131, loss = 0.00219910
Iteration 132, loss = 0.00213837
Iteration 133, loss = 0.00213734
Iteration 134, loss = 0.00214846
Iteration 135, loss = 0.00212487
Iteration 136, loss = 0.00211341
Iteration 137, loss = 0.00207230
Iteration 138, loss = 0.00204535
Iteration 139, loss = 0.00202611
Iteration 140, loss = 0.00199237
Iteration 141, loss = 0.00200561
Iteration 142, loss = 0.00199802
Iteration 143, loss = 0.00194964
Iteration 144, loss = 0.00198277
Iteration 145, loss = 0.00193020
Iteration 146, loss = 0.00205126
Iteration 147, loss = 0.00188661
Iteration 148, loss = 0.00185322
Iteration 149, loss = 0.00188230
Iteration 150, loss = 0.00189138
Iteration 151, loss = 0.00183196
Iteration 152, loss = 0.00186808
Iteration 153, loss = 0.00184356
Iteration 154, loss = 0.00182480
Iteration 155, loss = 0.00178981
Iteration 156, loss = 0.00178561
Iteration 157, loss = 0.00190304
Iteration 158, loss = 0.00181950
Iteration 159, loss = 0.00183634
Iteration 160, loss = 0.00179868
Iteration 161, loss = 0.00176394
Iteration 162, loss = 0.00172751
Iteration 163, loss = 0.00177117
Iteration 164, loss = 0.00172763
Iteration 165, loss = 0.00169973
Iteration 166, loss = 0.00170370
Iteration 167, loss = 0.00176801
Iteration 168, loss = 0.00174522
Iteration 169, loss = 0.00168297
Iteration 170, loss = 0.00166688
Iteration 171, loss = 0.00177541
Iteration 172, loss = 0.00168042
Iteration 173, loss = 0.00161655
Iteration 174, loss = 0.00167584
Iteration 175, loss = 0.00166789
Iteration 176, loss = 0.00164100
Iteration 177, loss = 0.00162627
Iteration 178, loss = 0.00173661
Iteration 179, loss = 0.00158948
Iteration 180, loss = 0.00160086
Iteration 181, loss = 0.00168066
Iteration 182, loss = 0.00171755
Iteration 183, loss = 0.00156285
Iteration 184, loss = 0.00158521
Iteration 185, loss = 0.00156940
Iteration 186, loss = 0.00156021
Iteration 187, loss = 0.00166011
Iteration 188, loss = 0.00165509
Iteration 189, loss = 0.00159737
Iteration 190, loss = 0.00155025
Iteration 191, loss = 0.00151916
Iteration 192, loss = 0.00164404
Iteration 193, loss = 0.00160877
Iteration 194, loss = 0.00156973
Iteration 195, loss = 0.00150483
Iteration 196, loss = 0.00155856
Iteration 197, loss = 0.00173710
Iteration 198, loss = 0.00151808
Iteration 199, loss = 0.00147938
Iteration 200, loss = 0.00148179
Iteration 1, loss = 0.14337554
Iteration 2, loss = 0.06533527
Iteration 3, loss = 0.05448229
Iteration 4, loss = 0.04624798
Iteration 5, loss = 0.04024814
Iteration 6, loss = 0.03567736
Iteration 7, loss = 0.03256277
Iteration 8, loss = 0.03000708
Iteration 9, loss = 0.02801595
Iteration 10, loss = 0.02646522
Iteration 11, loss = 0.02511635
Iteration 12, loss = 0.02380403
Iteration 13, loss = 0.02279178
Iteration 14, loss = 0.02174797
Iteration 15, loss = 0.02083742
Iteration 16, loss = 0.02011098
Iteration 17, loss = 0.01942065
Iteration 18, loss = 0.01879797
Iteration 19, loss = 0.01810751
Iteration 20, loss = 0.01753662
Iteration 21, loss = 0.01700699
Iteration 22, loss = 0.01646729
Iteration 23, loss = 0.01595067
Iteration 24, loss = 0.01545569
Iteration 25, loss = 0.01511213
Iteration 26, loss = 0.01455716
Iteration 27, loss = 0.01419963
Iteration 28, loss = 0.01384627
Iteration 29, loss = 0.01345863
Iteration 30, loss = 0.01296851
Iteration 31, loss = 0.01268490
Iteration 32, loss = 0.01232693
Iteration 33, loss = 0.01197922
Iteration 34, loss = 0.01157015
Iteration 35, loss = 0.01131448
Iteration 36, loss = 0.01113322
Iteration 37, loss = 0.01075171
Iteration 38, loss = 0.01049631
Iteration 39, loss = 0.01016935
Iteration 40, loss = 0.00994033
Iteration 41, loss = 0.00971226
Iteration 42, loss = 0.00946796
Iteration 43, loss = 0.00929128
Iteration 44, loss = 0.00910888
Iteration 45, loss = 0.00898321
Iteration 46, loss = 0.00862775
Iteration 47, loss = 0.00845752
Iteration 48, loss = 0.00812922
Iteration 49, loss = 0.00805453
Iteration 50, loss = 0.00787719
Iteration 51, loss = 0.00777484
Iteration 52, loss = 0.00746528
Iteration 53, loss = 0.00724760
Iteration 54, loss = 0.00710102
Iteration 55, loss = 0.00694629
Iteration 56, loss = 0.00690900
Iteration 57, loss = 0.00663234
Iteration 58, loss = 0.00655797
Iteration 59, loss = 0.00638746
Iteration 60, loss = 0.00628144
Iteration 61, loss = 0.00617634
Iteration 62, loss = 0.00604465
Iteration 63, loss = 0.00582004
Iteration 64, loss = 0.00582611
Iteration 65, loss = 0.00557302
Iteration 66, loss = 0.00554417
Iteration 67, loss = 0.00536410
Iteration 68, loss = 0.00536313
Iteration 69, loss = 0.00525278
Iteration 70, loss = 0.00506210
Iteration 71, loss = 0.00503646
Iteration 72, loss = 0.00478252
Iteration 73, loss = 0.00482043
Iteration 74, loss = 0.00471926
Iteration 75, loss = 0.00458879
Iteration 76, loss = 0.00447303
Iteration 77, loss = 0.00440528
Iteration 78, loss = 0.00431786
Iteration 79, loss = 0.00425276
Iteration 80, loss = 0.00422959
Iteration 81, loss = 0.00414706
Iteration 82, loss = 0.00400522
Iteration 83, loss = 0.00393791
Iteration 84, loss = 0.00385523
Iteration 85, loss = 0.00390924
Iteration 86, loss = 0.00371956
Iteration 87, loss = 0.00361562
Iteration 88, loss = 0.00363589
Iteration 89, loss = 0.00353017
Iteration 90, loss = 0.00347717
Iteration 91, loss = 0.00340520
Iteration 92, loss = 0.00346708
Iteration 93, loss = 0.00329703
Iteration 94, loss = 0.00329149
Iteration 95, loss = 0.00328187
Iteration 96, loss = 0.00321983
Iteration 97, loss = 0.00310619
Iteration 98, loss = 0.00304302
Iteration 99, loss = 0.00299650
Iteration 100, loss = 0.00299304
Iteration 101, loss = 0.00294792
Iteration 102, loss = 0.00293464
Iteration 103, loss = 0.00288644
Iteration 104, loss = 0.00284150
Iteration 105, loss = 0.00272326
Iteration 106, loss = 0.00270264
Iteration 107, loss = 0.00271115
Iteration 108, loss = 0.00267402
Iteration 109, loss = 0.00270252
Iteration 110, loss = 0.00259334
Iteration 111, loss = 0.00249673
Iteration 112, loss = 0.00250484
Iteration 113, loss = 0.00250478
Iteration 114, loss = 0.00238610
Iteration 115, loss = 0.00254685
Iteration 116, loss = 0.00241738
Iteration 117, loss = 0.00242157
Iteration 118, loss = 0.00237285
Iteration 119, loss = 0.00235906
Iteration 120, loss = 0.00235097
Iteration 121, loss = 0.00227888
Iteration 122, loss = 0.00228065
Iteration 123, loss = 0.00222079
Iteration 124, loss = 0.00225998
Iteration 125, loss = 0.00213962
Iteration 126, loss = 0.00223454
Iteration 127, loss = 0.00220657
Iteration 128, loss = 0.00213777
Iteration 129, loss = 0.00212504
Iteration 130, loss = 0.00203122
Iteration 131, loss = 0.00212303
Iteration 132, loss = 0.00211870
Iteration 133, loss = 0.00205528
Iteration 134, loss = 0.00205616
Iteration 135, loss = 0.00200505
Iteration 136, loss = 0.00200256
Iteration 137, loss = 0.00193690
Iteration 138, loss = 0.00199946
Iteration 139, loss = 0.00200998
Iteration 140, loss = 0.00190328
Iteration 141, loss = 0.00195184
Iteration 142, loss = 0.00197915
Iteration 143, loss = 0.00189437
Iteration 144, loss = 0.00187784
Iteration 145, loss = 0.00185080
Iteration 146, loss = 0.00186088
Iteration 147, loss = 0.00189773
Iteration 148, loss = 0.00181625
Iteration 149, loss = 0.00188001
Iteration 150, loss = 0.00184497
Iteration 151, loss = 0.00180826
Iteration 152, loss = 0.00178069
Iteration 153, loss = 0.00188047
Iteration 154, loss = 0.00183612
Iteration 155, loss = 0.00181647
Iteration 156, loss = 0.00173176
Iteration 157, loss = 0.00173378
Iteration 158, loss = 0.00180556
Iteration 159, loss = 0.00184157
Iteration 160, loss = 0.00170414
Iteration 161, loss = 0.00168149
Iteration 162, loss = 0.00169864
Iteration 163, loss = 0.00177586
Iteration 164, loss = 0.00174440
Iteration 165, loss = 0.00164731
Iteration 166, loss = 0.00165612
Iteration 167, loss = 0.00168124
Iteration 168, loss = 0.00170881
Iteration 169, loss = 0.00184847
Iteration 170, loss = 0.00163907
Iteration 171, loss = 0.00165760
Iteration 172, loss = 0.00168350
Iteration 173, loss = 0.00166289
Iteration 174, loss = 0.00162186
Iteration 175, loss = 0.00163760
Iteration 176, loss = 0.00169385
Iteration 177, loss = 0.00163690
Iteration 178, loss = 0.00167580
Iteration 179, loss = 0.00162845
Iteration 180, loss = 0.00163153
Iteration 181, loss = 0.00158862
Iteration 182, loss = 0.00161257
Iteration 183, loss = 0.00162647
Iteration 184, loss = 0.00158966
Iteration 185, loss = 0.00157406
Iteration 186, loss = 0.00160999
Iteration 187, loss = 0.00165327
Iteration 188, loss = 0.00153199
Iteration 189, loss = 0.00157190
Iteration 190, loss = 0.00154570
Iteration 191, loss = 0.00157449
Iteration 192, loss = 0.00153810
Iteration 193, loss = 0.00161025
Iteration 194, loss = 0.00151914
Iteration 195, loss = 0.00157139
Iteration 196, loss = 0.00155412
Iteration 197, loss = 0.00156534
Iteration 198, loss = 0.00163376
Iteration 199, loss = 0.00160075
Iteration 200, loss = 0.00148436
Iteration 1, loss = 0.13990417
Iteration 2, loss = 0.06429322
Iteration 3, loss = 0.05476607
Iteration 4, loss = 0.04723881
Iteration 5, loss = 0.04138909
Iteration 6, loss = 0.03711772
Iteration 7, loss = 0.03385053
Iteration 8, loss = 0.03117009
Iteration 9, loss = 0.02879452
Iteration 10, loss = 0.02702532
Iteration 11, loss = 0.02547765
Iteration 12, loss = 0.02406384
Iteration 13, loss = 0.02278168
Iteration 14, loss = 0.02174244
Iteration 15, loss = 0.02078978
Iteration 16, loss = 0.01992247
Iteration 17, loss = 0.01916261
Iteration 18, loss = 0.01841790
Iteration 19, loss = 0.01775713
Iteration 20, loss = 0.01717295
Iteration 21, loss = 0.01648746
Iteration 22, loss = 0.01611935
Iteration 23, loss = 0.01553815
Iteration 24, loss = 0.01505998
Iteration 25, loss = 0.01452528
Iteration 26, loss = 0.01416176
Iteration 27, loss = 0.01382211
Iteration 28, loss = 0.01334935
Iteration 29, loss = 0.01307200
Iteration 30, loss = 0.01264268
Iteration 31, loss = 0.01234732
Iteration 32, loss = 0.01190148
Iteration 33, loss = 0.01170658
Iteration 34, loss = 0.01149553
Iteration 35, loss = 0.01120170
Iteration 36, loss = 0.01087462
Iteration 37, loss = 0.01051851
Iteration 38, loss = 0.01028989
Iteration 39, loss = 0.01003845
Iteration 40, loss = 0.00978200
Iteration 41, loss = 0.00954662
Iteration 42, loss = 0.00940210
Iteration 43, loss = 0.00914016
Iteration 44, loss = 0.00894146
Iteration 45, loss = 0.00891582
Iteration 46, loss = 0.00854994
Iteration 47, loss = 0.00835460
Iteration 48, loss = 0.00810705
Iteration 49, loss = 0.00797773
Iteration 50, loss = 0.00782963
Iteration 51, loss = 0.00768921
Iteration 52, loss = 0.00752876
Iteration 53, loss = 0.00726040
Iteration 54, loss = 0.00720764
Iteration 55, loss = 0.00705243
Iteration 56, loss = 0.00694748
Iteration 57, loss = 0.00679046
Iteration 58, loss = 0.00661059
Iteration 59, loss = 0.00652185
Iteration 60, loss = 0.00638312
Iteration 61, loss = 0.00629670
Iteration 62, loss = 0.00605186
Iteration 63, loss = 0.00605143
Iteration 64, loss = 0.00580162
Iteration 65, loss = 0.00578398
Iteration 66, loss = 0.00557692
Iteration 67, loss = 0.00547154
Iteration 68, loss = 0.00551180
Iteration 69, loss = 0.00534190
Iteration 70, loss = 0.00524048
Iteration 71, loss = 0.00508725
Iteration 72, loss = 0.00500887
Iteration 73, loss = 0.00494110
Iteration 74, loss = 0.00482654
Iteration 75, loss = 0.00468986
Iteration 76, loss = 0.00462159
Iteration 77, loss = 0.00464416
Iteration 78, loss = 0.00449689
Iteration 79, loss = 0.00438468
Iteration 80, loss = 0.00428192
Iteration 81, loss = 0.00420229
Iteration 82, loss = 0.00413551
Iteration 83, loss = 0.00416332
Iteration 84, loss = 0.00405918
Iteration 85, loss = 0.00394830
Iteration 86, loss = 0.00390869
Iteration 87, loss = 0.00385938
Iteration 88, loss = 0.00364966
Iteration 89, loss = 0.00382526
Iteration 90, loss = 0.00364027
Iteration 91, loss = 0.00356831
Iteration 92, loss = 0.00354353
Iteration 93, loss = 0.00339498
Iteration 94, loss = 0.00345033
Iteration 95, loss = 0.00332416
Iteration 96, loss = 0.00324949
Iteration 97, loss = 0.00323998
Iteration 98, loss = 0.00315965
Iteration 99, loss = 0.00316934
Iteration 100, loss = 0.00308401
Iteration 101, loss = 0.00308450
Iteration 102, loss = 0.00301344
Iteration 103, loss = 0.00290601
Iteration 104, loss = 0.00292804
Iteration 105, loss = 0.00279053
Iteration 106, loss = 0.00290989
Iteration 107, loss = 0.00279538
Iteration 108, loss = 0.00276981
Iteration 109, loss = 0.00263644
Iteration 110, loss = 0.00271662
Iteration 111, loss = 0.00261772
Iteration 112, loss = 0.00257392
Iteration 113, loss = 0.00256529
Iteration 114, loss = 0.00252347
Iteration 115, loss = 0.00249379
Iteration 116, loss = 0.00244751
Iteration 117, loss = 0.00240896
Iteration 118, loss = 0.00243335
Iteration 119, loss = 0.00245385
Iteration 120, loss = 0.00232871
Iteration 121, loss = 0.00231785
Iteration 122, loss = 0.00230122
Iteration 123, loss = 0.00225816
Iteration 124, loss = 0.00224199
Iteration 125, loss = 0.00218730
Iteration 126, loss = 0.00223014
Iteration 127, loss = 0.00218087
Iteration 128, loss = 0.00215419
Iteration 129, loss = 0.00216460
Iteration 130, loss = 0.00218713
Iteration 131, loss = 0.00211359
Iteration 132, loss = 0.00207025
Iteration 133, loss = 0.00206104
Iteration 134, loss = 0.00202404
Iteration 135, loss = 0.00205733
Iteration 136, loss = 0.00201354
Iteration 137, loss = 0.00200549
Iteration 138, loss = 0.00195808
Iteration 139, loss = 0.00198888
Iteration 140, loss = 0.00193228
Iteration 141, loss = 0.00194796
Iteration 142, loss = 0.00191743
Iteration 143, loss = 0.00190526
Iteration 144, loss = 0.00192773
Iteration 145, loss = 0.00190205
Iteration 146, loss = 0.00187181
Iteration 147, loss = 0.00185614
Iteration 148, loss = 0.00185415
Iteration 149, loss = 0.00182625
Iteration 150, loss = 0.00180072
Iteration 151, loss = 0.00179007
Iteration 152, loss = 0.00182110
Iteration 153, loss = 0.00182972
Iteration 154, loss = 0.00182567
Iteration 155, loss = 0.00175979
Iteration 156, loss = 0.00171566
Iteration 157, loss = 0.00177108
Iteration 158, loss = 0.00179795
Iteration 159, loss = 0.00179140
Iteration 160, loss = 0.00176977
Iteration 161, loss = 0.00178140
Iteration 162, loss = 0.00168430
Iteration 163, loss = 0.00166663
Iteration 164, loss = 0.00176725
Iteration 165, loss = 0.00169307
Iteration 166, loss = 0.00164790
Iteration 167, loss = 0.00167528
Iteration 168, loss = 0.00166675
Iteration 169, loss = 0.00171082
Iteration 170, loss = 0.00168215
Iteration 171, loss = 0.00163005
Iteration 172, loss = 0.00162933
Iteration 173, loss = 0.00161387
Iteration 174, loss = 0.00164049
Iteration 175, loss = 0.00164954
Iteration 176, loss = 0.00163000
Iteration 177, loss = 0.00162735
Iteration 178, loss = 0.00163608
Iteration 179, loss = 0.00166091
Iteration 180, loss = 0.00160883
Iteration 181, loss = 0.00158917
Iteration 182, loss = 0.00158871
Iteration 183, loss = 0.00158730
Iteration 184, loss = 0.00160237
Iteration 185, loss = 0.00163404
Iteration 186, loss = 0.00154060
Iteration 187, loss = 0.00156229
Iteration 188, loss = 0.00155577
Iteration 189, loss = 0.00155679
Iteration 190, loss = 0.00158945
Iteration 191, loss = 0.00152939
Iteration 192, loss = 0.00155975
Iteration 193, loss = 0.00155141
Iteration 194, loss = 0.00154655
Iteration 195, loss = 0.00156522
Iteration 196, loss = 0.00155106
Iteration 197, loss = 0.00153532
Iteration 198, loss = 0.00152906
Iteration 199, loss = 0.00149965
Iteration 200, loss = 0.00149896
Iteration 1, loss = 0.15417333
Iteration 2, loss = 0.06536369
Iteration 3, loss = 0.05457634
Iteration 4, loss = 0.04690680
Iteration 5, loss = 0.04090044
Iteration 6, loss = 0.03628458
Iteration 7, loss = 0.03277464
Iteration 8, loss = 0.02996735
Iteration 9, loss = 0.02760597
Iteration 10, loss = 0.02569235
Iteration 11, loss = 0.02407866
Iteration 12, loss = 0.02261261
Iteration 13, loss = 0.02152973
Iteration 14, loss = 0.02039667
Iteration 15, loss = 0.01939169
Iteration 16, loss = 0.01860937
Iteration 17, loss = 0.01785829
Iteration 18, loss = 0.01711608
Iteration 19, loss = 0.01645227
Iteration 20, loss = 0.01594234
Iteration 21, loss = 0.01543008
Iteration 22, loss = 0.01494403
Iteration 23, loss = 0.01436578
Iteration 24, loss = 0.01370883
Iteration 25, loss = 0.01351442
Iteration 26, loss = 0.01303648
Iteration 27, loss = 0.01271910
Iteration 28, loss = 0.01220838
Iteration 29, loss = 0.01178390
Iteration 30, loss = 0.01144491
Iteration 31, loss = 0.01109411
Iteration 32, loss = 0.01088457
Iteration 33, loss = 0.01035253
Iteration 34, loss = 0.01003763
Iteration 35, loss = 0.00985059
Iteration 36, loss = 0.00961877
Iteration 37, loss = 0.00929934
Iteration 38, loss = 0.00902155
Iteration 39, loss = 0.00882329
Iteration 40, loss = 0.00851757
Iteration 41, loss = 0.00820153
Iteration 42, loss = 0.00803619
Iteration 43, loss = 0.00785449
Iteration 44, loss = 0.00768547
Iteration 45, loss = 0.00742887
Iteration 46, loss = 0.00725945
Iteration 47, loss = 0.00700536
Iteration 48, loss = 0.00706439
Iteration 49, loss = 0.00669634
Iteration 50, loss = 0.00653425
Iteration 51, loss = 0.00638393
Iteration 52, loss = 0.00621811
Iteration 53, loss = 0.00597468
Iteration 54, loss = 0.00598268
Iteration 55, loss = 0.00576739
Iteration 56, loss = 0.00555958
Iteration 57, loss = 0.00551933
Iteration 58, loss = 0.00541059
Iteration 59, loss = 0.00526197
Iteration 60, loss = 0.00510199
Iteration 61, loss = 0.00494526
Iteration 62, loss = 0.00490848
Iteration 63, loss = 0.00472819
Iteration 64, loss = 0.00456739
Iteration 65, loss = 0.00444478
Iteration 66, loss = 0.00436184
Iteration 67, loss = 0.00442736
Iteration 68, loss = 0.00417798
Iteration 69, loss = 0.00412566
Iteration 70, loss = 0.00399736
Iteration 71, loss = 0.00399167
Iteration 72, loss = 0.00398042
Iteration 73, loss = 0.00370107
Iteration 74, loss = 0.00369042
Iteration 75, loss = 0.00365643
Iteration 76, loss = 0.00352981
Iteration 77, loss = 0.00354484
Iteration 78, loss = 0.00347745
Iteration 79, loss = 0.00336695
Iteration 80, loss = 0.00319271
Iteration 81, loss = 0.00326712
Iteration 82, loss = 0.00321646
Iteration 83, loss = 0.00307939
Iteration 84, loss = 0.00299103
Iteration 85, loss = 0.00305449
Iteration 86, loss = 0.00288088
Iteration 87, loss = 0.00289996
Iteration 88, loss = 0.00285913
Iteration 89, loss = 0.00284510
Iteration 90, loss = 0.00274022
Iteration 91, loss = 0.00265131
Iteration 92, loss = 0.00266698
Iteration 93, loss = 0.00267778
Iteration 94, loss = 0.00259173
Iteration 95, loss = 0.00256019
Iteration 96, loss = 0.00251250
Iteration 97, loss = 0.00245487
Iteration 98, loss = 0.00244523
Iteration 99, loss = 0.00239707
Iteration 100, loss = 0.00238913
Iteration 101, loss = 0.00235601
Iteration 102, loss = 0.00231783
Iteration 103, loss = 0.00226794
Iteration 104, loss = 0.00218753
Iteration 105, loss = 0.00218357
Iteration 106, loss = 0.00224544
Iteration 107, loss = 0.00219797
Iteration 108, loss = 0.00213024
Iteration 109, loss = 0.00212574
Iteration 110, loss = 0.00206846
Iteration 111, loss = 0.00210896
Iteration 112, loss = 0.00204394
Iteration 113, loss = 0.00198445
Iteration 114, loss = 0.00200167
Iteration 115, loss = 0.00198255
Iteration 116, loss = 0.00195701
Iteration 117, loss = 0.00197188
Iteration 118, loss = 0.00192101
Iteration 119, loss = 0.00190429
Iteration 120, loss = 0.00189413
Iteration 121, loss = 0.00188712
Iteration 122, loss = 0.00187345
Iteration 123, loss = 0.00193502
Iteration 124, loss = 0.00183791
Iteration 125, loss = 0.00180961
Iteration 126, loss = 0.00179135
Iteration 127, loss = 0.00173504
Iteration 128, loss = 0.00188269
Iteration 129, loss = 0.00178107
Iteration 130, loss = 0.00181051
Iteration 131, loss = 0.00173165
Iteration 132, loss = 0.00182760
Iteration 133, loss = 0.00169793
Iteration 134, loss = 0.00171939
Iteration 135, loss = 0.00169863
Iteration 136, loss = 0.00166167
Iteration 137, loss = 0.00168833
Iteration 138, loss = 0.00169199
Iteration 139, loss = 0.00166344
Iteration 140, loss = 0.00165721
Iteration 141, loss = 0.00166111
Iteration 142, loss = 0.00174648
Iteration 143, loss = 0.00164934
Iteration 144, loss = 0.00162199
Iteration 145, loss = 0.00166327
Iteration 146, loss = 0.00156604
Iteration 147, loss = 0.00163754
Iteration 148, loss = 0.00171230
Iteration 149, loss = 0.00157776
Iteration 150, loss = 0.00158761
Iteration 151, loss = 0.00157445
Iteration 152, loss = 0.00159509
Iteration 153, loss = 0.00156448
Iteration 154, loss = 0.00157922
Iteration 155, loss = 0.00154749
Iteration 156, loss = 0.00155631
Iteration 157, loss = 0.00153160
Iteration 158, loss = 0.00155981
Iteration 159, loss = 0.00158577
Iteration 160, loss = 0.00160047
Iteration 161, loss = 0.00154767
Iteration 162, loss = 0.00151760
Iteration 163, loss = 0.00170887
Iteration 164, loss = 0.00158385
Iteration 165, loss = 0.00148501
Iteration 166, loss = 0.00147905
Iteration 167, loss = 0.00144853
Iteration 168, loss = 0.00145771
Iteration 169, loss = 0.00151483
Iteration 170, loss = 0.00151113
Iteration 171, loss = 0.00153537
Iteration 172, loss = 0.00155878
Iteration 173, loss = 0.00147867
Iteration 174, loss = 0.00149016
Iteration 175, loss = 0.00159540
Iteration 176, loss = 0.00144445
Iteration 177, loss = 0.00144356
Iteration 178, loss = 0.00142269
Iteration 179, loss = 0.00147884
Iteration 180, loss = 0.00151375
Iteration 181, loss = 0.00142397
Iteration 182, loss = 0.00151809
Iteration 183, loss = 0.00166322
Iteration 184, loss = 0.00144013
Iteration 185, loss = 0.00137783
Iteration 186, loss = 0.00139673
Iteration 187, loss = 0.00144727
Iteration 188, loss = 0.00147856
Iteration 189, loss = 0.00141505
Iteration 190, loss = 0.00139867
Iteration 191, loss = 0.00145489
Iteration 192, loss = 0.00160328
Iteration 193, loss = 0.00141369
Iteration 194, loss = 0.00137845
Iteration 195, loss = 0.00138638
Iteration 196, loss = 0.00138920
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.12395733
Iteration 2, loss = 0.06057829
Iteration 3, loss = 0.05105193
Iteration 4, loss = 0.04385544
Iteration 5, loss = 0.03850546
Iteration 6, loss = 0.03449842
Iteration 7, loss = 0.03147145
Iteration 8, loss = 0.02907635
Iteration 9, loss = 0.02691908
Iteration 10, loss = 0.02525433
Iteration 11, loss = 0.02375043
Iteration 12, loss = 0.02237702
Iteration 13, loss = 0.02117182
Iteration 14, loss = 0.02006863
Iteration 15, loss = 0.01920510
Iteration 16, loss = 0.01833200
Iteration 17, loss = 0.01738301
Iteration 18, loss = 0.01672504
Iteration 19, loss = 0.01601101
Iteration 20, loss = 0.01543387
Iteration 21, loss = 0.01479531
Iteration 22, loss = 0.01425547
Iteration 23, loss = 0.01380369
Iteration 24, loss = 0.01328858
Iteration 25, loss = 0.01281781
Iteration 26, loss = 0.01240133
Iteration 27, loss = 0.01194516
Iteration 28, loss = 0.01168140
Iteration 29, loss = 0.01115011
Iteration 30, loss = 0.01087533
Iteration 31, loss = 0.01056642
Iteration 32, loss = 0.01026331
Iteration 33, loss = 0.00992761
Iteration 34, loss = 0.00955185
Iteration 35, loss = 0.00929849
Iteration 36, loss = 0.00904062
Iteration 37, loss = 0.00877695
Iteration 38, loss = 0.00860845
Iteration 39, loss = 0.00828237
Iteration 40, loss = 0.00812508
Iteration 41, loss = 0.00785121
Iteration 42, loss = 0.00775792
Iteration 43, loss = 0.00742857
Iteration 44, loss = 0.00722208
Iteration 45, loss = 0.00710894
Iteration 46, loss = 0.00692644
Iteration 47, loss = 0.00659731
Iteration 48, loss = 0.00661579
Iteration 49, loss = 0.00639264
Iteration 50, loss = 0.00622681
Iteration 51, loss = 0.00608304
Iteration 52, loss = 0.00588654
Iteration 53, loss = 0.00569191
Iteration 54, loss = 0.00557863
Iteration 55, loss = 0.00559407
Iteration 56, loss = 0.00537998
Iteration 57, loss = 0.00520476
Iteration 58, loss = 0.00520700
Iteration 59, loss = 0.00498999
Iteration 60, loss = 0.00484646
Iteration 61, loss = 0.00473353
Iteration 62, loss = 0.00465902
Iteration 63, loss = 0.00452648
Iteration 64, loss = 0.00447712
Iteration 65, loss = 0.00436179
Iteration 66, loss = 0.00425147
Iteration 67, loss = 0.00418579
Iteration 68, loss = 0.00399785
Iteration 69, loss = 0.00401062
Iteration 70, loss = 0.00386174
Iteration 71, loss = 0.00383575
Iteration 72, loss = 0.00375751
Iteration 73, loss = 0.00371857
Iteration 74, loss = 0.00355467
Iteration 75, loss = 0.00353490
Iteration 76, loss = 0.00348777
Iteration 77, loss = 0.00339730
Iteration 78, loss = 0.00336327
Iteration 79, loss = 0.00325482
Iteration 80, loss = 0.00315964
Iteration 81, loss = 0.00313325
Iteration 82, loss = 0.00302417
Iteration 83, loss = 0.00303173
Iteration 84, loss = 0.00299469
Iteration 85, loss = 0.00289117
Iteration 86, loss = 0.00284817
Iteration 87, loss = 0.00273770
Iteration 88, loss = 0.00270901
Iteration 89, loss = 0.00269598
Iteration 90, loss = 0.00276022
Iteration 91, loss = 0.00256940
Iteration 92, loss = 0.00251751
Iteration 93, loss = 0.00250280
Iteration 94, loss = 0.00251348
Iteration 95, loss = 0.00241254
Iteration 96, loss = 0.00248755
Iteration 97, loss = 0.00231481
Iteration 98, loss = 0.00238141
Iteration 99, loss = 0.00235158
Iteration 100, loss = 0.00224985
Iteration 101, loss = 0.00219889
Iteration 102, loss = 0.00226444
Iteration 103, loss = 0.00223164
Iteration 104, loss = 0.00213596
Iteration 105, loss = 0.00217173
Iteration 106, loss = 0.00209640
Iteration 107, loss = 0.00213181
Iteration 108, loss = 0.00214885
Iteration 109, loss = 0.00207941
Iteration 110, loss = 0.00198147
Iteration 111, loss = 0.00201244
Iteration 112, loss = 0.00198003
Iteration 113, loss = 0.00195089
Iteration 114, loss = 0.00199194
Iteration 115, loss = 0.00189691
Iteration 116, loss = 0.00187418
Iteration 117, loss = 0.00189810
Iteration 118, loss = 0.00193615
Iteration 119, loss = 0.00187515
Iteration 120, loss = 0.00190652
Iteration 121, loss = 0.00183157
Iteration 122, loss = 0.00180529
Iteration 123, loss = 0.00173280
Iteration 124, loss = 0.00182106
Iteration 125, loss = 0.00178022
Iteration 126, loss = 0.00178341
Iteration 127, loss = 0.00176190
Iteration 128, loss = 0.00169249
Iteration 129, loss = 0.00174134
Iteration 130, loss = 0.00170141
Iteration 131, loss = 0.00170487
Iteration 132, loss = 0.00166678
Iteration 133, loss = 0.00169300
Iteration 134, loss = 0.00188704
Iteration 135, loss = 0.00170385
Iteration 136, loss = 0.00159184
Iteration 137, loss = 0.00156425
Iteration 138, loss = 0.00162411
Iteration 139, loss = 0.00183176
Iteration 140, loss = 0.00157740
Iteration 141, loss = 0.00157915
Iteration 142, loss = 0.00158738
Iteration 143, loss = 0.00173955
Iteration 144, loss = 0.00163369
Iteration 145, loss = 0.00152930
Iteration 146, loss = 0.00150259
Iteration 147, loss = 0.00169563
Iteration 148, loss = 0.00156385
Iteration 149, loss = 0.00153665
Iteration 150, loss = 0.00153562
Iteration 151, loss = 0.00153622
Iteration 152, loss = 0.00162652
Iteration 153, loss = 0.00154399
Iteration 154, loss = 0.00160193
Iteration 155, loss = 0.00155340
Iteration 156, loss = 0.00146654
Iteration 157, loss = 0.00150302
Iteration 158, loss = 0.00161413
Iteration 159, loss = 0.00150986
Iteration 160, loss = 0.00147463
Iteration 161, loss = 0.00159158
Iteration 162, loss = 0.00150789
Iteration 163, loss = 0.00144316
Iteration 164, loss = 0.00151549
Iteration 165, loss = 0.00142902
Iteration 166, loss = 0.00145888
Iteration 167, loss = 0.00145604
Iteration 168, loss = 0.00165006
Iteration 169, loss = 0.00147963
Iteration 170, loss = 0.00147228
Iteration 171, loss = 0.00139672
Iteration 172, loss = 0.00147893
Iteration 173, loss = 0.00143971
Iteration 174, loss = 0.00142795
Iteration 175, loss = 0.00145695
Iteration 176, loss = 0.00159460
Iteration 177, loss = 0.00143630
Iteration 178, loss = 0.00140953
Iteration 179, loss = 0.00139026
Iteration 180, loss = 0.00138210
Iteration 181, loss = 0.00166646
Iteration 182, loss = 0.00141270
Iteration 183, loss = 0.00135988
Iteration 184, loss = 0.00137594
Iteration 185, loss = 0.00136560
Iteration 186, loss = 0.00151113
Iteration 187, loss = 0.00145957
Iteration 188, loss = 0.00158088
Iteration 189, loss = 0.00138372
Iteration 190, loss = 0.00137751
Iteration 191, loss = 0.00137536
Iteration 192, loss = 0.00134993
Iteration 193, loss = 0.00137810
Iteration 194, loss = 0.00147361
Iteration 195, loss = 0.00147414
Iteration 196, loss = 0.00158487
Iteration 197, loss = 0.00133641
Iteration 198, loss = 0.00133128
Iteration 199, loss = 0.00135378
Iteration 200, loss = 0.00137614
Iteration 1, loss = 0.14412895
Iteration 2, loss = 0.06478136
Iteration 3, loss = 0.05491137
Iteration 4, loss = 0.04700046
Iteration 5, loss = 0.04074627
Iteration 6, loss = 0.03581551
Iteration 7, loss = 0.03220647
Iteration 8, loss = 0.02958996
Iteration 9, loss = 0.02715480
Iteration 10, loss = 0.02535825
Iteration 11, loss = 0.02377446
Iteration 12, loss = 0.02242835
Iteration 13, loss = 0.02123123
Iteration 14, loss = 0.02012964
Iteration 15, loss = 0.01917978
Iteration 16, loss = 0.01831753
Iteration 17, loss = 0.01749543
Iteration 18, loss = 0.01667590
Iteration 19, loss = 0.01608862
Iteration 20, loss = 0.01539906
Iteration 21, loss = 0.01478401
Iteration 22, loss = 0.01422007
Iteration 23, loss = 0.01379255
Iteration 24, loss = 0.01325584
Iteration 25, loss = 0.01281842
Iteration 26, loss = 0.01227579
Iteration 27, loss = 0.01184597
Iteration 28, loss = 0.01153046
Iteration 29, loss = 0.01110266
Iteration 30, loss = 0.01075752
Iteration 31, loss = 0.01043579
Iteration 32, loss = 0.01004995
Iteration 33, loss = 0.00970989
Iteration 34, loss = 0.00941215
Iteration 35, loss = 0.00922407
Iteration 36, loss = 0.00898289
Iteration 37, loss = 0.00862488
Iteration 38, loss = 0.00839495
Iteration 39, loss = 0.00809530
Iteration 40, loss = 0.00790549
Iteration 41, loss = 0.00762193
Iteration 42, loss = 0.00759832
Iteration 43, loss = 0.00727777
Iteration 44, loss = 0.00712647
Iteration 45, loss = 0.00680681
Iteration 46, loss = 0.00675785
Iteration 47, loss = 0.00660005
Iteration 48, loss = 0.00629806
Iteration 49, loss = 0.00618061
Iteration 50, loss = 0.00605022
Iteration 51, loss = 0.00582744
Iteration 52, loss = 0.00576125
Iteration 53, loss = 0.00559651
Iteration 54, loss = 0.00545226
Iteration 55, loss = 0.00528298
Iteration 56, loss = 0.00520563
Iteration 57, loss = 0.00510138
Iteration 58, loss = 0.00489241
Iteration 59, loss = 0.00473759
Iteration 60, loss = 0.00470027
Iteration 61, loss = 0.00458179
Iteration 62, loss = 0.00439608
Iteration 63, loss = 0.00447488
Iteration 64, loss = 0.00425491
Iteration 65, loss = 0.00421464
Iteration 66, loss = 0.00404443
Iteration 67, loss = 0.00394300
Iteration 68, loss = 0.00396191
Iteration 69, loss = 0.00385168
Iteration 70, loss = 0.00367358
Iteration 71, loss = 0.00363242
Iteration 72, loss = 0.00351283
Iteration 73, loss = 0.00342896
Iteration 74, loss = 0.00342620
Iteration 75, loss = 0.00329581
Iteration 76, loss = 0.00318267
Iteration 77, loss = 0.00322514
Iteration 78, loss = 0.00310022
Iteration 79, loss = 0.00303223
Iteration 80, loss = 0.00299394
Iteration 81, loss = 0.00293071
Iteration 82, loss = 0.00289437
Iteration 83, loss = 0.00283325
Iteration 84, loss = 0.00280117
Iteration 85, loss = 0.00274399
Iteration 86, loss = 0.00263817
Iteration 87, loss = 0.00260498
Iteration 88, loss = 0.00263133
Iteration 89, loss = 0.00254264
Iteration 90, loss = 0.00255681
Iteration 91, loss = 0.00238213
Iteration 92, loss = 0.00243579
Iteration 93, loss = 0.00241258
Iteration 94, loss = 0.00244642
Iteration 95, loss = 0.00236748
Iteration 96, loss = 0.00223852
Iteration 97, loss = 0.00225566
Iteration 98, loss = 0.00225133
Iteration 99, loss = 0.00217121
Iteration 100, loss = 0.00219397
Iteration 101, loss = 0.00218096
Iteration 102, loss = 0.00213981
Iteration 103, loss = 0.00207312
Iteration 104, loss = 0.00208732
Iteration 105, loss = 0.00207109
Iteration 106, loss = 0.00210067
Iteration 107, loss = 0.00201509
Iteration 108, loss = 0.00199607
Iteration 109, loss = 0.00196921
Iteration 110, loss = 0.00195516
Iteration 111, loss = 0.00194871
Iteration 112, loss = 0.00194162
Iteration 113, loss = 0.00187623
Iteration 114, loss = 0.00191065
Iteration 115, loss = 0.00188085
Iteration 116, loss = 0.00186366
Iteration 117, loss = 0.00184546
Iteration 118, loss = 0.00179506
Iteration 119, loss = 0.00180514
Iteration 120, loss = 0.00180189
Iteration 121, loss = 0.00190707
Iteration 122, loss = 0.00176676
Iteration 123, loss = 0.00170190
Iteration 124, loss = 0.00171682
Iteration 125, loss = 0.00182003
Iteration 126, loss = 0.00176147
Iteration 127, loss = 0.00166320
Iteration 128, loss = 0.00166278
Iteration 129, loss = 0.00172095
Iteration 130, loss = 0.00167615
Iteration 131, loss = 0.00165797
Iteration 132, loss = 0.00171210
Iteration 133, loss = 0.00164574
Iteration 134, loss = 0.00168678
Iteration 135, loss = 0.00161283
Iteration 136, loss = 0.00164137
Iteration 137, loss = 0.00171516
Iteration 138, loss = 0.00162307
Iteration 139, loss = 0.00154447
Iteration 140, loss = 0.00158318
Iteration 141, loss = 0.00157942
Iteration 142, loss = 0.00166857
Iteration 143, loss = 0.00162675
Iteration 144, loss = 0.00159239
Iteration 145, loss = 0.00152056
Iteration 146, loss = 0.00158809
Iteration 147, loss = 0.00164711
Iteration 148, loss = 0.00172278
Iteration 149, loss = 0.00149727
Iteration 150, loss = 0.00148771
Iteration 151, loss = 0.00152427
Iteration 152, loss = 0.00152645
Iteration 153, loss = 0.00151344
Iteration 154, loss = 0.00159066
Iteration 155, loss = 0.00161902
Iteration 156, loss = 0.00148386
Iteration 157, loss = 0.00150778
Iteration 158, loss = 0.00149297
Iteration 159, loss = 0.00158066
Iteration 160, loss = 0.00147066
Iteration 161, loss = 0.00154175
Iteration 162, loss = 0.00148260
Iteration 163, loss = 0.00147123
Iteration 164, loss = 0.00145390
Iteration 165, loss = 0.00150427
Iteration 166, loss = 0.00150551
Iteration 167, loss = 0.00151132
Iteration 168, loss = 0.00151363
Iteration 169, loss = 0.00143610
Iteration 170, loss = 0.00143827
Iteration 171, loss = 0.00150621
Iteration 172, loss = 0.00149840
Iteration 173, loss = 0.00144825
Iteration 174, loss = 0.00141030
Iteration 175, loss = 0.00141387
Iteration 176, loss = 0.00148869
Iteration 177, loss = 0.00154307
Iteration 178, loss = 0.00154379
Iteration 179, loss = 0.00139995
Iteration 180, loss = 0.00137808
Iteration 181, loss = 0.00140939
Iteration 182, loss = 0.00143212
Iteration 183, loss = 0.00143060
Iteration 184, loss = 0.00143807
Iteration 185, loss = 0.00145194
Iteration 186, loss = 0.00149514
Iteration 187, loss = 0.00142136
Iteration 188, loss = 0.00138636
Iteration 189, loss = 0.00139087
Iteration 190, loss = 0.00141746
Iteration 191, loss = 0.00147889
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13381539
Iteration 2, loss = 0.06195905
Iteration 3, loss = 0.05282834
Iteration 4, loss = 0.04475485
Iteration 5, loss = 0.03865066
Iteration 6, loss = 0.03413656
Iteration 7, loss = 0.03079504
Iteration 8, loss = 0.02823390
Iteration 9, loss = 0.02601111
Iteration 10, loss = 0.02440425
Iteration 11, loss = 0.02284548
Iteration 12, loss = 0.02148561
Iteration 13, loss = 0.02030968
Iteration 14, loss = 0.01933724
Iteration 15, loss = 0.01832845
Iteration 16, loss = 0.01757141
Iteration 17, loss = 0.01676429
Iteration 18, loss = 0.01602772
Iteration 19, loss = 0.01543461
Iteration 20, loss = 0.01471611
Iteration 21, loss = 0.01418705
Iteration 22, loss = 0.01358822
Iteration 23, loss = 0.01318068
Iteration 24, loss = 0.01253776
Iteration 25, loss = 0.01210884
Iteration 26, loss = 0.01166044
Iteration 27, loss = 0.01118218
Iteration 28, loss = 0.01088789
Iteration 29, loss = 0.01051182
Iteration 30, loss = 0.01020172
Iteration 31, loss = 0.00980938
Iteration 32, loss = 0.00946432
Iteration 33, loss = 0.00921456
Iteration 34, loss = 0.00886713
Iteration 35, loss = 0.00863566
Iteration 36, loss = 0.00836346
Iteration 37, loss = 0.00806540
Iteration 38, loss = 0.00778484
Iteration 39, loss = 0.00770842
Iteration 40, loss = 0.00743028
Iteration 41, loss = 0.00719446
Iteration 42, loss = 0.00681531
Iteration 43, loss = 0.00671935
Iteration 44, loss = 0.00653421
Iteration 45, loss = 0.00633336
Iteration 46, loss = 0.00604715
Iteration 47, loss = 0.00597952
Iteration 48, loss = 0.00577464
Iteration 49, loss = 0.00561095
Iteration 50, loss = 0.00540880
Iteration 51, loss = 0.00524668
Iteration 52, loss = 0.00512714
Iteration 53, loss = 0.00498532
Iteration 54, loss = 0.00494073
Iteration 55, loss = 0.00472193
Iteration 56, loss = 0.00464048
Iteration 57, loss = 0.00454178
Iteration 58, loss = 0.00437141
Iteration 59, loss = 0.00424988
Iteration 60, loss = 0.00415275
Iteration 61, loss = 0.00406640
Iteration 62, loss = 0.00393566
Iteration 63, loss = 0.00380797
Iteration 64, loss = 0.00373996
Iteration 65, loss = 0.00370710
Iteration 66, loss = 0.00360278
Iteration 67, loss = 0.00346387
Iteration 68, loss = 0.00335925
Iteration 69, loss = 0.00330036
Iteration 70, loss = 0.00326400
Iteration 71, loss = 0.00322980
Iteration 72, loss = 0.00313618
Iteration 73, loss = 0.00305150
Iteration 74, loss = 0.00291796
Iteration 75, loss = 0.00298827
Iteration 76, loss = 0.00283815
Iteration 77, loss = 0.00279546
Iteration 78, loss = 0.00277425
Iteration 79, loss = 0.00274012
Iteration 80, loss = 0.00261815
Iteration 81, loss = 0.00256939
Iteration 82, loss = 0.00252151
Iteration 83, loss = 0.00244814
Iteration 84, loss = 0.00243306
Iteration 85, loss = 0.00237724
Iteration 86, loss = 0.00240291
Iteration 87, loss = 0.00239886
Iteration 88, loss = 0.00224509
Iteration 89, loss = 0.00229345
Iteration 90, loss = 0.00219248
Iteration 91, loss = 0.00220056
Iteration 92, loss = 0.00215267
Iteration 93, loss = 0.00213401
Iteration 94, loss = 0.00211192
Iteration 95, loss = 0.00207195
Iteration 96, loss = 0.00203965
Iteration 97, loss = 0.00200029
Iteration 98, loss = 0.00195265
Iteration 99, loss = 0.00200397
Iteration 100, loss = 0.00192835
Iteration 101, loss = 0.00195454
Iteration 102, loss = 0.00197955
Iteration 103, loss = 0.00192628
Iteration 104, loss = 0.00190198
Iteration 105, loss = 0.00184597
Iteration 106, loss = 0.00183360
Iteration 107, loss = 0.00189882
Iteration 108, loss = 0.00185020
Iteration 109, loss = 0.00176415
Iteration 110, loss = 0.00174174
Iteration 111, loss = 0.00170534
Iteration 112, loss = 0.00183621
Iteration 113, loss = 0.00172690
Iteration 114, loss = 0.00170034
Iteration 115, loss = 0.00166825
Iteration 116, loss = 0.00168571
Iteration 117, loss = 0.00176669
Iteration 118, loss = 0.00171760
Iteration 119, loss = 0.00164494
Iteration 120, loss = 0.00163240
Iteration 121, loss = 0.00161230
Iteration 122, loss = 0.00177516
Iteration 123, loss = 0.00176778
Iteration 124, loss = 0.00153766
Iteration 125, loss = 0.00157689
Iteration 126, loss = 0.00154754
Iteration 127, loss = 0.00157136
Iteration 128, loss = 0.00165826
Iteration 129, loss = 0.00164768
Iteration 130, loss = 0.00154697
Iteration 131, loss = 0.00166258
Iteration 132, loss = 0.00161497
Iteration 133, loss = 0.00150286
Iteration 134, loss = 0.00149785
Iteration 135, loss = 0.00155449
Iteration 136, loss = 0.00151606
Iteration 137, loss = 0.00149717
Iteration 138, loss = 0.00147049
Iteration 139, loss = 0.00174119
Iteration 140, loss = 0.00153538
Iteration 141, loss = 0.00144631
Iteration 142, loss = 0.00143777
Iteration 143, loss = 0.00147774
Iteration 144, loss = 0.00163563
Iteration 145, loss = 0.00144829
Iteration 146, loss = 0.00144612
Iteration 147, loss = 0.00142879
Iteration 148, loss = 0.00143286
Iteration 149, loss = 0.00149936
Iteration 150, loss = 0.00149961
Iteration 151, loss = 0.00186230
Iteration 152, loss = 0.00139952
Iteration 153, loss = 0.00137726
Iteration 154, loss = 0.00136550
Iteration 155, loss = 0.00137985
Iteration 156, loss = 0.00149907
Iteration 157, loss = 0.00147415
Iteration 158, loss = 0.00149054
Iteration 159, loss = 0.00143861
Iteration 160, loss = 0.00154850
Iteration 161, loss = 0.00137977
Iteration 162, loss = 0.00136836
Iteration 163, loss = 0.00135927
Iteration 164, loss = 0.00136770
Iteration 165, loss = 0.00195581
Iteration 166, loss = 0.00141777
Iteration 167, loss = 0.00135326
Iteration 168, loss = 0.00132286
Iteration 169, loss = 0.00139304
Iteration 170, loss = 0.00142423
Iteration 171, loss = 0.00151723
Iteration 172, loss = 0.00138273
Iteration 173, loss = 0.00137267
Iteration 174, loss = 0.00133427
Iteration 175, loss = 0.00142557
Iteration 176, loss = 0.00133738
Iteration 177, loss = 0.00151833
Iteration 178, loss = 0.00134979
Iteration 179, loss = 0.00134480
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.12770307
Iteration 2, loss = 0.06023462
Iteration 3, loss = 0.05037466
Iteration 4, loss = 0.04315837
Iteration 5, loss = 0.03765016
Iteration 6, loss = 0.03356656
Iteration 7, loss = 0.03025562
Iteration 8, loss = 0.02770710
Iteration 9, loss = 0.02557364
Iteration 10, loss = 0.02396699
Iteration 11, loss = 0.02258368
Iteration 12, loss = 0.02125958
Iteration 13, loss = 0.02024527
Iteration 14, loss = 0.01932545
Iteration 15, loss = 0.01832900
Iteration 16, loss = 0.01760529
Iteration 17, loss = 0.01684612
Iteration 18, loss = 0.01615656
Iteration 19, loss = 0.01548376
Iteration 20, loss = 0.01501372
Iteration 21, loss = 0.01423342
Iteration 22, loss = 0.01379909
Iteration 23, loss = 0.01341680
Iteration 24, loss = 0.01274551
Iteration 25, loss = 0.01231068
Iteration 26, loss = 0.01186069
Iteration 27, loss = 0.01149904
Iteration 28, loss = 0.01119908
Iteration 29, loss = 0.01088882
Iteration 30, loss = 0.01040403
Iteration 31, loss = 0.01013064
Iteration 32, loss = 0.00972520
Iteration 33, loss = 0.00947342
Iteration 34, loss = 0.00926707
Iteration 35, loss = 0.00898120
Iteration 36, loss = 0.00858129
Iteration 37, loss = 0.00840306
Iteration 38, loss = 0.00812508
Iteration 39, loss = 0.00800871
Iteration 40, loss = 0.00775578
Iteration 41, loss = 0.00746178
Iteration 42, loss = 0.00726822
Iteration 43, loss = 0.00702810
Iteration 44, loss = 0.00686964
Iteration 45, loss = 0.00662203
Iteration 46, loss = 0.00654791
Iteration 47, loss = 0.00619409
Iteration 48, loss = 0.00615728
Iteration 49, loss = 0.00598794
Iteration 50, loss = 0.00577686
Iteration 51, loss = 0.00573856
Iteration 52, loss = 0.00542992
Iteration 53, loss = 0.00532000
Iteration 54, loss = 0.00523076
Iteration 55, loss = 0.00505364
Iteration 56, loss = 0.00502029
Iteration 57, loss = 0.00484583
Iteration 58, loss = 0.00465150
Iteration 59, loss = 0.00452405
Iteration 60, loss = 0.00451307
Iteration 61, loss = 0.00432499
Iteration 62, loss = 0.00428347
Iteration 63, loss = 0.00402818
Iteration 64, loss = 0.00399402
Iteration 65, loss = 0.00392740
Iteration 66, loss = 0.00382662
Iteration 67, loss = 0.00379115
Iteration 68, loss = 0.00367259
Iteration 69, loss = 0.00352210
Iteration 70, loss = 0.00346701
Iteration 71, loss = 0.00346880
Iteration 72, loss = 0.00332296
Iteration 73, loss = 0.00319468
Iteration 74, loss = 0.00320704
Iteration 75, loss = 0.00310590
Iteration 76, loss = 0.00316440
Iteration 77, loss = 0.00291882
Iteration 78, loss = 0.00291829
Iteration 79, loss = 0.00288017
Iteration 80, loss = 0.00278412
Iteration 81, loss = 0.00279366
Iteration 82, loss = 0.00272830
Iteration 83, loss = 0.00265178
Iteration 84, loss = 0.00258509
Iteration 85, loss = 0.00249344
Iteration 86, loss = 0.00257137
Iteration 87, loss = 0.00244800
Iteration 88, loss = 0.00243139
Iteration 89, loss = 0.00241204
Iteration 90, loss = 0.00230578
Iteration 91, loss = 0.00235017
Iteration 92, loss = 0.00227984
Iteration 93, loss = 0.00226831
Iteration 94, loss = 0.00220416
Iteration 95, loss = 0.00210668
Iteration 96, loss = 0.00213122
Iteration 97, loss = 0.00221084
Iteration 98, loss = 0.00207051
Iteration 99, loss = 0.00210894
Iteration 100, loss = 0.00204018
Iteration 101, loss = 0.00200750
Iteration 102, loss = 0.00199776
Iteration 103, loss = 0.00197845
Iteration 104, loss = 0.00197257
Iteration 105, loss = 0.00195242
Iteration 106, loss = 0.00197828
Iteration 107, loss = 0.00188688
Iteration 108, loss = 0.00186286
Iteration 109, loss = 0.00188403
Iteration 110, loss = 0.00185850
Iteration 111, loss = 0.00183036
Iteration 112, loss = 0.00184925
Iteration 113, loss = 0.00178193
Iteration 114, loss = 0.00173178
Iteration 115, loss = 0.00187716
Iteration 116, loss = 0.00175932
Iteration 117, loss = 0.00173405
Iteration 118, loss = 0.00182902
Iteration 119, loss = 0.00183953
Iteration 120, loss = 0.00174211
Iteration 121, loss = 0.00164863
Iteration 122, loss = 0.00164327
Iteration 123, loss = 0.00176481
Iteration 124, loss = 0.00165761
Iteration 125, loss = 0.00164411
Iteration 126, loss = 0.00162930
Iteration 127, loss = 0.00167225
Iteration 128, loss = 0.00164488
Iteration 129, loss = 0.00164876
Iteration 130, loss = 0.00163260
Iteration 131, loss = 0.00162780
Iteration 132, loss = 0.00160861
Iteration 133, loss = 0.00162820
Iteration 134, loss = 0.00157648
Iteration 135, loss = 0.00155506
Iteration 136, loss = 0.00158769
Iteration 137, loss = 0.00157176
Iteration 138, loss = 0.00156790
Iteration 139, loss = 0.00152685
Iteration 140, loss = 0.00165820
Iteration 141, loss = 0.00166149
Iteration 142, loss = 0.00154444
Iteration 143, loss = 0.00148423
Iteration 144, loss = 0.00148515
Iteration 145, loss = 0.00156404
Iteration 146, loss = 0.00151619
Iteration 147, loss = 0.00143932
Iteration 148, loss = 0.00145175
Iteration 149, loss = 0.00150928
Iteration 150, loss = 0.00154729
Iteration 151, loss = 0.00150306
Iteration 152, loss = 0.00147528
Iteration 153, loss = 0.00142766
Iteration 154, loss = 0.00150191
Iteration 155, loss = 0.00148682
Iteration 156, loss = 0.00153565
Iteration 157, loss = 0.00158644
Iteration 158, loss = 0.00141090
Iteration 159, loss = 0.00138651
Iteration 160, loss = 0.00144649
Iteration 161, loss = 0.00161198
Iteration 162, loss = 0.00141133
Iteration 163, loss = 0.00137444
Iteration 164, loss = 0.00148099
Iteration 165, loss = 0.00161864
Iteration 166, loss = 0.00139501
Iteration 167, loss = 0.00136491
Iteration 168, loss = 0.00144210
Iteration 169, loss = 0.00136656
Iteration 170, loss = 0.00144440
Iteration 171, loss = 0.00176391
Iteration 172, loss = 0.00137509
Iteration 173, loss = 0.00133278
Iteration 174, loss = 0.00135581
Iteration 175, loss = 0.00136798
Iteration 176, loss = 0.00142117
Iteration 177, loss = 0.00146416
Iteration 178, loss = 0.00151563
Iteration 179, loss = 0.00139522
Iteration 180, loss = 0.00134370
Iteration 181, loss = 0.00134842
Iteration 182, loss = 0.00139909
Iteration 183, loss = 0.00166374
Iteration 184, loss = 0.00135183
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.14542546
Iteration 2, loss = 0.06400160
Iteration 3, loss = 0.05387778
Iteration 4, loss = 0.04507220
Iteration 5, loss = 0.03878096
Iteration 6, loss = 0.03441672
Iteration 7, loss = 0.03094963
Iteration 8, loss = 0.02827300
Iteration 9, loss = 0.02611001
Iteration 10, loss = 0.02429524
Iteration 11, loss = 0.02270815
Iteration 12, loss = 0.02136016
Iteration 13, loss = 0.02025706
Iteration 14, loss = 0.01913541
Iteration 15, loss = 0.01818153
Iteration 16, loss = 0.01730949
Iteration 17, loss = 0.01663417
Iteration 18, loss = 0.01576915
Iteration 19, loss = 0.01507991
Iteration 20, loss = 0.01450138
Iteration 21, loss = 0.01389970
Iteration 22, loss = 0.01326487
Iteration 23, loss = 0.01281050
Iteration 24, loss = 0.01234173
Iteration 25, loss = 0.01184119
Iteration 26, loss = 0.01151369
Iteration 27, loss = 0.01097778
Iteration 28, loss = 0.01057721
Iteration 29, loss = 0.01020612
Iteration 30, loss = 0.00986680
Iteration 31, loss = 0.00960891
Iteration 32, loss = 0.00916817
Iteration 33, loss = 0.00886321
Iteration 34, loss = 0.00855249
Iteration 35, loss = 0.00836975
Iteration 36, loss = 0.00805615
Iteration 37, loss = 0.00776171
Iteration 38, loss = 0.00763080
Iteration 39, loss = 0.00726489
Iteration 40, loss = 0.00714988
Iteration 41, loss = 0.00685282
Iteration 42, loss = 0.00659775
Iteration 43, loss = 0.00639796
Iteration 44, loss = 0.00611637
Iteration 45, loss = 0.00609735
Iteration 46, loss = 0.00587444
Iteration 47, loss = 0.00576190
Iteration 48, loss = 0.00541988
Iteration 49, loss = 0.00532474
Iteration 50, loss = 0.00511732
Iteration 51, loss = 0.00499210
Iteration 52, loss = 0.00485080
Iteration 53, loss = 0.00464069
Iteration 54, loss = 0.00454090
Iteration 55, loss = 0.00443288
Iteration 56, loss = 0.00426909
Iteration 57, loss = 0.00421925
Iteration 58, loss = 0.00403181
Iteration 59, loss = 0.00395046
Iteration 60, loss = 0.00381578
Iteration 61, loss = 0.00374198
Iteration 62, loss = 0.00356374
Iteration 63, loss = 0.00350857
Iteration 64, loss = 0.00342358
Iteration 65, loss = 0.00336751
Iteration 66, loss = 0.00329655
Iteration 67, loss = 0.00329842
Iteration 68, loss = 0.00313793
Iteration 69, loss = 0.00306757
Iteration 70, loss = 0.00297364
Iteration 71, loss = 0.00295272
Iteration 72, loss = 0.00283503
Iteration 73, loss = 0.00272442
Iteration 74, loss = 0.00274237
Iteration 75, loss = 0.00262782
Iteration 76, loss = 0.00265177
Iteration 77, loss = 0.00259277
Iteration 78, loss = 0.00247922
Iteration 79, loss = 0.00246389
Iteration 80, loss = 0.00239360
Iteration 81, loss = 0.00235522
Iteration 82, loss = 0.00242218
Iteration 83, loss = 0.00233988
Iteration 84, loss = 0.00226518
Iteration 85, loss = 0.00234912
Iteration 86, loss = 0.00215704
Iteration 87, loss = 0.00208092
Iteration 88, loss = 0.00214270
Iteration 89, loss = 0.00210693
Iteration 90, loss = 0.00204855
Iteration 91, loss = 0.00201159
Iteration 92, loss = 0.00203170
Iteration 93, loss = 0.00195134
Iteration 94, loss = 0.00196539
Iteration 95, loss = 0.00192569
Iteration 96, loss = 0.00189312
Iteration 97, loss = 0.00190422
Iteration 98, loss = 0.00192208
Iteration 99, loss = 0.00185816
Iteration 100, loss = 0.00181998
Iteration 101, loss = 0.00182768
Iteration 102, loss = 0.00180829
Iteration 103, loss = 0.00173777
Iteration 104, loss = 0.00175141
Iteration 105, loss = 0.00175692
Iteration 106, loss = 0.00175045
Iteration 107, loss = 0.00171697
Iteration 108, loss = 0.00168986
Iteration 109, loss = 0.00176305
Iteration 110, loss = 0.00168126
Iteration 111, loss = 0.00171033
Iteration 112, loss = 0.00162901
Iteration 113, loss = 0.00162189
Iteration 114, loss = 0.00161366
Iteration 115, loss = 0.00164064
Iteration 116, loss = 0.00161176
Iteration 117, loss = 0.00162174
Iteration 118, loss = 0.00163607
Iteration 119, loss = 0.00162542
Iteration 120, loss = 0.00158539
Iteration 121, loss = 0.00154620
Iteration 122, loss = 0.00157431
Iteration 123, loss = 0.00153179
Iteration 124, loss = 0.00152074
Iteration 125, loss = 0.00152054
Iteration 126, loss = 0.00156018
Iteration 127, loss = 0.00154190
Iteration 128, loss = 0.00152496
Iteration 129, loss = 0.00154213
Iteration 130, loss = 0.00154090
Iteration 131, loss = 0.00147575
Iteration 132, loss = 0.00156146
Iteration 133, loss = 0.00149369
Iteration 134, loss = 0.00144032
Iteration 135, loss = 0.00147747
Iteration 136, loss = 0.00149981
Iteration 137, loss = 0.00147589
Iteration 138, loss = 0.00145520
Iteration 139, loss = 0.00146941
Iteration 140, loss = 0.00146131
Iteration 141, loss = 0.00141084
Iteration 142, loss = 0.00145326
Iteration 143, loss = 0.00144133
Iteration 144, loss = 0.00141558
Iteration 145, loss = 0.00161752
Iteration 146, loss = 0.00145348
Iteration 147, loss = 0.00137213
Iteration 148, loss = 0.00136614
Iteration 149, loss = 0.00138073
Iteration 150, loss = 0.00142289
Iteration 151, loss = 0.00164688
Iteration 152, loss = 0.00146325
Iteration 153, loss = 0.00135589
Iteration 154, loss = 0.00132736
Iteration 155, loss = 0.00132833
Iteration 156, loss = 0.00141101
Iteration 157, loss = 0.00144429
Iteration 158, loss = 0.00157112
Iteration 159, loss = 0.00138570
Iteration 160, loss = 0.00134286
Iteration 161, loss = 0.00131798
Iteration 162, loss = 0.00135122
Iteration 163, loss = 0.00166351
Iteration 164, loss = 0.00152886
Iteration 165, loss = 0.00132187
Iteration 166, loss = 0.00129756
Iteration 167, loss = 0.00129283
Iteration 168, loss = 0.00129704
Iteration 169, loss = 0.00142040
Iteration 170, loss = 0.00169112
Iteration 171, loss = 0.00131724
Iteration 172, loss = 0.00129550
Iteration 173, loss = 0.00128970
Iteration 174, loss = 0.00136765
Iteration 175, loss = 0.00136831
Iteration 176, loss = 0.00131201
Iteration 177, loss = 0.00131402
Iteration 178, loss = 0.00139825
Iteration 179, loss = 0.00163978
Iteration 180, loss = 0.00131763
Iteration 181, loss = 0.00126656
Iteration 182, loss = 0.00127017
Iteration 183, loss = 0.00129388
Iteration 184, loss = 0.00136784
Iteration 185, loss = 0.00132134
Iteration 186, loss = 0.00129040
Iteration 187, loss = 0.00140376
Iteration 188, loss = 0.00151670
Iteration 189, loss = 0.00128150
Iteration 190, loss = 0.00126056
Iteration 191, loss = 0.00125431
Iteration 192, loss = 0.00128121
Iteration 193, loss = 0.00166202
Iteration 194, loss = 0.00146655
Iteration 195, loss = 0.00127808
Iteration 196, loss = 0.00124891
Iteration 197, loss = 0.00123421
Iteration 198, loss = 0.00124305
Iteration 199, loss = 0.00125653
Iteration 200, loss = 0.00127072
Iteration 1, loss = 0.12263866
Iteration 2, loss = 0.05998359
Iteration 3, loss = 0.04877762
Iteration 4, loss = 0.04116495
Iteration 5, loss = 0.03601824
Iteration 6, loss = 0.03220744
Iteration 7, loss = 0.02917001
Iteration 8, loss = 0.02679372
Iteration 9, loss = 0.02478223
Iteration 10, loss = 0.02311172
Iteration 11, loss = 0.02170826
Iteration 12, loss = 0.02044674
Iteration 13, loss = 0.01937087
Iteration 14, loss = 0.01836673
Iteration 15, loss = 0.01748622
Iteration 16, loss = 0.01670857
Iteration 17, loss = 0.01577695
Iteration 18, loss = 0.01513090
Iteration 19, loss = 0.01448958
Iteration 20, loss = 0.01382445
Iteration 21, loss = 0.01333635
Iteration 22, loss = 0.01280653
Iteration 23, loss = 0.01224439
Iteration 24, loss = 0.01187800
Iteration 25, loss = 0.01126487
Iteration 26, loss = 0.01075676
Iteration 27, loss = 0.01043163
Iteration 28, loss = 0.01009045
Iteration 29, loss = 0.00986224
Iteration 30, loss = 0.00937862
Iteration 31, loss = 0.00890602
Iteration 32, loss = 0.00879175
Iteration 33, loss = 0.00830398
Iteration 34, loss = 0.00824428
Iteration 35, loss = 0.00777733
Iteration 36, loss = 0.00759460
Iteration 37, loss = 0.00729312
Iteration 38, loss = 0.00697106
Iteration 39, loss = 0.00673921
Iteration 40, loss = 0.00657637
Iteration 41, loss = 0.00630419
Iteration 42, loss = 0.00604411
Iteration 43, loss = 0.00583789
Iteration 44, loss = 0.00578120
Iteration 45, loss = 0.00546920
Iteration 46, loss = 0.00535619
Iteration 47, loss = 0.00525168
Iteration 48, loss = 0.00497787
Iteration 49, loss = 0.00486830
Iteration 50, loss = 0.00466576
Iteration 51, loss = 0.00453053
Iteration 52, loss = 0.00445981
Iteration 53, loss = 0.00433060
Iteration 54, loss = 0.00420377
Iteration 55, loss = 0.00406098
Iteration 56, loss = 0.00395155
Iteration 57, loss = 0.00379800
Iteration 58, loss = 0.00373313
Iteration 59, loss = 0.00353608
Iteration 60, loss = 0.00350728
Iteration 61, loss = 0.00339946
Iteration 62, loss = 0.00324351
Iteration 63, loss = 0.00327614
Iteration 64, loss = 0.00313500
Iteration 65, loss = 0.00312867
Iteration 66, loss = 0.00297875
Iteration 67, loss = 0.00300729
Iteration 68, loss = 0.00287523
Iteration 69, loss = 0.00282126
Iteration 70, loss = 0.00272803
Iteration 71, loss = 0.00266033
Iteration 72, loss = 0.00259836
Iteration 73, loss = 0.00253812
Iteration 74, loss = 0.00249958
Iteration 75, loss = 0.00247568
Iteration 76, loss = 0.00245630
Iteration 77, loss = 0.00240441
Iteration 78, loss = 0.00246017
Iteration 79, loss = 0.00227914
Iteration 80, loss = 0.00216258
Iteration 81, loss = 0.00215134
Iteration 82, loss = 0.00235106
Iteration 83, loss = 0.00210578
Iteration 84, loss = 0.00201273
Iteration 85, loss = 0.00202762
Iteration 86, loss = 0.00209883
Iteration 87, loss = 0.00199499
Iteration 88, loss = 0.00196853
Iteration 89, loss = 0.00190791
Iteration 90, loss = 0.00197172
Iteration 91, loss = 0.00194139
Iteration 92, loss = 0.00188960
Iteration 93, loss = 0.00186880
Iteration 94, loss = 0.00182932
Iteration 95, loss = 0.00181855
Iteration 96, loss = 0.00178007
Iteration 97, loss = 0.00184096
Iteration 98, loss = 0.00180840
Iteration 99, loss = 0.00183272
Iteration 100, loss = 0.00181136
Iteration 101, loss = 0.00167468
Iteration 102, loss = 0.00165571
Iteration 103, loss = 0.00169020
Iteration 104, loss = 0.00166588
Iteration 105, loss = 0.00169833
Iteration 106, loss = 0.00175214
Iteration 107, loss = 0.00167656
Iteration 108, loss = 0.00159772
Iteration 109, loss = 0.00157675
Iteration 110, loss = 0.00167485
Iteration 111, loss = 0.00164953
Iteration 112, loss = 0.00154575
Iteration 113, loss = 0.00158313
Iteration 114, loss = 0.00157842
Iteration 115, loss = 0.00159074
Iteration 116, loss = 0.00159104
Iteration 117, loss = 0.00171187
Iteration 118, loss = 0.00147531
Iteration 119, loss = 0.00148007
Iteration 120, loss = 0.00151855
Iteration 121, loss = 0.00151304
Iteration 122, loss = 0.00146790
Iteration 123, loss = 0.00146822
Iteration 124, loss = 0.00152015
Iteration 125, loss = 0.00172597
Iteration 126, loss = 0.00148295
Iteration 127, loss = 0.00140937
Iteration 128, loss = 0.00143899
Iteration 129, loss = 0.00144293
Iteration 130, loss = 0.00156058
Iteration 131, loss = 0.00158595
Iteration 132, loss = 0.00144383
Iteration 133, loss = 0.00139808
Iteration 134, loss = 0.00139379
Iteration 135, loss = 0.00159999
Iteration 136, loss = 0.00163432
Iteration 137, loss = 0.00136580
Iteration 138, loss = 0.00134734
Iteration 139, loss = 0.00136323
Iteration 140, loss = 0.00138817
Iteration 141, loss = 0.00139488
Iteration 142, loss = 0.00167898
Iteration 143, loss = 0.00148711
Iteration 144, loss = 0.00135135
Iteration 145, loss = 0.00132355
Iteration 146, loss = 0.00146698
Iteration 147, loss = 0.00141783
Iteration 148, loss = 0.00146102
Iteration 149, loss = 0.00136140
Iteration 150, loss = 0.00132834
Iteration 151, loss = 0.00134246
Iteration 152, loss = 0.00136239
Iteration 153, loss = 0.00166426
Iteration 154, loss = 0.00134435
Iteration 155, loss = 0.00131045
Iteration 156, loss = 0.00130411
Iteration 157, loss = 0.00131599
Iteration 158, loss = 0.00133949
Iteration 159, loss = 0.00161338
Iteration 160, loss = 0.00173615
Iteration 161, loss = 0.00129324
Iteration 162, loss = 0.00128105
Iteration 163, loss = 0.00127656
Iteration 164, loss = 0.00128279
Iteration 165, loss = 0.00131819
Iteration 166, loss = 0.00145159
Iteration 167, loss = 0.00155876
Iteration 168, loss = 0.00131714
Iteration 169, loss = 0.00127798
Iteration 170, loss = 0.00129069
Iteration 171, loss = 0.00152823
Iteration 172, loss = 0.00128735
Iteration 173, loss = 0.00127276
Iteration 174, loss = 0.00126083
Iteration 175, loss = 0.00146086
Iteration 176, loss = 0.00148231
Iteration 177, loss = 0.00127512
Iteration 178, loss = 0.00126732
Iteration 179, loss = 0.00125842
Iteration 180, loss = 0.00132745
Iteration 181, loss = 0.00163016
Iteration 182, loss = 0.00132541
Iteration 183, loss = 0.00124539
Iteration 184, loss = 0.00124285
Iteration 185, loss = 0.00124677
Iteration 186, loss = 0.00127622
Iteration 187, loss = 0.00167213
Iteration 188, loss = 0.00129978
Iteration 189, loss = 0.00124151
Iteration 190, loss = 0.00122721
Iteration 191, loss = 0.00124429
Iteration 192, loss = 0.00132841
Iteration 193, loss = 0.00156330
Iteration 194, loss = 0.00132953
Iteration 195, loss = 0.00122634
Iteration 196, loss = 0.00121620
Iteration 197, loss = 0.00122411
Iteration 198, loss = 0.00128196
Iteration 199, loss = 0.00146651
Iteration 200, loss = 0.00177092
Iteration 1, loss = 0.12770817
Iteration 2, loss = 0.06041263
Iteration 3, loss = 0.05009535
Iteration 4, loss = 0.04235540
Iteration 5, loss = 0.03685934
Iteration 6, loss = 0.03280944
Iteration 7, loss = 0.02982176
Iteration 8, loss = 0.02749289
Iteration 9, loss = 0.02526888
Iteration 10, loss = 0.02375673
Iteration 11, loss = 0.02236013
Iteration 12, loss = 0.02108317
Iteration 13, loss = 0.02001347
Iteration 14, loss = 0.01893673
Iteration 15, loss = 0.01808686
Iteration 16, loss = 0.01720608
Iteration 17, loss = 0.01632710
Iteration 18, loss = 0.01563330
Iteration 19, loss = 0.01516370
Iteration 20, loss = 0.01433532
Iteration 21, loss = 0.01374504
Iteration 22, loss = 0.01310954
Iteration 23, loss = 0.01272470
Iteration 24, loss = 0.01214434
Iteration 25, loss = 0.01184223
Iteration 26, loss = 0.01125506
Iteration 27, loss = 0.01079666
Iteration 28, loss = 0.01042061
Iteration 29, loss = 0.01006356
Iteration 30, loss = 0.00964403
Iteration 31, loss = 0.00933132
Iteration 32, loss = 0.00903011
Iteration 33, loss = 0.00871183
Iteration 34, loss = 0.00839495
Iteration 35, loss = 0.00801612
Iteration 36, loss = 0.00784435
Iteration 37, loss = 0.00762668
Iteration 38, loss = 0.00734022
Iteration 39, loss = 0.00716584
Iteration 40, loss = 0.00678873
Iteration 41, loss = 0.00662140
Iteration 42, loss = 0.00641603
Iteration 43, loss = 0.00626387
Iteration 44, loss = 0.00602581
Iteration 45, loss = 0.00581043
Iteration 46, loss = 0.00559111
Iteration 47, loss = 0.00548734
Iteration 48, loss = 0.00524496
Iteration 49, loss = 0.00522754
Iteration 50, loss = 0.00501456
Iteration 51, loss = 0.00486056
Iteration 52, loss = 0.00463692
Iteration 53, loss = 0.00455278
Iteration 54, loss = 0.00442614
Iteration 55, loss = 0.00435969
Iteration 56, loss = 0.00412343
Iteration 57, loss = 0.00413213
Iteration 58, loss = 0.00393967
Iteration 59, loss = 0.00377513
Iteration 60, loss = 0.00374573
Iteration 61, loss = 0.00367960
Iteration 62, loss = 0.00355284
Iteration 63, loss = 0.00346778
Iteration 64, loss = 0.00349606
Iteration 65, loss = 0.00327406
Iteration 66, loss = 0.00329119
Iteration 67, loss = 0.00310869
Iteration 68, loss = 0.00307476
Iteration 69, loss = 0.00291884
Iteration 70, loss = 0.00293015
Iteration 71, loss = 0.00278136
Iteration 72, loss = 0.00278615
Iteration 73, loss = 0.00277934
Iteration 74, loss = 0.00267530
Iteration 75, loss = 0.00257257
Iteration 76, loss = 0.00254003
Iteration 77, loss = 0.00250171
Iteration 78, loss = 0.00250511
Iteration 79, loss = 0.00250540
Iteration 80, loss = 0.00237559
Iteration 81, loss = 0.00238891
Iteration 82, loss = 0.00225460
Iteration 83, loss = 0.00220982
Iteration 84, loss = 0.00217242
Iteration 85, loss = 0.00225502
Iteration 86, loss = 0.00209263
Iteration 87, loss = 0.00215992
Iteration 88, loss = 0.00206891
Iteration 89, loss = 0.00201534
Iteration 90, loss = 0.00198315
Iteration 91, loss = 0.00208222
Iteration 92, loss = 0.00198511
Iteration 93, loss = 0.00191720
Iteration 94, loss = 0.00195542
Iteration 95, loss = 0.00194761
Iteration 96, loss = 0.00187499
Iteration 97, loss = 0.00186875
Iteration 98, loss = 0.00185203
Iteration 99, loss = 0.00178749
Iteration 100, loss = 0.00183514
Iteration 101, loss = 0.00177952
Iteration 102, loss = 0.00174717
Iteration 103, loss = 0.00183356
Iteration 104, loss = 0.00174528
Iteration 105, loss = 0.00173426
Iteration 106, loss = 0.00174881
Iteration 107, loss = 0.00170648
Iteration 108, loss = 0.00167083
Iteration 109, loss = 0.00166044
Iteration 110, loss = 0.00167181
Iteration 111, loss = 0.00165033
Iteration 112, loss = 0.00167369
Iteration 113, loss = 0.00172183
Iteration 114, loss = 0.00163795
Iteration 115, loss = 0.00157909
Iteration 116, loss = 0.00155243
Iteration 117, loss = 0.00179258
Iteration 118, loss = 0.00159873
Iteration 119, loss = 0.00156222
Iteration 120, loss = 0.00154742
Iteration 121, loss = 0.00151619
Iteration 122, loss = 0.00156198
Iteration 123, loss = 0.00157621
Iteration 124, loss = 0.00154033
Iteration 125, loss = 0.00159499
Iteration 126, loss = 0.00152031
Iteration 127, loss = 0.00147873
Iteration 128, loss = 0.00163135
Iteration 129, loss = 0.00175123
Iteration 130, loss = 0.00148616
Iteration 131, loss = 0.00141325
Iteration 132, loss = 0.00143537
Iteration 133, loss = 0.00160111
Iteration 134, loss = 0.00160892
Iteration 135, loss = 0.00143909
Iteration 136, loss = 0.00141950
Iteration 137, loss = 0.00142378
Iteration 138, loss = 0.00151622
Iteration 139, loss = 0.00180927
Iteration 140, loss = 0.00141237
Iteration 141, loss = 0.00140754
Iteration 142, loss = 0.00137851
Iteration 143, loss = 0.00146872
Iteration 144, loss = 0.00148450
Iteration 145, loss = 0.00159835
Iteration 146, loss = 0.00153415
Iteration 147, loss = 0.00143176
Iteration 148, loss = 0.00137087
Iteration 149, loss = 0.00136594
Iteration 150, loss = 0.00149690
Iteration 151, loss = 0.00165194
Iteration 152, loss = 0.00137609
Iteration 153, loss = 0.00134992
Iteration 154, loss = 0.00135210
Iteration 155, loss = 0.00138602
Iteration 156, loss = 0.00137778
Iteration 157, loss = 0.00155535
Iteration 158, loss = 0.00176689
Iteration 159, loss = 0.00136520
Iteration 160, loss = 0.00132464
Iteration 161, loss = 0.00133003
Iteration 162, loss = 0.00132814
Iteration 163, loss = 0.00148257
Iteration 164, loss = 0.00180507
Iteration 165, loss = 0.00134329
Iteration 166, loss = 0.00131951
Iteration 167, loss = 0.00132216
Iteration 168, loss = 0.00130415
Iteration 169, loss = 0.00132957
Iteration 170, loss = 0.00151003
Iteration 171, loss = 0.00157929
Iteration 172, loss = 0.00132462
Iteration 173, loss = 0.00130403
Iteration 174, loss = 0.00129826
Iteration 175, loss = 0.00135057
Iteration 176, loss = 0.00206080
Iteration 177, loss = 0.00131479
Iteration 178, loss = 0.00129602
Iteration 179, loss = 0.00128571
Iteration 180, loss = 0.00127058
Iteration 181, loss = 0.00127960
Iteration 182, loss = 0.00139650
Iteration 183, loss = 0.00203441
Iteration 184, loss = 0.00135599
Iteration 185, loss = 0.00127737
Iteration 186, loss = 0.00126797
Iteration 187, loss = 0.00126058
Iteration 188, loss = 0.00129557
Iteration 189, loss = 0.00132800
Iteration 190, loss = 0.00152395
Iteration 191, loss = 0.00129792
Iteration 192, loss = 0.00127719
Iteration 193, loss = 0.00127769
Iteration 194, loss = 0.00144701
Iteration 195, loss = 0.00188164
Iteration 196, loss = 0.00130659
Iteration 197, loss = 0.00125554
Iteration 198, loss = 0.00124336
Iteration 199, loss = 0.00126561
Iteration 200, loss = 0.00126529
Iteration 1, loss = 0.11194190
Iteration 2, loss = 0.05737208
Iteration 3, loss = 0.04672726
Iteration 4, loss = 0.03952418
Iteration 5, loss = 0.03448373
Iteration 6, loss = 0.03075905
Iteration 7, loss = 0.02796501
Iteration 8, loss = 0.02577533
Iteration 9, loss = 0.02377841
Iteration 10, loss = 0.02221813
Iteration 11, loss = 0.02076686
Iteration 12, loss = 0.01970571
Iteration 13, loss = 0.01842160
Iteration 14, loss = 0.01743782
Iteration 15, loss = 0.01670262
Iteration 16, loss = 0.01595134
Iteration 17, loss = 0.01515157
Iteration 18, loss = 0.01446947
Iteration 19, loss = 0.01379423
Iteration 20, loss = 0.01303276
Iteration 21, loss = 0.01271851
Iteration 22, loss = 0.01209919
Iteration 23, loss = 0.01164277
Iteration 24, loss = 0.01113480
Iteration 25, loss = 0.01074767
Iteration 26, loss = 0.01030445
Iteration 27, loss = 0.01002497
Iteration 28, loss = 0.00958431
Iteration 29, loss = 0.00924361
Iteration 30, loss = 0.00895663
Iteration 31, loss = 0.00863166
Iteration 32, loss = 0.00829541
Iteration 33, loss = 0.00794654
Iteration 34, loss = 0.00771738
Iteration 35, loss = 0.00743208
Iteration 36, loss = 0.00719895
Iteration 37, loss = 0.00707883
Iteration 38, loss = 0.00675053
Iteration 39, loss = 0.00653410
Iteration 40, loss = 0.00634324
Iteration 41, loss = 0.00615620
Iteration 42, loss = 0.00597829
Iteration 43, loss = 0.00574539
Iteration 44, loss = 0.00569365
Iteration 45, loss = 0.00543518
Iteration 46, loss = 0.00519670
Iteration 47, loss = 0.00513493
Iteration 48, loss = 0.00495525
Iteration 49, loss = 0.00477482
Iteration 50, loss = 0.00461899
Iteration 51, loss = 0.00456446
Iteration 52, loss = 0.00446984
Iteration 53, loss = 0.00429573
Iteration 54, loss = 0.00412527
Iteration 55, loss = 0.00416702
Iteration 56, loss = 0.00399690
Iteration 57, loss = 0.00399489
Iteration 58, loss = 0.00370663
Iteration 59, loss = 0.00365791
Iteration 60, loss = 0.00356655
Iteration 61, loss = 0.00355991
Iteration 62, loss = 0.00334073
Iteration 63, loss = 0.00333699
Iteration 64, loss = 0.00330815
Iteration 65, loss = 0.00321127
Iteration 66, loss = 0.00310933
Iteration 67, loss = 0.00297883
Iteration 68, loss = 0.00298558
Iteration 69, loss = 0.00280825
Iteration 70, loss = 0.00294621
Iteration 71, loss = 0.00277912
Iteration 72, loss = 0.00272780
Iteration 73, loss = 0.00268482
Iteration 74, loss = 0.00255724
Iteration 75, loss = 0.00262977
Iteration 76, loss = 0.00246340
Iteration 77, loss = 0.00243866
Iteration 78, loss = 0.00239868
Iteration 79, loss = 0.00236372
Iteration 80, loss = 0.00239967
Iteration 81, loss = 0.00225516
Iteration 82, loss = 0.00235052
Iteration 83, loss = 0.00218801
Iteration 84, loss = 0.00218901
Iteration 85, loss = 0.00209517
Iteration 86, loss = 0.00207128
Iteration 87, loss = 0.00207766
Iteration 88, loss = 0.00202876
Iteration 89, loss = 0.00209491
Iteration 90, loss = 0.00204739
Iteration 91, loss = 0.00191213
Iteration 92, loss = 0.00199938
Iteration 93, loss = 0.00193261
Iteration 94, loss = 0.00186911
Iteration 95, loss = 0.00184403
Iteration 96, loss = 0.00185642
Iteration 97, loss = 0.00192562
Iteration 98, loss = 0.00184532
Iteration 99, loss = 0.00188426
Iteration 100, loss = 0.00178511
Iteration 101, loss = 0.00180863
Iteration 102, loss = 0.00171634
Iteration 103, loss = 0.00176437
Iteration 104, loss = 0.00165541
Iteration 105, loss = 0.00173854
Iteration 106, loss = 0.00179654
Iteration 107, loss = 0.00168774
Iteration 108, loss = 0.00167903
Iteration 109, loss = 0.00168382
Iteration 110, loss = 0.00168333
Iteration 111, loss = 0.00159212
Iteration 112, loss = 0.00161487
Iteration 113, loss = 0.00162684
Iteration 114, loss = 0.00168132
Iteration 115, loss = 0.00158599
Iteration 116, loss = 0.00177529
Iteration 117, loss = 0.00169482
Iteration 118, loss = 0.00152564
Iteration 119, loss = 0.00147812
Iteration 120, loss = 0.00149974
Iteration 121, loss = 0.00152097
Iteration 122, loss = 0.00168392
Iteration 123, loss = 0.00168088
Iteration 124, loss = 0.00151736
Iteration 125, loss = 0.00150628
Iteration 126, loss = 0.00150318
Iteration 127, loss = 0.00146223
Iteration 128, loss = 0.00148610
Iteration 129, loss = 0.00148380
Iteration 130, loss = 0.00180383
Iteration 131, loss = 0.00145266
Iteration 132, loss = 0.00148923
Iteration 133, loss = 0.00150065
Iteration 134, loss = 0.00154094
Iteration 135, loss = 0.00152284
Iteration 136, loss = 0.00148730
Iteration 137, loss = 0.00138556
Iteration 138, loss = 0.00147481
Iteration 139, loss = 0.00142559
Iteration 140, loss = 0.00151463
Iteration 141, loss = 0.00181210
Iteration 142, loss = 0.00156325
Iteration 143, loss = 0.00137364
Iteration 144, loss = 0.00135022
Iteration 145, loss = 0.00135935
Iteration 146, loss = 0.00138396
Iteration 147, loss = 0.00153953
Iteration 148, loss = 0.00175285
Iteration 149, loss = 0.00139020
Iteration 150, loss = 0.00134298
Iteration 151, loss = 0.00133757
Iteration 152, loss = 0.00151734
Iteration 153, loss = 0.00145763
Iteration 154, loss = 0.00135853
Iteration 155, loss = 0.00148996
Iteration 156, loss = 0.00169805
Iteration 157, loss = 0.00134056
Iteration 158, loss = 0.00131618
Iteration 159, loss = 0.00131912
Iteration 160, loss = 0.00132601
Iteration 161, loss = 0.00162732
Iteration 162, loss = 0.00171798
Iteration 163, loss = 0.00137125
Iteration 164, loss = 0.00131155
Iteration 165, loss = 0.00130656
Iteration 166, loss = 0.00131899
Iteration 167, loss = 0.00130901
Iteration 168, loss = 0.00168855
Iteration 169, loss = 0.00139648
Iteration 170, loss = 0.00131359
Iteration 171, loss = 0.00130198
Iteration 172, loss = 0.00135565
Iteration 173, loss = 0.00139549
Iteration 174, loss = 0.00134122
Iteration 175, loss = 0.00177473
Iteration 176, loss = 0.00138158
Iteration 177, loss = 0.00132150
Iteration 178, loss = 0.00128181
Iteration 179, loss = 0.00128161
Iteration 180, loss = 0.00128535
Iteration 181, loss = 0.00136772
Iteration 182, loss = 0.00201246
Iteration 183, loss = 0.00132543
Iteration 184, loss = 0.00128146
Iteration 185, loss = 0.00126541
Iteration 186, loss = 0.00127193
Iteration 187, loss = 0.00127457
Iteration 188, loss = 0.00131892
Iteration 189, loss = 0.00198420
Iteration 190, loss = 0.00150479
Iteration 191, loss = 0.00127501
Iteration 192, loss = 0.00125290
Iteration 193, loss = 0.00124568
Iteration 194, loss = 0.00125105
Iteration 195, loss = 0.00126896
Iteration 196, loss = 0.00136566
Iteration 197, loss = 0.00148501
Iteration 198, loss = 0.00135022
Iteration 199, loss = 0.00126377
Iteration 200, loss = 0.00125654
Iteration 1, loss = 0.13311468
Iteration 2, loss = 0.06510982
Iteration 3, loss = 0.05610932
Iteration 4, loss = 0.04954353
Iteration 5, loss = 0.04369810
Iteration 6, loss = 0.03930322
Iteration 7, loss = 0.03600255
Iteration 8, loss = 0.03342440
Iteration 9, loss = 0.03141253
Iteration 10, loss = 0.02968191
Iteration 11, loss = 0.02825553
Iteration 12, loss = 0.02691044
Iteration 13, loss = 0.02575509
Iteration 14, loss = 0.02473774
Iteration 15, loss = 0.02363496
Iteration 16, loss = 0.02285002
Iteration 17, loss = 0.02207044
Iteration 18, loss = 0.02128442
Iteration 19, loss = 0.02063342
Iteration 20, loss = 0.01997045
Iteration 21, loss = 0.01937714
Iteration 22, loss = 0.01879770
Iteration 23, loss = 0.01823961
Iteration 24, loss = 0.01779526
Iteration 25, loss = 0.01733336
Iteration 26, loss = 0.01694965
Iteration 27, loss = 0.01638091
Iteration 28, loss = 0.01605456
Iteration 29, loss = 0.01556981
Iteration 30, loss = 0.01525776
Iteration 31, loss = 0.01486926
Iteration 32, loss = 0.01454326
Iteration 33, loss = 0.01429033
Iteration 34, loss = 0.01399845
Iteration 35, loss = 0.01365105
Iteration 36, loss = 0.01331530
Iteration 37, loss = 0.01312584
Iteration 38, loss = 0.01287779
Iteration 39, loss = 0.01247792
Iteration 40, loss = 0.01229295
Iteration 41, loss = 0.01205213
Iteration 42, loss = 0.01184712
Iteration 43, loss = 0.01160762
Iteration 44, loss = 0.01147312
Iteration 45, loss = 0.01118247
Iteration 46, loss = 0.01098475
Iteration 47, loss = 0.01085414
Iteration 48, loss = 0.01063019
Iteration 49, loss = 0.01049655
Iteration 50, loss = 0.01036581
Iteration 51, loss = 0.01017943
Iteration 52, loss = 0.00999001
Iteration 53, loss = 0.00981597
Iteration 54, loss = 0.00967824
Iteration 55, loss = 0.00948232
Iteration 56, loss = 0.00933670
Iteration 57, loss = 0.00933511
Iteration 58, loss = 0.00912340
Iteration 59, loss = 0.00902461
Iteration 60, loss = 0.00882902
Iteration 61, loss = 0.00874440
Iteration 62, loss = 0.00859706
Iteration 63, loss = 0.00856817
Iteration 64, loss = 0.00836444
Iteration 65, loss = 0.00832335
Iteration 66, loss = 0.00816821
Iteration 67, loss = 0.00798141
Iteration 68, loss = 0.00805187
Iteration 69, loss = 0.00783581
Iteration 70, loss = 0.00772874
Iteration 71, loss = 0.00764716
Iteration 72, loss = 0.00754733
Iteration 73, loss = 0.00746361
Iteration 74, loss = 0.00738845
Iteration 75, loss = 0.00724709
Iteration 76, loss = 0.00727073
Iteration 77, loss = 0.00713447
Iteration 78, loss = 0.00708043
Iteration 79, loss = 0.00694087
Iteration 80, loss = 0.00690922
Iteration 81, loss = 0.00678468
Iteration 82, loss = 0.00675116
Iteration 83, loss = 0.00659486
Iteration 84, loss = 0.00656768
Iteration 85, loss = 0.00652416
Iteration 86, loss = 0.00639462
Iteration 87, loss = 0.00635590
Iteration 88, loss = 0.00629173
Iteration 89, loss = 0.00619476
Iteration 90, loss = 0.00630261
Iteration 91, loss = 0.00612444
Iteration 92, loss = 0.00608525
Iteration 93, loss = 0.00602982
Iteration 94, loss = 0.00595391
Iteration 95, loss = 0.00591120
Iteration 96, loss = 0.00585816
Iteration 97, loss = 0.00569003
Iteration 98, loss = 0.00574273
Iteration 99, loss = 0.00563809
Iteration 100, loss = 0.00560315
Iteration 101, loss = 0.00556133
Iteration 102, loss = 0.00545217
Iteration 103, loss = 0.00547897
Iteration 104, loss = 0.00540453
Iteration 105, loss = 0.00534480
Iteration 106, loss = 0.00533414
Iteration 107, loss = 0.00527337
Iteration 108, loss = 0.00518640
Iteration 109, loss = 0.00515708
Iteration 110, loss = 0.00510299
Iteration 111, loss = 0.00506129
Iteration 112, loss = 0.00495542
Iteration 113, loss = 0.00503974
Iteration 114, loss = 0.00501462
Iteration 115, loss = 0.00488349
Iteration 116, loss = 0.00491993
Iteration 117, loss = 0.00485949
Iteration 118, loss = 0.00477604
Iteration 119, loss = 0.00473592
Iteration 120, loss = 0.00475633
Iteration 121, loss = 0.00469595
Iteration 122, loss = 0.00461794
Iteration 123, loss = 0.00467297
Iteration 124, loss = 0.00454181
Iteration 125, loss = 0.00449885
Iteration 126, loss = 0.00453598
Iteration 127, loss = 0.00449720
Iteration 128, loss = 0.00450889
Iteration 129, loss = 0.00450409
Iteration 130, loss = 0.00435371
Iteration 131, loss = 0.00430707
Iteration 132, loss = 0.00438416
Iteration 133, loss = 0.00434244
Iteration 134, loss = 0.00428708
Iteration 135, loss = 0.00424814
Iteration 136, loss = 0.00420885
Iteration 137, loss = 0.00422314
Iteration 138, loss = 0.00421349
Iteration 139, loss = 0.00418724
Iteration 140, loss = 0.00414060
Iteration 141, loss = 0.00410342
Iteration 142, loss = 0.00416973
Iteration 143, loss = 0.00408290
Iteration 144, loss = 0.00406288
Iteration 145, loss = 0.00397264
Iteration 146, loss = 0.00400585
Iteration 147, loss = 0.00396479
Iteration 148, loss = 0.00400873
Iteration 149, loss = 0.00396450
Iteration 150, loss = 0.00399046
Iteration 151, loss = 0.00396989
Iteration 152, loss = 0.00384534
Iteration 153, loss = 0.00390552
Iteration 154, loss = 0.00384860
Iteration 155, loss = 0.00383062
Iteration 156, loss = 0.00384908
Iteration 157, loss = 0.00383002
Iteration 158, loss = 0.00377719
Iteration 159, loss = 0.00377159
Iteration 160, loss = 0.00377423
Iteration 161, loss = 0.00376610
Iteration 162, loss = 0.00371897
Iteration 163, loss = 0.00373968
Iteration 164, loss = 0.00381694
Iteration 165, loss = 0.00370221
Iteration 166, loss = 0.00369763
Iteration 167, loss = 0.00374153
Iteration 168, loss = 0.00369844
Iteration 169, loss = 0.00365898
Iteration 170, loss = 0.00363316
Iteration 171, loss = 0.00354865
Iteration 172, loss = 0.00363595
Iteration 173, loss = 0.00359975
Iteration 174, loss = 0.00357412
Iteration 175, loss = 0.00356063
Iteration 176, loss = 0.00355612
Iteration 177, loss = 0.00360782
Iteration 178, loss = 0.00350988
Iteration 179, loss = 0.00365058
Iteration 180, loss = 0.00355485
Iteration 181, loss = 0.00350260
Iteration 182, loss = 0.00352744
Iteration 183, loss = 0.00350344
Iteration 184, loss = 0.00345471
Iteration 185, loss = 0.00347154
Iteration 186, loss = 0.00345605
Iteration 187, loss = 0.00346888
Iteration 188, loss = 0.00343736
Iteration 189, loss = 0.00347806
Iteration 190, loss = 0.00345652
Iteration 191, loss = 0.00343107
Iteration 192, loss = 0.00342783
Iteration 193, loss = 0.00336888
Iteration 194, loss = 0.00342512
Iteration 195, loss = 0.00345560
Iteration 196, loss = 0.00334139
Iteration 197, loss = 0.00342772
Iteration 198, loss = 0.00332373
Iteration 199, loss = 0.00333931
Iteration 200, loss = 0.00341601
Iteration 1, loss = 0.14305945
Iteration 2, loss = 0.06580729
Iteration 3, loss = 0.05550678
Iteration 4, loss = 0.04843562
Iteration 5, loss = 0.04282158
Iteration 6, loss = 0.03885098
Iteration 7, loss = 0.03558417
Iteration 8, loss = 0.03298553
Iteration 9, loss = 0.03087460
Iteration 10, loss = 0.02919866
Iteration 11, loss = 0.02773004
Iteration 12, loss = 0.02643396
Iteration 13, loss = 0.02538083
Iteration 14, loss = 0.02432294
Iteration 15, loss = 0.02353163
Iteration 16, loss = 0.02267838
Iteration 17, loss = 0.02195780
Iteration 18, loss = 0.02122333
Iteration 19, loss = 0.02062066
Iteration 20, loss = 0.02000088
Iteration 21, loss = 0.01939997
Iteration 22, loss = 0.01892780
Iteration 23, loss = 0.01843770
Iteration 24, loss = 0.01806884
Iteration 25, loss = 0.01762340
Iteration 26, loss = 0.01732725
Iteration 27, loss = 0.01679256
Iteration 28, loss = 0.01633416
Iteration 29, loss = 0.01610714
Iteration 30, loss = 0.01575553
Iteration 31, loss = 0.01546470
Iteration 32, loss = 0.01513161
Iteration 33, loss = 0.01485935
Iteration 34, loss = 0.01457613
Iteration 35, loss = 0.01419339
Iteration 36, loss = 0.01399556
Iteration 37, loss = 0.01381656
Iteration 38, loss = 0.01348858
Iteration 39, loss = 0.01321999
Iteration 40, loss = 0.01299774
Iteration 41, loss = 0.01273805
Iteration 42, loss = 0.01250024
Iteration 43, loss = 0.01242532
Iteration 44, loss = 0.01213529
Iteration 45, loss = 0.01189563
Iteration 46, loss = 0.01183681
Iteration 47, loss = 0.01156644
Iteration 48, loss = 0.01137017
Iteration 49, loss = 0.01107435
Iteration 50, loss = 0.01105630
Iteration 51, loss = 0.01078189
Iteration 52, loss = 0.01067952
Iteration 53, loss = 0.01049495
Iteration 54, loss = 0.01038708
Iteration 55, loss = 0.01027214
Iteration 56, loss = 0.01012680
Iteration 57, loss = 0.01000474
Iteration 58, loss = 0.00977717
Iteration 59, loss = 0.00967242
Iteration 60, loss = 0.00957902
Iteration 61, loss = 0.00935914
Iteration 62, loss = 0.00933859
Iteration 63, loss = 0.00912800
Iteration 64, loss = 0.00897837
Iteration 65, loss = 0.00879436
Iteration 66, loss = 0.00876735
Iteration 67, loss = 0.00865238
Iteration 68, loss = 0.00858342
Iteration 69, loss = 0.00844547
Iteration 70, loss = 0.00845651
Iteration 71, loss = 0.00815563
Iteration 72, loss = 0.00806341
Iteration 73, loss = 0.00798006
Iteration 74, loss = 0.00787066
Iteration 75, loss = 0.00787593
Iteration 76, loss = 0.00773500
Iteration 77, loss = 0.00753012
Iteration 78, loss = 0.00754748
Iteration 79, loss = 0.00746521
Iteration 80, loss = 0.00726398
Iteration 81, loss = 0.00723371
Iteration 82, loss = 0.00712381
Iteration 83, loss = 0.00705949
Iteration 84, loss = 0.00693743
Iteration 85, loss = 0.00683665
Iteration 86, loss = 0.00684482
Iteration 87, loss = 0.00680663
Iteration 88, loss = 0.00666635
Iteration 89, loss = 0.00655055
Iteration 90, loss = 0.00657864
Iteration 91, loss = 0.00647472
Iteration 92, loss = 0.00633443
Iteration 93, loss = 0.00626379
Iteration 94, loss = 0.00629194
Iteration 95, loss = 0.00610975
Iteration 96, loss = 0.00618105
Iteration 97, loss = 0.00608057
Iteration 98, loss = 0.00604754
Iteration 99, loss = 0.00588039
Iteration 100, loss = 0.00584367
Iteration 101, loss = 0.00577897
Iteration 102, loss = 0.00585044
Iteration 103, loss = 0.00577224
Iteration 104, loss = 0.00561342
Iteration 105, loss = 0.00558643
Iteration 106, loss = 0.00558400
Iteration 107, loss = 0.00547108
Iteration 108, loss = 0.00550681
Iteration 109, loss = 0.00542685
Iteration 110, loss = 0.00531420
Iteration 111, loss = 0.00535192
Iteration 112, loss = 0.00529059
Iteration 113, loss = 0.00517414
Iteration 114, loss = 0.00515615
Iteration 115, loss = 0.00516049
Iteration 116, loss = 0.00500311
Iteration 117, loss = 0.00500367
Iteration 118, loss = 0.00501003
Iteration 119, loss = 0.00495292
Iteration 120, loss = 0.00492709
Iteration 121, loss = 0.00483418
Iteration 122, loss = 0.00492345
Iteration 123, loss = 0.00469035
Iteration 124, loss = 0.00475868
Iteration 125, loss = 0.00482515
Iteration 126, loss = 0.00470078
Iteration 127, loss = 0.00463115
Iteration 128, loss = 0.00465361
Iteration 129, loss = 0.00457219
Iteration 130, loss = 0.00450623
Iteration 131, loss = 0.00453672
Iteration 132, loss = 0.00449586
Iteration 133, loss = 0.00443192
Iteration 134, loss = 0.00447019
Iteration 135, loss = 0.00437936
Iteration 136, loss = 0.00437490
Iteration 137, loss = 0.00427092
Iteration 138, loss = 0.00430854
Iteration 139, loss = 0.00423932
Iteration 140, loss = 0.00429726
Iteration 141, loss = 0.00422275
Iteration 142, loss = 0.00414507
Iteration 143, loss = 0.00412899
Iteration 144, loss = 0.00416553
Iteration 145, loss = 0.00411141
Iteration 146, loss = 0.00416864
Iteration 147, loss = 0.00402156
Iteration 148, loss = 0.00407209
Iteration 149, loss = 0.00397936
Iteration 150, loss = 0.00405747
Iteration 151, loss = 0.00397179
Iteration 152, loss = 0.00399159
Iteration 153, loss = 0.00395016
Iteration 154, loss = 0.00394880
Iteration 155, loss = 0.00394545
Iteration 156, loss = 0.00386007
Iteration 157, loss = 0.00392962
Iteration 158, loss = 0.00384310
Iteration 159, loss = 0.00380097
Iteration 160, loss = 0.00384535
Iteration 161, loss = 0.00381636
Iteration 162, loss = 0.00376857
Iteration 163, loss = 0.00379176
Iteration 164, loss = 0.00370924
Iteration 165, loss = 0.00369524
Iteration 166, loss = 0.00370192
Iteration 167, loss = 0.00369446
Iteration 168, loss = 0.00367316
Iteration 169, loss = 0.00364570
Iteration 170, loss = 0.00366433
Iteration 171, loss = 0.00366587
Iteration 172, loss = 0.00362748
Iteration 173, loss = 0.00362303
Iteration 174, loss = 0.00357517
Iteration 175, loss = 0.00359553
Iteration 176, loss = 0.00356167
Iteration 177, loss = 0.00357889
Iteration 178, loss = 0.00354490
Iteration 179, loss = 0.00353840
Iteration 180, loss = 0.00355996
Iteration 181, loss = 0.00350803
Iteration 182, loss = 0.00351380
Iteration 183, loss = 0.00352606
Iteration 184, loss = 0.00348311
Iteration 185, loss = 0.00344924
Iteration 186, loss = 0.00342987
Iteration 187, loss = 0.00347751
Iteration 188, loss = 0.00344296
Iteration 189, loss = 0.00342522
Iteration 190, loss = 0.00341710
Iteration 191, loss = 0.00341566
Iteration 192, loss = 0.00340733
Iteration 193, loss = 0.00335258
Iteration 194, loss = 0.00346615
Iteration 195, loss = 0.00338228
Iteration 196, loss = 0.00335785
Iteration 197, loss = 0.00336639
Iteration 198, loss = 0.00340169
Iteration 199, loss = 0.00331098
Iteration 200, loss = 0.00335887
Iteration 1, loss = 0.14403760
Iteration 2, loss = 0.06587149
Iteration 3, loss = 0.05592367
Iteration 4, loss = 0.04925393
Iteration 5, loss = 0.04420718
Iteration 6, loss = 0.03985630
Iteration 7, loss = 0.03625825
Iteration 8, loss = 0.03355579
Iteration 9, loss = 0.03156245
Iteration 10, loss = 0.02975358
Iteration 11, loss = 0.02827537
Iteration 12, loss = 0.02687203
Iteration 13, loss = 0.02570039
Iteration 14, loss = 0.02456017
Iteration 15, loss = 0.02362128
Iteration 16, loss = 0.02274314
Iteration 17, loss = 0.02182429
Iteration 18, loss = 0.02131346
Iteration 19, loss = 0.02056237
Iteration 20, loss = 0.01980060
Iteration 21, loss = 0.01935796
Iteration 22, loss = 0.01875732
Iteration 23, loss = 0.01823692
Iteration 24, loss = 0.01781684
Iteration 25, loss = 0.01731068
Iteration 26, loss = 0.01689368
Iteration 27, loss = 0.01643676
Iteration 28, loss = 0.01615156
Iteration 29, loss = 0.01586964
Iteration 30, loss = 0.01542139
Iteration 31, loss = 0.01513494
Iteration 32, loss = 0.01462985
Iteration 33, loss = 0.01452026
Iteration 34, loss = 0.01414550
Iteration 35, loss = 0.01386538
Iteration 36, loss = 0.01354740
Iteration 37, loss = 0.01336119
Iteration 38, loss = 0.01311476
Iteration 39, loss = 0.01283372
Iteration 40, loss = 0.01266510
Iteration 41, loss = 0.01240180
Iteration 42, loss = 0.01213910
Iteration 43, loss = 0.01205239
Iteration 44, loss = 0.01177352
Iteration 45, loss = 0.01159078
Iteration 46, loss = 0.01131094
Iteration 47, loss = 0.01121468
Iteration 48, loss = 0.01102283
Iteration 49, loss = 0.01082767
Iteration 50, loss = 0.01064906
Iteration 51, loss = 0.01049908
Iteration 52, loss = 0.01031986
Iteration 53, loss = 0.01010838
Iteration 54, loss = 0.01002307
Iteration 55, loss = 0.00984907
Iteration 56, loss = 0.00969163
Iteration 57, loss = 0.00960727
Iteration 58, loss = 0.00947988
Iteration 59, loss = 0.00931611
Iteration 60, loss = 0.00914454
Iteration 61, loss = 0.00910557
Iteration 62, loss = 0.00890437
Iteration 63, loss = 0.00884870
Iteration 64, loss = 0.00865868
Iteration 65, loss = 0.00865152
Iteration 66, loss = 0.00837944
Iteration 67, loss = 0.00832019
Iteration 68, loss = 0.00829596
Iteration 69, loss = 0.00807461
Iteration 70, loss = 0.00802128
Iteration 71, loss = 0.00789404
Iteration 72, loss = 0.00779308
Iteration 73, loss = 0.00772544
Iteration 74, loss = 0.00762893
Iteration 75, loss = 0.00757699
Iteration 76, loss = 0.00759741
Iteration 77, loss = 0.00734175
Iteration 78, loss = 0.00731321
Iteration 79, loss = 0.00719412
Iteration 80, loss = 0.00717174
Iteration 81, loss = 0.00698166
Iteration 82, loss = 0.00699520
Iteration 83, loss = 0.00684534
Iteration 84, loss = 0.00677603
Iteration 85, loss = 0.00679198
Iteration 86, loss = 0.00667318
Iteration 87, loss = 0.00660254
Iteration 88, loss = 0.00650607
Iteration 89, loss = 0.00647541
Iteration 90, loss = 0.00634724
Iteration 91, loss = 0.00634443
Iteration 92, loss = 0.00627331
Iteration 93, loss = 0.00623979
Iteration 94, loss = 0.00611539
Iteration 95, loss = 0.00602679
Iteration 96, loss = 0.00606070
Iteration 97, loss = 0.00599174
Iteration 98, loss = 0.00590904
Iteration 99, loss = 0.00584708
Iteration 100, loss = 0.00587474
Iteration 101, loss = 0.00580510
Iteration 102, loss = 0.00560726
Iteration 103, loss = 0.00565403
Iteration 104, loss = 0.00562329
Iteration 105, loss = 0.00560417
Iteration 106, loss = 0.00547834
Iteration 107, loss = 0.00543657
Iteration 108, loss = 0.00538601
Iteration 109, loss = 0.00540180
Iteration 110, loss = 0.00535633
Iteration 111, loss = 0.00530538
Iteration 112, loss = 0.00525843
Iteration 113, loss = 0.00519163
Iteration 114, loss = 0.00516855
Iteration 115, loss = 0.00512829
Iteration 116, loss = 0.00506594
Iteration 117, loss = 0.00507995
Iteration 118, loss = 0.00496171
Iteration 119, loss = 0.00497665
Iteration 120, loss = 0.00493736
Iteration 121, loss = 0.00485780
Iteration 122, loss = 0.00485797
Iteration 123, loss = 0.00483094
Iteration 124, loss = 0.00480133
Iteration 125, loss = 0.00475660
Iteration 126, loss = 0.00476362
Iteration 127, loss = 0.00471529
Iteration 128, loss = 0.00463658
Iteration 129, loss = 0.00462912
Iteration 130, loss = 0.00456624
Iteration 131, loss = 0.00457354
Iteration 132, loss = 0.00454420
Iteration 133, loss = 0.00451954
Iteration 134, loss = 0.00448355
Iteration 135, loss = 0.00447180
Iteration 136, loss = 0.00443022
Iteration 137, loss = 0.00436980
Iteration 138, loss = 0.00436370
Iteration 139, loss = 0.00433013
Iteration 140, loss = 0.00435496
Iteration 141, loss = 0.00427305
Iteration 142, loss = 0.00426322
Iteration 143, loss = 0.00424028
Iteration 144, loss = 0.00427806
Iteration 145, loss = 0.00413297
Iteration 146, loss = 0.00415047
Iteration 147, loss = 0.00420522
Iteration 148, loss = 0.00419890
Iteration 149, loss = 0.00411081
Iteration 150, loss = 0.00410728
Iteration 151, loss = 0.00407139
Iteration 152, loss = 0.00398274
Iteration 153, loss = 0.00411678
Iteration 154, loss = 0.00403611
Iteration 155, loss = 0.00397878
Iteration 156, loss = 0.00400849
Iteration 157, loss = 0.00399265
Iteration 158, loss = 0.00390740
Iteration 159, loss = 0.00393968
Iteration 160, loss = 0.00389720
Iteration 161, loss = 0.00386504
Iteration 162, loss = 0.00395515
Iteration 163, loss = 0.00382530
Iteration 164, loss = 0.00385917
Iteration 165, loss = 0.00382590
Iteration 166, loss = 0.00384172
Iteration 167, loss = 0.00380429
Iteration 168, loss = 0.00377378
Iteration 169, loss = 0.00384620
Iteration 170, loss = 0.00377982
Iteration 171, loss = 0.00369680
Iteration 172, loss = 0.00376249
Iteration 173, loss = 0.00375813
Iteration 174, loss = 0.00366347
Iteration 175, loss = 0.00374572
Iteration 176, loss = 0.00365730
Iteration 177, loss = 0.00366825
Iteration 178, loss = 0.00361787
Iteration 179, loss = 0.00366011
Iteration 180, loss = 0.00364168
Iteration 181, loss = 0.00366964
Iteration 182, loss = 0.00362179
Iteration 183, loss = 0.00362587
Iteration 184, loss = 0.00361636
Iteration 185, loss = 0.00356784
Iteration 186, loss = 0.00354333
Iteration 187, loss = 0.00348548
Iteration 188, loss = 0.00354210
Iteration 189, loss = 0.00354314
Iteration 190, loss = 0.00355737
Iteration 191, loss = 0.00353250
Iteration 192, loss = 0.00346931
Iteration 193, loss = 0.00348568
Iteration 194, loss = 0.00350364
Iteration 195, loss = 0.00344348
Iteration 196, loss = 0.00346482
Iteration 197, loss = 0.00342469
Iteration 198, loss = 0.00350270
Iteration 199, loss = 0.00343917
Iteration 200, loss = 0.00342681
Iteration 1, loss = 0.13788450
Iteration 2, loss = 0.06457819
Iteration 3, loss = 0.05511853
Iteration 4, loss = 0.04770788
Iteration 5, loss = 0.04153508
Iteration 6, loss = 0.03681294
Iteration 7, loss = 0.03347052
Iteration 8, loss = 0.03084689
Iteration 9, loss = 0.02884779
Iteration 10, loss = 0.02713447
Iteration 11, loss = 0.02564768
Iteration 12, loss = 0.02427535
Iteration 13, loss = 0.02316944
Iteration 14, loss = 0.02230480
Iteration 15, loss = 0.02141569
Iteration 16, loss = 0.02058936
Iteration 17, loss = 0.01967565
Iteration 18, loss = 0.01914229
Iteration 19, loss = 0.01844385
Iteration 20, loss = 0.01779442
Iteration 21, loss = 0.01734484
Iteration 22, loss = 0.01673305
Iteration 23, loss = 0.01624036
Iteration 24, loss = 0.01583829
Iteration 25, loss = 0.01526271
Iteration 26, loss = 0.01497208
Iteration 27, loss = 0.01461517
Iteration 28, loss = 0.01415954
Iteration 29, loss = 0.01377677
Iteration 30, loss = 0.01347139
Iteration 31, loss = 0.01311391
Iteration 32, loss = 0.01273396
Iteration 33, loss = 0.01256355
Iteration 34, loss = 0.01226861
Iteration 35, loss = 0.01201018
Iteration 36, loss = 0.01174979
Iteration 37, loss = 0.01142273
Iteration 38, loss = 0.01121678
Iteration 39, loss = 0.01100655
Iteration 40, loss = 0.01077191
Iteration 41, loss = 0.01057453
Iteration 42, loss = 0.01029906
Iteration 43, loss = 0.01010990
Iteration 44, loss = 0.01005760
Iteration 45, loss = 0.00976864
Iteration 46, loss = 0.00952556
Iteration 47, loss = 0.00936209
Iteration 48, loss = 0.00921497
Iteration 49, loss = 0.00900817
Iteration 50, loss = 0.00882473
Iteration 51, loss = 0.00870228
Iteration 52, loss = 0.00857405
Iteration 53, loss = 0.00839387
Iteration 54, loss = 0.00824208
Iteration 55, loss = 0.00812855
Iteration 56, loss = 0.00797183
Iteration 57, loss = 0.00789480
Iteration 58, loss = 0.00769570
Iteration 59, loss = 0.00760388
Iteration 60, loss = 0.00748597
Iteration 61, loss = 0.00733212
Iteration 62, loss = 0.00728025
Iteration 63, loss = 0.00714253
Iteration 64, loss = 0.00704873
Iteration 65, loss = 0.00694375
Iteration 66, loss = 0.00681710
Iteration 67, loss = 0.00666175
Iteration 68, loss = 0.00656735
Iteration 69, loss = 0.00661945
Iteration 70, loss = 0.00644081
Iteration 71, loss = 0.00642841
Iteration 72, loss = 0.00631265
Iteration 73, loss = 0.00622388
Iteration 74, loss = 0.00616146
Iteration 75, loss = 0.00601643
Iteration 76, loss = 0.00588630
Iteration 77, loss = 0.00582608
Iteration 78, loss = 0.00579639
Iteration 79, loss = 0.00571366
Iteration 80, loss = 0.00566227
Iteration 81, loss = 0.00553288
Iteration 82, loss = 0.00557376
Iteration 83, loss = 0.00547610
Iteration 84, loss = 0.00530594
Iteration 85, loss = 0.00530357
Iteration 86, loss = 0.00523392
Iteration 87, loss = 0.00517873
Iteration 88, loss = 0.00520426
Iteration 89, loss = 0.00504717
Iteration 90, loss = 0.00503787
Iteration 91, loss = 0.00489007
Iteration 92, loss = 0.00498167
Iteration 93, loss = 0.00475589
Iteration 94, loss = 0.00482274
Iteration 95, loss = 0.00474244
Iteration 96, loss = 0.00466171
Iteration 97, loss = 0.00469128
Iteration 98, loss = 0.00460375
Iteration 99, loss = 0.00459495
Iteration 100, loss = 0.00456249
Iteration 101, loss = 0.00452495
Iteration 102, loss = 0.00447399
Iteration 103, loss = 0.00435996
Iteration 104, loss = 0.00435683
Iteration 105, loss = 0.00434018
Iteration 106, loss = 0.00432453
Iteration 107, loss = 0.00434400
Iteration 108, loss = 0.00423180
Iteration 109, loss = 0.00425346
Iteration 110, loss = 0.00418719
Iteration 111, loss = 0.00410690
Iteration 112, loss = 0.00412342
Iteration 113, loss = 0.00406676
Iteration 114, loss = 0.00405183
Iteration 115, loss = 0.00403400
Iteration 116, loss = 0.00403227
Iteration 117, loss = 0.00394833
Iteration 118, loss = 0.00391258
Iteration 119, loss = 0.00401156
Iteration 120, loss = 0.00387506
Iteration 121, loss = 0.00388172
Iteration 122, loss = 0.00387855
Iteration 123, loss = 0.00381843
Iteration 124, loss = 0.00374589
Iteration 125, loss = 0.00385603
Iteration 126, loss = 0.00369081
Iteration 127, loss = 0.00377206
Iteration 128, loss = 0.00368188
Iteration 129, loss = 0.00366489
Iteration 130, loss = 0.00377839
Iteration 131, loss = 0.00361844
Iteration 132, loss = 0.00365875
Iteration 133, loss = 0.00367361
Iteration 134, loss = 0.00362517
Iteration 135, loss = 0.00358767
Iteration 136, loss = 0.00359340
Iteration 137, loss = 0.00350528
Iteration 138, loss = 0.00353097
Iteration 139, loss = 0.00354317
Iteration 140, loss = 0.00348561
Iteration 141, loss = 0.00350155
Iteration 142, loss = 0.00351964
Iteration 143, loss = 0.00346685
Iteration 144, loss = 0.00356382
Iteration 145, loss = 0.00355134
Iteration 146, loss = 0.00339834
Iteration 147, loss = 0.00337958
Iteration 148, loss = 0.00345157
Iteration 149, loss = 0.00333744
Iteration 150, loss = 0.00337709
Iteration 151, loss = 0.00330939
Iteration 152, loss = 0.00346373
Iteration 153, loss = 0.00343718
Iteration 154, loss = 0.00321488
Iteration 155, loss = 0.00336809
Iteration 156, loss = 0.00334066
Iteration 157, loss = 0.00326871
Iteration 158, loss = 0.00334383
Iteration 159, loss = 0.00326624
Iteration 160, loss = 0.00323528
Iteration 161, loss = 0.00327724
Iteration 162, loss = 0.00326782
Iteration 163, loss = 0.00327284
Iteration 164, loss = 0.00325955
Iteration 165, loss = 0.00328432
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.15261271
Iteration 2, loss = 0.06596269
Iteration 3, loss = 0.05598972
Iteration 4, loss = 0.04872476
Iteration 5, loss = 0.04293373
Iteration 6, loss = 0.03836537
Iteration 7, loss = 0.03495271
Iteration 8, loss = 0.03221819
Iteration 9, loss = 0.03001916
Iteration 10, loss = 0.02808057
Iteration 11, loss = 0.02651008
Iteration 12, loss = 0.02520543
Iteration 13, loss = 0.02392977
Iteration 14, loss = 0.02286648
Iteration 15, loss = 0.02186910
Iteration 16, loss = 0.02105418
Iteration 17, loss = 0.02025986
Iteration 18, loss = 0.01944580
Iteration 19, loss = 0.01876801
Iteration 20, loss = 0.01818421
Iteration 21, loss = 0.01765152
Iteration 22, loss = 0.01715152
Iteration 23, loss = 0.01650660
Iteration 24, loss = 0.01599236
Iteration 25, loss = 0.01558914
Iteration 26, loss = 0.01526596
Iteration 27, loss = 0.01480870
Iteration 28, loss = 0.01439133
Iteration 29, loss = 0.01400273
Iteration 30, loss = 0.01368653
Iteration 31, loss = 0.01341297
Iteration 32, loss = 0.01307080
Iteration 33, loss = 0.01267176
Iteration 34, loss = 0.01240230
Iteration 35, loss = 0.01213837
Iteration 36, loss = 0.01182372
Iteration 37, loss = 0.01171552
Iteration 38, loss = 0.01155050
Iteration 39, loss = 0.01103289
Iteration 40, loss = 0.01094878
Iteration 41, loss = 0.01068362
Iteration 42, loss = 0.01047970
Iteration 43, loss = 0.01023158
Iteration 44, loss = 0.00997697
Iteration 45, loss = 0.00989726
Iteration 46, loss = 0.00967413
Iteration 47, loss = 0.00941617
Iteration 48, loss = 0.00936373
Iteration 49, loss = 0.00924840
Iteration 50, loss = 0.00900448
Iteration 51, loss = 0.00883443
Iteration 52, loss = 0.00877305
Iteration 53, loss = 0.00851860
Iteration 54, loss = 0.00844828
Iteration 55, loss = 0.00824661
Iteration 56, loss = 0.00813960
Iteration 57, loss = 0.00791652
Iteration 58, loss = 0.00782755
Iteration 59, loss = 0.00764003
Iteration 60, loss = 0.00767812
Iteration 61, loss = 0.00745571
Iteration 62, loss = 0.00738046
Iteration 63, loss = 0.00728030
Iteration 64, loss = 0.00712035
Iteration 65, loss = 0.00705722
Iteration 66, loss = 0.00689477
Iteration 67, loss = 0.00671765
Iteration 68, loss = 0.00666284
Iteration 69, loss = 0.00666183
Iteration 70, loss = 0.00664977
Iteration 71, loss = 0.00646175
Iteration 72, loss = 0.00637317
Iteration 73, loss = 0.00623081
Iteration 74, loss = 0.00622471
Iteration 75, loss = 0.00610539
Iteration 76, loss = 0.00613570
Iteration 77, loss = 0.00594090
Iteration 78, loss = 0.00585886
Iteration 79, loss = 0.00579152
Iteration 80, loss = 0.00566938
Iteration 81, loss = 0.00560750
Iteration 82, loss = 0.00559210
Iteration 83, loss = 0.00547576
Iteration 84, loss = 0.00537415
Iteration 85, loss = 0.00536185
Iteration 86, loss = 0.00532457
Iteration 87, loss = 0.00532636
Iteration 88, loss = 0.00514191
Iteration 89, loss = 0.00517553
Iteration 90, loss = 0.00510278
Iteration 91, loss = 0.00500827
Iteration 92, loss = 0.00504260
Iteration 93, loss = 0.00491900
Iteration 94, loss = 0.00491590
Iteration 95, loss = 0.00484499
Iteration 96, loss = 0.00480977
Iteration 97, loss = 0.00476375
Iteration 98, loss = 0.00465524
Iteration 99, loss = 0.00462407
Iteration 100, loss = 0.00453906
Iteration 101, loss = 0.00452027
Iteration 102, loss = 0.00444850
Iteration 103, loss = 0.00446544
Iteration 104, loss = 0.00448996
Iteration 105, loss = 0.00435660
Iteration 106, loss = 0.00430245
Iteration 107, loss = 0.00425242
Iteration 108, loss = 0.00429924
Iteration 109, loss = 0.00426828
Iteration 110, loss = 0.00422016
Iteration 111, loss = 0.00420481
Iteration 112, loss = 0.00415203
Iteration 113, loss = 0.00411498
Iteration 114, loss = 0.00406465
Iteration 115, loss = 0.00408647
Iteration 116, loss = 0.00407266
Iteration 117, loss = 0.00397971
Iteration 118, loss = 0.00400892
Iteration 119, loss = 0.00391414
Iteration 120, loss = 0.00394323
Iteration 121, loss = 0.00391631
Iteration 122, loss = 0.00384224
Iteration 123, loss = 0.00378124
Iteration 124, loss = 0.00376879
Iteration 125, loss = 0.00385987
Iteration 126, loss = 0.00378725
Iteration 127, loss = 0.00377942
Iteration 128, loss = 0.00368578
Iteration 129, loss = 0.00374026
Iteration 130, loss = 0.00367895
Iteration 131, loss = 0.00359368
Iteration 132, loss = 0.00360992
Iteration 133, loss = 0.00362897
Iteration 134, loss = 0.00363499
Iteration 135, loss = 0.00353633
Iteration 136, loss = 0.00354440
Iteration 137, loss = 0.00354641
Iteration 138, loss = 0.00349264
Iteration 139, loss = 0.00351069
Iteration 140, loss = 0.00350706
Iteration 141, loss = 0.00348547
Iteration 142, loss = 0.00350104
Iteration 143, loss = 0.00348068
Iteration 144, loss = 0.00338919
Iteration 145, loss = 0.00344334
Iteration 146, loss = 0.00340939
Iteration 147, loss = 0.00345643
Iteration 148, loss = 0.00347328
Iteration 149, loss = 0.00337761
Iteration 150, loss = 0.00335237
Iteration 151, loss = 0.00330712
Iteration 152, loss = 0.00332763
Iteration 153, loss = 0.00332642
Iteration 154, loss = 0.00334169
Iteration 155, loss = 0.00328889
Iteration 156, loss = 0.00328316
Iteration 157, loss = 0.00328901
Iteration 158, loss = 0.00331839
Iteration 159, loss = 0.00326253
Iteration 160, loss = 0.00324364
Iteration 161, loss = 0.00321475
Iteration 162, loss = 0.00319498
Iteration 163, loss = 0.00324684
Iteration 164, loss = 0.00318514
Iteration 165, loss = 0.00327207
Iteration 166, loss = 0.00320817
Iteration 167, loss = 0.00318268
Iteration 168, loss = 0.00314300
Iteration 169, loss = 0.00310962
Iteration 170, loss = 0.00319350
Iteration 171, loss = 0.00308116
Iteration 172, loss = 0.00321090
Iteration 173, loss = 0.00306759
Iteration 174, loss = 0.00317504
Iteration 175, loss = 0.00302553
Iteration 176, loss = 0.00306804
Iteration 177, loss = 0.00312506
Iteration 178, loss = 0.00316973
Iteration 179, loss = 0.00314153
Iteration 180, loss = 0.00303074
Iteration 181, loss = 0.00308094
Iteration 182, loss = 0.00305277
Iteration 183, loss = 0.00303589
Iteration 184, loss = 0.00303725
Iteration 185, loss = 0.00305262
Iteration 186, loss = 0.00303120
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13075430
Iteration 2, loss = 0.06233563
Iteration 3, loss = 0.05267638
Iteration 4, loss = 0.04464316
Iteration 5, loss = 0.03907546
Iteration 6, loss = 0.03509128
Iteration 7, loss = 0.03200901
Iteration 8, loss = 0.02964395
Iteration 9, loss = 0.02759775
Iteration 10, loss = 0.02598587
Iteration 11, loss = 0.02467083
Iteration 12, loss = 0.02331491
Iteration 13, loss = 0.02237770
Iteration 14, loss = 0.02119066
Iteration 15, loss = 0.02050011
Iteration 16, loss = 0.01966762
Iteration 17, loss = 0.01895531
Iteration 18, loss = 0.01835603
Iteration 19, loss = 0.01766330
Iteration 20, loss = 0.01714426
Iteration 21, loss = 0.01652421
Iteration 22, loss = 0.01598015
Iteration 23, loss = 0.01561969
Iteration 24, loss = 0.01515890
Iteration 25, loss = 0.01468692
Iteration 26, loss = 0.01430113
Iteration 27, loss = 0.01398574
Iteration 28, loss = 0.01367029
Iteration 29, loss = 0.01314779
Iteration 30, loss = 0.01300915
Iteration 31, loss = 0.01268461
Iteration 32, loss = 0.01230208
Iteration 33, loss = 0.01215272
Iteration 34, loss = 0.01187647
Iteration 35, loss = 0.01156161
Iteration 36, loss = 0.01145480
Iteration 37, loss = 0.01115412
Iteration 38, loss = 0.01089313
Iteration 39, loss = 0.01061185
Iteration 40, loss = 0.01047298
Iteration 41, loss = 0.01025922
Iteration 42, loss = 0.01004705
Iteration 43, loss = 0.00982645
Iteration 44, loss = 0.00962485
Iteration 45, loss = 0.00946443
Iteration 46, loss = 0.00918775
Iteration 47, loss = 0.00905199
Iteration 48, loss = 0.00883460
Iteration 49, loss = 0.00868347
Iteration 50, loss = 0.00860299
Iteration 51, loss = 0.00841989
Iteration 52, loss = 0.00827908
Iteration 53, loss = 0.00800815
Iteration 54, loss = 0.00796717
Iteration 55, loss = 0.00776670
Iteration 56, loss = 0.00772652
Iteration 57, loss = 0.00754177
Iteration 58, loss = 0.00739579
Iteration 59, loss = 0.00734017
Iteration 60, loss = 0.00721695
Iteration 61, loss = 0.00703128
Iteration 62, loss = 0.00681280
Iteration 63, loss = 0.00678463
Iteration 64, loss = 0.00665257
Iteration 65, loss = 0.00656053
Iteration 66, loss = 0.00654179
Iteration 67, loss = 0.00640180
Iteration 68, loss = 0.00641415
Iteration 69, loss = 0.00614757
Iteration 70, loss = 0.00611179
Iteration 71, loss = 0.00604082
Iteration 72, loss = 0.00590561
Iteration 73, loss = 0.00578808
Iteration 74, loss = 0.00582608
Iteration 75, loss = 0.00568578
Iteration 76, loss = 0.00558195
Iteration 77, loss = 0.00562681
Iteration 78, loss = 0.00545169
Iteration 79, loss = 0.00537305
Iteration 80, loss = 0.00532523
Iteration 81, loss = 0.00521407
Iteration 82, loss = 0.00514704
Iteration 83, loss = 0.00509056
Iteration 84, loss = 0.00500152
Iteration 85, loss = 0.00503124
Iteration 86, loss = 0.00492479
Iteration 87, loss = 0.00485304
Iteration 88, loss = 0.00480147
Iteration 89, loss = 0.00476365
Iteration 90, loss = 0.00470983
Iteration 91, loss = 0.00469049
Iteration 92, loss = 0.00465733
Iteration 93, loss = 0.00456599
Iteration 94, loss = 0.00459264
Iteration 95, loss = 0.00445711
Iteration 96, loss = 0.00436107
Iteration 97, loss = 0.00440699
Iteration 98, loss = 0.00433395
Iteration 99, loss = 0.00427461
Iteration 100, loss = 0.00427280
Iteration 101, loss = 0.00418963
Iteration 102, loss = 0.00414387
Iteration 103, loss = 0.00415570
Iteration 104, loss = 0.00413763
Iteration 105, loss = 0.00411573
Iteration 106, loss = 0.00412723
Iteration 107, loss = 0.00403803
Iteration 108, loss = 0.00395220
Iteration 109, loss = 0.00392669
Iteration 110, loss = 0.00394528
Iteration 111, loss = 0.00394422
Iteration 112, loss = 0.00387881
Iteration 113, loss = 0.00385311
Iteration 114, loss = 0.00382427
Iteration 115, loss = 0.00381988
Iteration 116, loss = 0.00373200
Iteration 117, loss = 0.00374938
Iteration 118, loss = 0.00375762
Iteration 119, loss = 0.00368434
Iteration 120, loss = 0.00371823
Iteration 121, loss = 0.00365123
Iteration 122, loss = 0.00362683
Iteration 123, loss = 0.00367213
Iteration 124, loss = 0.00357252
Iteration 125, loss = 0.00358509
Iteration 126, loss = 0.00358653
Iteration 127, loss = 0.00353258
Iteration 128, loss = 0.00353611
Iteration 129, loss = 0.00350374
Iteration 130, loss = 0.00349184
Iteration 131, loss = 0.00352452
Iteration 132, loss = 0.00344591
Iteration 133, loss = 0.00348432
Iteration 134, loss = 0.00341700
Iteration 135, loss = 0.00348733
Iteration 136, loss = 0.00339468
Iteration 137, loss = 0.00344657
Iteration 138, loss = 0.00333257
Iteration 139, loss = 0.00336446
Iteration 140, loss = 0.00340138
Iteration 141, loss = 0.00336561
Iteration 142, loss = 0.00332263
Iteration 143, loss = 0.00330948
Iteration 144, loss = 0.00328977
Iteration 145, loss = 0.00333833
Iteration 146, loss = 0.00330774
Iteration 147, loss = 0.00327553
Iteration 148, loss = 0.00322016
Iteration 149, loss = 0.00334009
Iteration 150, loss = 0.00328982
Iteration 151, loss = 0.00323907
Iteration 152, loss = 0.00324539
Iteration 153, loss = 0.00322051
Iteration 154, loss = 0.00321038
Iteration 155, loss = 0.00319989
Iteration 156, loss = 0.00318541
Iteration 157, loss = 0.00317808
Iteration 158, loss = 0.00325311
Iteration 159, loss = 0.00315099
Iteration 160, loss = 0.00311543
Iteration 161, loss = 0.00319170
Iteration 162, loss = 0.00326609
Iteration 163, loss = 0.00309919
Iteration 164, loss = 0.00308736
Iteration 165, loss = 0.00306503
Iteration 166, loss = 0.00317106
Iteration 167, loss = 0.00319157
Iteration 168, loss = 0.00311967
Iteration 169, loss = 0.00306146
Iteration 170, loss = 0.00312070
Iteration 171, loss = 0.00308126
Iteration 172, loss = 0.00303807
Iteration 173, loss = 0.00314309
Iteration 174, loss = 0.00300776
Iteration 175, loss = 0.00308011
Iteration 176, loss = 0.00311096
Iteration 177, loss = 0.00307311
Iteration 178, loss = 0.00302112
Iteration 179, loss = 0.00305603
Iteration 180, loss = 0.00304458
Iteration 181, loss = 0.00300221
Iteration 182, loss = 0.00303536
Iteration 183, loss = 0.00309672
Iteration 184, loss = 0.00301659
Iteration 185, loss = 0.00297631
Iteration 186, loss = 0.00303613
Iteration 187, loss = 0.00295797
Iteration 188, loss = 0.00299566
Iteration 189, loss = 0.00293656
Iteration 190, loss = 0.00299352
Iteration 191, loss = 0.00298062
Iteration 192, loss = 0.00297603
Iteration 193, loss = 0.00297632
Iteration 194, loss = 0.00291430
Iteration 195, loss = 0.00292061
Iteration 196, loss = 0.00301616
Iteration 197, loss = 0.00296753
Iteration 198, loss = 0.00294770
Iteration 199, loss = 0.00293752
Iteration 200, loss = 0.00295442
Iteration 1, loss = 0.14530472
Iteration 2, loss = 0.06494301
Iteration 3, loss = 0.05471900
Iteration 4, loss = 0.04711225
Iteration 5, loss = 0.04126720
Iteration 6, loss = 0.03696662
Iteration 7, loss = 0.03368526
Iteration 8, loss = 0.03073071
Iteration 9, loss = 0.02854402
Iteration 10, loss = 0.02658882
Iteration 11, loss = 0.02492218
Iteration 12, loss = 0.02358247
Iteration 13, loss = 0.02233354
Iteration 14, loss = 0.02115677
Iteration 15, loss = 0.02016741
Iteration 16, loss = 0.01931216
Iteration 17, loss = 0.01871585
Iteration 18, loss = 0.01772940
Iteration 19, loss = 0.01709434
Iteration 20, loss = 0.01668056
Iteration 21, loss = 0.01603763
Iteration 22, loss = 0.01548028
Iteration 23, loss = 0.01514768
Iteration 24, loss = 0.01458486
Iteration 25, loss = 0.01400368
Iteration 26, loss = 0.01365715
Iteration 27, loss = 0.01328681
Iteration 28, loss = 0.01287661
Iteration 29, loss = 0.01273167
Iteration 30, loss = 0.01219730
Iteration 31, loss = 0.01182291
Iteration 32, loss = 0.01164517
Iteration 33, loss = 0.01123289
Iteration 34, loss = 0.01105769
Iteration 35, loss = 0.01068010
Iteration 36, loss = 0.01042853
Iteration 37, loss = 0.01017014
Iteration 38, loss = 0.00992216
Iteration 39, loss = 0.00970768
Iteration 40, loss = 0.00940553
Iteration 41, loss = 0.00929272
Iteration 42, loss = 0.00915035
Iteration 43, loss = 0.00900074
Iteration 44, loss = 0.00858407
Iteration 45, loss = 0.00847732
Iteration 46, loss = 0.00834617
Iteration 47, loss = 0.00818660
Iteration 48, loss = 0.00798506
Iteration 49, loss = 0.00767051
Iteration 50, loss = 0.00766035
Iteration 51, loss = 0.00753173
Iteration 52, loss = 0.00732447
Iteration 53, loss = 0.00714609
Iteration 54, loss = 0.00692999
Iteration 55, loss = 0.00694130
Iteration 56, loss = 0.00671209
Iteration 57, loss = 0.00660800
Iteration 58, loss = 0.00655594
Iteration 59, loss = 0.00630610
Iteration 60, loss = 0.00620656
Iteration 61, loss = 0.00606999
Iteration 62, loss = 0.00601139
Iteration 63, loss = 0.00595539
Iteration 64, loss = 0.00579738
Iteration 65, loss = 0.00572565
Iteration 66, loss = 0.00553480
Iteration 67, loss = 0.00547705
Iteration 68, loss = 0.00553465
Iteration 69, loss = 0.00535735
Iteration 70, loss = 0.00518088
Iteration 71, loss = 0.00511893
Iteration 72, loss = 0.00498594
Iteration 73, loss = 0.00495917
Iteration 74, loss = 0.00502455
Iteration 75, loss = 0.00483685
Iteration 76, loss = 0.00480816
Iteration 77, loss = 0.00475047
Iteration 78, loss = 0.00462866
Iteration 79, loss = 0.00461430
Iteration 80, loss = 0.00460078
Iteration 81, loss = 0.00442790
Iteration 82, loss = 0.00449283
Iteration 83, loss = 0.00436454
Iteration 84, loss = 0.00432733
Iteration 85, loss = 0.00425466
Iteration 86, loss = 0.00426797
Iteration 87, loss = 0.00414101
Iteration 88, loss = 0.00419279
Iteration 89, loss = 0.00407101
Iteration 90, loss = 0.00400789
Iteration 91, loss = 0.00411653
Iteration 92, loss = 0.00392718
Iteration 93, loss = 0.00399072
Iteration 94, loss = 0.00394824
Iteration 95, loss = 0.00383390
Iteration 96, loss = 0.00376864
Iteration 97, loss = 0.00386349
Iteration 98, loss = 0.00372757
Iteration 99, loss = 0.00373488
Iteration 100, loss = 0.00375042
Iteration 101, loss = 0.00367471
Iteration 102, loss = 0.00362181
Iteration 103, loss = 0.00363487
Iteration 104, loss = 0.00362033
Iteration 105, loss = 0.00357607
Iteration 106, loss = 0.00356380
Iteration 107, loss = 0.00351796
Iteration 108, loss = 0.00349561
Iteration 109, loss = 0.00346181
Iteration 110, loss = 0.00350587
Iteration 111, loss = 0.00345494
Iteration 112, loss = 0.00346866
Iteration 113, loss = 0.00344151
Iteration 114, loss = 0.00344663
Iteration 115, loss = 0.00335391
Iteration 116, loss = 0.00331201
Iteration 117, loss = 0.00332676
Iteration 118, loss = 0.00331087
Iteration 119, loss = 0.00337352
Iteration 120, loss = 0.00327288
Iteration 121, loss = 0.00325369
Iteration 122, loss = 0.00338175
Iteration 123, loss = 0.00324750
Iteration 124, loss = 0.00321674
Iteration 125, loss = 0.00324726
Iteration 126, loss = 0.00323679
Iteration 127, loss = 0.00314719
Iteration 128, loss = 0.00318907
Iteration 129, loss = 0.00319560
Iteration 130, loss = 0.00319229
Iteration 131, loss = 0.00323616
Iteration 132, loss = 0.00307903
Iteration 133, loss = 0.00315169
Iteration 134, loss = 0.00317012
Iteration 135, loss = 0.00311981
Iteration 136, loss = 0.00310220
Iteration 137, loss = 0.00303434
Iteration 138, loss = 0.00315574
Iteration 139, loss = 0.00305782
Iteration 140, loss = 0.00305680
Iteration 141, loss = 0.00304595
Iteration 142, loss = 0.00307707
Iteration 143, loss = 0.00304533
Iteration 144, loss = 0.00300322
Iteration 145, loss = 0.00305740
Iteration 146, loss = 0.00298678
Iteration 147, loss = 0.00308000
Iteration 148, loss = 0.00302053
Iteration 149, loss = 0.00301672
Iteration 150, loss = 0.00294647
Iteration 151, loss = 0.00297141
Iteration 152, loss = 0.00294586
Iteration 153, loss = 0.00303795
Iteration 154, loss = 0.00303469
Iteration 155, loss = 0.00298452
Iteration 156, loss = 0.00293144
Iteration 157, loss = 0.00294023
Iteration 158, loss = 0.00299015
Iteration 159, loss = 0.00293001
Iteration 160, loss = 0.00295510
Iteration 161, loss = 0.00300008
Iteration 162, loss = 0.00294739
Iteration 163, loss = 0.00282492
Iteration 164, loss = 0.00283017
Iteration 165, loss = 0.00292223
Iteration 166, loss = 0.00308725
Iteration 167, loss = 0.00299040
Iteration 168, loss = 0.00279404
Iteration 169, loss = 0.00278806
Iteration 170, loss = 0.00281893
Iteration 171, loss = 0.00289000
Iteration 172, loss = 0.00293678
Iteration 173, loss = 0.00290890
Iteration 174, loss = 0.00286963
Iteration 175, loss = 0.00282569
Iteration 176, loss = 0.00283600
Iteration 177, loss = 0.00290348
Iteration 178, loss = 0.00294419
Iteration 179, loss = 0.00286088
Iteration 180, loss = 0.00277548
Iteration 181, loss = 0.00278896
Iteration 182, loss = 0.00281350
Iteration 183, loss = 0.00286861
Iteration 184, loss = 0.00284999
Iteration 185, loss = 0.00280158
Iteration 186, loss = 0.00290971
Iteration 187, loss = 0.00275585
Iteration 188, loss = 0.00280517
Iteration 189, loss = 0.00281619
Iteration 190, loss = 0.00278128
Iteration 191, loss = 0.00276321
Iteration 192, loss = 0.00277194
Iteration 193, loss = 0.00274920
Iteration 194, loss = 0.00282028
Iteration 195, loss = 0.00280020
Iteration 196, loss = 0.00287373
Iteration 197, loss = 0.00285807
Iteration 198, loss = 0.00270280
Iteration 199, loss = 0.00275089
Iteration 200, loss = 0.00284015
Iteration 1, loss = 0.13666721
Iteration 2, loss = 0.06318585
Iteration 3, loss = 0.05314127
Iteration 4, loss = 0.04488058
Iteration 5, loss = 0.03912010
Iteration 6, loss = 0.03523096
Iteration 7, loss = 0.03235230
Iteration 8, loss = 0.02992062
Iteration 9, loss = 0.02790836
Iteration 10, loss = 0.02631449
Iteration 11, loss = 0.02464904
Iteration 12, loss = 0.02349879
Iteration 13, loss = 0.02234025
Iteration 14, loss = 0.02134463
Iteration 15, loss = 0.02047235
Iteration 16, loss = 0.01954131
Iteration 17, loss = 0.01867978
Iteration 18, loss = 0.01800290
Iteration 19, loss = 0.01743477
Iteration 20, loss = 0.01689343
Iteration 21, loss = 0.01617903
Iteration 22, loss = 0.01560489
Iteration 23, loss = 0.01499485
Iteration 24, loss = 0.01452907
Iteration 25, loss = 0.01421835
Iteration 26, loss = 0.01365764
Iteration 27, loss = 0.01330429
Iteration 28, loss = 0.01280236
Iteration 29, loss = 0.01238822
Iteration 30, loss = 0.01207956
Iteration 31, loss = 0.01164786
Iteration 32, loss = 0.01142084
Iteration 33, loss = 0.01107771
Iteration 34, loss = 0.01089051
Iteration 35, loss = 0.01042585
Iteration 36, loss = 0.01027434
Iteration 37, loss = 0.00996819
Iteration 38, loss = 0.00970648
Iteration 39, loss = 0.00950346
Iteration 40, loss = 0.00926078
Iteration 41, loss = 0.00904750
Iteration 42, loss = 0.00868331
Iteration 43, loss = 0.00859542
Iteration 44, loss = 0.00824595
Iteration 45, loss = 0.00818277
Iteration 46, loss = 0.00798849
Iteration 47, loss = 0.00783180
Iteration 48, loss = 0.00760150
Iteration 49, loss = 0.00747232
Iteration 50, loss = 0.00729568
Iteration 51, loss = 0.00709075
Iteration 52, loss = 0.00700852
Iteration 53, loss = 0.00687900
Iteration 54, loss = 0.00676085
Iteration 55, loss = 0.00660823
Iteration 56, loss = 0.00634720
Iteration 57, loss = 0.00629041
Iteration 58, loss = 0.00628245
Iteration 59, loss = 0.00607957
Iteration 60, loss = 0.00606061
Iteration 61, loss = 0.00590193
Iteration 62, loss = 0.00572746
Iteration 63, loss = 0.00565561
Iteration 64, loss = 0.00555160
Iteration 65, loss = 0.00550861
Iteration 66, loss = 0.00536263
Iteration 67, loss = 0.00526579
Iteration 68, loss = 0.00523904
Iteration 69, loss = 0.00517037
Iteration 70, loss = 0.00508996
Iteration 71, loss = 0.00499274
Iteration 72, loss = 0.00488098
Iteration 73, loss = 0.00481313
Iteration 74, loss = 0.00480627
Iteration 75, loss = 0.00475272
Iteration 76, loss = 0.00464735
Iteration 77, loss = 0.00460309
Iteration 78, loss = 0.00451775
Iteration 79, loss = 0.00446336
Iteration 80, loss = 0.00448963
Iteration 81, loss = 0.00438875
Iteration 82, loss = 0.00432131
Iteration 83, loss = 0.00423371
Iteration 84, loss = 0.00421338
Iteration 85, loss = 0.00414060
Iteration 86, loss = 0.00411588
Iteration 87, loss = 0.00405688
Iteration 88, loss = 0.00410856
Iteration 89, loss = 0.00402683
Iteration 90, loss = 0.00390610
Iteration 91, loss = 0.00395930
Iteration 92, loss = 0.00393225
Iteration 93, loss = 0.00383265
Iteration 94, loss = 0.00379873
Iteration 95, loss = 0.00379055
Iteration 96, loss = 0.00371600
Iteration 97, loss = 0.00366982
Iteration 98, loss = 0.00365829
Iteration 99, loss = 0.00373225
Iteration 100, loss = 0.00361417
Iteration 101, loss = 0.00361582
Iteration 102, loss = 0.00354519
Iteration 103, loss = 0.00351946
Iteration 104, loss = 0.00350310
Iteration 105, loss = 0.00349916
Iteration 106, loss = 0.00348605
Iteration 107, loss = 0.00344250
Iteration 108, loss = 0.00345650
Iteration 109, loss = 0.00338892
Iteration 110, loss = 0.00338046
Iteration 111, loss = 0.00342395
Iteration 112, loss = 0.00339247
Iteration 113, loss = 0.00330656
Iteration 114, loss = 0.00337264
Iteration 115, loss = 0.00335141
Iteration 116, loss = 0.00324106
Iteration 117, loss = 0.00330144
Iteration 118, loss = 0.00326909
Iteration 119, loss = 0.00324952
Iteration 120, loss = 0.00321486
Iteration 121, loss = 0.00324706
Iteration 122, loss = 0.00322374
Iteration 123, loss = 0.00317361
Iteration 124, loss = 0.00323257
Iteration 125, loss = 0.00323339
Iteration 126, loss = 0.00315653
Iteration 127, loss = 0.00316037
Iteration 128, loss = 0.00309424
Iteration 129, loss = 0.00314719
Iteration 130, loss = 0.00320157
Iteration 131, loss = 0.00306487
Iteration 132, loss = 0.00312885
Iteration 133, loss = 0.00306788
Iteration 134, loss = 0.00303739
Iteration 135, loss = 0.00309327
Iteration 136, loss = 0.00306195
Iteration 137, loss = 0.00302894
Iteration 138, loss = 0.00303698
Iteration 139, loss = 0.00309121
Iteration 140, loss = 0.00308414
Iteration 141, loss = 0.00305048
Iteration 142, loss = 0.00301779
Iteration 143, loss = 0.00293842
Iteration 144, loss = 0.00298049
Iteration 145, loss = 0.00311053
Iteration 146, loss = 0.00304774
Iteration 147, loss = 0.00294284
Iteration 148, loss = 0.00291149
Iteration 149, loss = 0.00289985
Iteration 150, loss = 0.00298527
Iteration 151, loss = 0.00291280
Iteration 152, loss = 0.00295491
Iteration 153, loss = 0.00299028
Iteration 154, loss = 0.00290333
Iteration 155, loss = 0.00297739
Iteration 156, loss = 0.00290574
Iteration 157, loss = 0.00292361
Iteration 158, loss = 0.00294754
Iteration 159, loss = 0.00289897
Iteration 160, loss = 0.00287530
Iteration 161, loss = 0.00287023
Iteration 162, loss = 0.00285932
Iteration 163, loss = 0.00286623
Iteration 164, loss = 0.00290920
Iteration 165, loss = 0.00293912
Iteration 166, loss = 0.00281786
Iteration 167, loss = 0.00288568
Iteration 168, loss = 0.00288081
Iteration 169, loss = 0.00285928
Iteration 170, loss = 0.00281038
Iteration 171, loss = 0.00286979
Iteration 172, loss = 0.00285660
Iteration 173, loss = 0.00287289
Iteration 174, loss = 0.00297121
Iteration 175, loss = 0.00286406
Iteration 176, loss = 0.00280257
Iteration 177, loss = 0.00280491
Iteration 178, loss = 0.00281245
Iteration 179, loss = 0.00282414
Iteration 180, loss = 0.00278413
Iteration 181, loss = 0.00278038
Iteration 182, loss = 0.00292588
Iteration 183, loss = 0.00288549
Iteration 184, loss = 0.00283336
Iteration 185, loss = 0.00271318
Iteration 186, loss = 0.00272744
Iteration 187, loss = 0.00276481
Iteration 188, loss = 0.00284643
Iteration 189, loss = 0.00285734
Iteration 190, loss = 0.00278784
Iteration 191, loss = 0.00283318
Iteration 192, loss = 0.00270058
Iteration 193, loss = 0.00274673
Iteration 194, loss = 0.00275861
Iteration 195, loss = 0.00277776
Iteration 196, loss = 0.00271948
Iteration 197, loss = 0.00274423
Iteration 198, loss = 0.00277671
Iteration 199, loss = 0.00287476
Iteration 200, loss = 0.00286528
Iteration 1, loss = 0.13403681
Iteration 2, loss = 0.06294449
Iteration 3, loss = 0.05280141
Iteration 4, loss = 0.04551703
Iteration 5, loss = 0.03988966
Iteration 6, loss = 0.03570626
Iteration 7, loss = 0.03248928
Iteration 8, loss = 0.02990706
Iteration 9, loss = 0.02780457
Iteration 10, loss = 0.02612060
Iteration 11, loss = 0.02472148
Iteration 12, loss = 0.02344519
Iteration 13, loss = 0.02230117
Iteration 14, loss = 0.02150066
Iteration 15, loss = 0.02050966
Iteration 16, loss = 0.01968457
Iteration 17, loss = 0.01893429
Iteration 18, loss = 0.01830597
Iteration 19, loss = 0.01751996
Iteration 20, loss = 0.01695882
Iteration 21, loss = 0.01643371
Iteration 22, loss = 0.01595008
Iteration 23, loss = 0.01539323
Iteration 24, loss = 0.01496085
Iteration 25, loss = 0.01436689
Iteration 26, loss = 0.01390040
Iteration 27, loss = 0.01354732
Iteration 28, loss = 0.01331413
Iteration 29, loss = 0.01289707
Iteration 30, loss = 0.01251744
Iteration 31, loss = 0.01212341
Iteration 32, loss = 0.01178814
Iteration 33, loss = 0.01146167
Iteration 34, loss = 0.01128473
Iteration 35, loss = 0.01101730
Iteration 36, loss = 0.01066888
Iteration 37, loss = 0.01049200
Iteration 38, loss = 0.01025767
Iteration 39, loss = 0.01001418
Iteration 40, loss = 0.00966853
Iteration 41, loss = 0.00946002
Iteration 42, loss = 0.00928286
Iteration 43, loss = 0.00897798
Iteration 44, loss = 0.00886157
Iteration 45, loss = 0.00865006
Iteration 46, loss = 0.00858489
Iteration 47, loss = 0.00824584
Iteration 48, loss = 0.00808228
Iteration 49, loss = 0.00791881
Iteration 50, loss = 0.00785943
Iteration 51, loss = 0.00766427
Iteration 52, loss = 0.00742803
Iteration 53, loss = 0.00735894
Iteration 54, loss = 0.00713513
Iteration 55, loss = 0.00702264
Iteration 56, loss = 0.00695643
Iteration 57, loss = 0.00675454
Iteration 58, loss = 0.00667012
Iteration 59, loss = 0.00643362
Iteration 60, loss = 0.00651951
Iteration 61, loss = 0.00635481
Iteration 62, loss = 0.00621215
Iteration 63, loss = 0.00607548
Iteration 64, loss = 0.00603457
Iteration 65, loss = 0.00588121
Iteration 66, loss = 0.00577753
Iteration 67, loss = 0.00569151
Iteration 68, loss = 0.00555337
Iteration 69, loss = 0.00553667
Iteration 70, loss = 0.00544898
Iteration 71, loss = 0.00536225
Iteration 72, loss = 0.00520892
Iteration 73, loss = 0.00514816
Iteration 74, loss = 0.00508264
Iteration 75, loss = 0.00497447
Iteration 76, loss = 0.00497582
Iteration 77, loss = 0.00484213
Iteration 78, loss = 0.00482111
Iteration 79, loss = 0.00474432
Iteration 80, loss = 0.00478523
Iteration 81, loss = 0.00465920
Iteration 82, loss = 0.00461001
Iteration 83, loss = 0.00458299
Iteration 84, loss = 0.00443400
Iteration 85, loss = 0.00450125
Iteration 86, loss = 0.00434311
Iteration 87, loss = 0.00435105
Iteration 88, loss = 0.00426107
Iteration 89, loss = 0.00419841
Iteration 90, loss = 0.00421804
Iteration 91, loss = 0.00411889
Iteration 92, loss = 0.00412921
Iteration 93, loss = 0.00406601
Iteration 94, loss = 0.00406130
Iteration 95, loss = 0.00410219
Iteration 96, loss = 0.00391745
Iteration 97, loss = 0.00385386
Iteration 98, loss = 0.00383326
Iteration 99, loss = 0.00380585
Iteration 100, loss = 0.00380068
Iteration 101, loss = 0.00381578
Iteration 102, loss = 0.00375112
Iteration 103, loss = 0.00376147
Iteration 104, loss = 0.00366757
Iteration 105, loss = 0.00365225
Iteration 106, loss = 0.00361833
Iteration 107, loss = 0.00353592
Iteration 108, loss = 0.00366984
Iteration 109, loss = 0.00355790
Iteration 110, loss = 0.00355112
Iteration 111, loss = 0.00355877
Iteration 112, loss = 0.00343812
Iteration 113, loss = 0.00342480
Iteration 114, loss = 0.00344245
Iteration 115, loss = 0.00339717
Iteration 116, loss = 0.00337651
Iteration 117, loss = 0.00340660
Iteration 118, loss = 0.00351704
Iteration 119, loss = 0.00336400
Iteration 120, loss = 0.00330049
Iteration 121, loss = 0.00330334
Iteration 122, loss = 0.00324058
Iteration 123, loss = 0.00333809
Iteration 124, loss = 0.00326060
Iteration 125, loss = 0.00321212
Iteration 126, loss = 0.00327906
Iteration 127, loss = 0.00319477
Iteration 128, loss = 0.00325223
Iteration 129, loss = 0.00315040
Iteration 130, loss = 0.00319496
Iteration 131, loss = 0.00314630
Iteration 132, loss = 0.00320373
Iteration 133, loss = 0.00317714
Iteration 134, loss = 0.00308797
Iteration 135, loss = 0.00305225
Iteration 136, loss = 0.00312823
Iteration 137, loss = 0.00305265
Iteration 138, loss = 0.00311444
Iteration 139, loss = 0.00306956
Iteration 140, loss = 0.00300611
Iteration 141, loss = 0.00311432
Iteration 142, loss = 0.00300530
Iteration 143, loss = 0.00302369
Iteration 144, loss = 0.00306152
Iteration 145, loss = 0.00303233
Iteration 146, loss = 0.00306307
Iteration 147, loss = 0.00297261
Iteration 148, loss = 0.00293098
Iteration 149, loss = 0.00298211
Iteration 150, loss = 0.00303639
Iteration 151, loss = 0.00306131
Iteration 152, loss = 0.00291462
Iteration 153, loss = 0.00290379
Iteration 154, loss = 0.00292883
Iteration 155, loss = 0.00296507
Iteration 156, loss = 0.00289593
Iteration 157, loss = 0.00300599
Iteration 158, loss = 0.00300728
Iteration 159, loss = 0.00287901
Iteration 160, loss = 0.00290675
Iteration 161, loss = 0.00292570
Iteration 162, loss = 0.00286015
Iteration 163, loss = 0.00288838
Iteration 164, loss = 0.00291750
Iteration 165, loss = 0.00290459
Iteration 166, loss = 0.00288682
Iteration 167, loss = 0.00287843
Iteration 168, loss = 0.00288438
Iteration 169, loss = 0.00281850
Iteration 170, loss = 0.00284097
Iteration 171, loss = 0.00288505
Iteration 172, loss = 0.00291515
Iteration 173, loss = 0.00280040
Iteration 174, loss = 0.00278806
Iteration 175, loss = 0.00301108
Iteration 176, loss = 0.00279748
Iteration 177, loss = 0.00278114
Iteration 178, loss = 0.00275134
Iteration 179, loss = 0.00293921
Iteration 180, loss = 0.00283732
Iteration 181, loss = 0.00276928
Iteration 182, loss = 0.00280461
Iteration 183, loss = 0.00274649
Iteration 184, loss = 0.00278075
Iteration 185, loss = 0.00336010
Iteration 186, loss = 0.00273295
Iteration 187, loss = 0.00271234
Iteration 188, loss = 0.00267011
Iteration 189, loss = 0.00276557
Iteration 190, loss = 0.00294623
Iteration 191, loss = 0.00274610
Iteration 192, loss = 0.00273849
Iteration 193, loss = 0.00271959
Iteration 194, loss = 0.00282262
Iteration 195, loss = 0.00288673
Iteration 196, loss = 0.00287980
Iteration 197, loss = 0.00271438
Iteration 198, loss = 0.00270661
Iteration 199, loss = 0.00267921
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.12456393
Iteration 2, loss = 0.06130478
Iteration 3, loss = 0.05116069
Iteration 4, loss = 0.04336798
Iteration 5, loss = 0.03800729
Iteration 6, loss = 0.03407534
Iteration 7, loss = 0.03100661
Iteration 8, loss = 0.02858031
Iteration 9, loss = 0.02653805
Iteration 10, loss = 0.02486094
Iteration 11, loss = 0.02325638
Iteration 12, loss = 0.02209725
Iteration 13, loss = 0.02076532
Iteration 14, loss = 0.01981987
Iteration 15, loss = 0.01899636
Iteration 16, loss = 0.01814305
Iteration 17, loss = 0.01754565
Iteration 18, loss = 0.01678006
Iteration 19, loss = 0.01610795
Iteration 20, loss = 0.01551853
Iteration 21, loss = 0.01493359
Iteration 22, loss = 0.01452978
Iteration 23, loss = 0.01392311
Iteration 24, loss = 0.01344291
Iteration 25, loss = 0.01314626
Iteration 26, loss = 0.01257253
Iteration 27, loss = 0.01240607
Iteration 28, loss = 0.01186870
Iteration 29, loss = 0.01155627
Iteration 30, loss = 0.01121788
Iteration 31, loss = 0.01081768
Iteration 32, loss = 0.01055320
Iteration 33, loss = 0.01031631
Iteration 34, loss = 0.01000972
Iteration 35, loss = 0.00982444
Iteration 36, loss = 0.00946626
Iteration 37, loss = 0.00917844
Iteration 38, loss = 0.00894462
Iteration 39, loss = 0.00874258
Iteration 40, loss = 0.00850675
Iteration 41, loss = 0.00830760
Iteration 42, loss = 0.00805605
Iteration 43, loss = 0.00813884
Iteration 44, loss = 0.00775149
Iteration 45, loss = 0.00754167
Iteration 46, loss = 0.00736020
Iteration 47, loss = 0.00721519
Iteration 48, loss = 0.00697721
Iteration 49, loss = 0.00697525
Iteration 50, loss = 0.00668587
Iteration 51, loss = 0.00667974
Iteration 52, loss = 0.00655094
Iteration 53, loss = 0.00625381
Iteration 54, loss = 0.00625569
Iteration 55, loss = 0.00610541
Iteration 56, loss = 0.00600232
Iteration 57, loss = 0.00584823
Iteration 58, loss = 0.00587084
Iteration 59, loss = 0.00563895
Iteration 60, loss = 0.00551010
Iteration 61, loss = 0.00550773
Iteration 62, loss = 0.00532554
Iteration 63, loss = 0.00531831
Iteration 64, loss = 0.00526159
Iteration 65, loss = 0.00510661
Iteration 66, loss = 0.00502583
Iteration 67, loss = 0.00499848
Iteration 68, loss = 0.00480435
Iteration 69, loss = 0.00482474
Iteration 70, loss = 0.00474227
Iteration 71, loss = 0.00470383
Iteration 72, loss = 0.00454197
Iteration 73, loss = 0.00459519
Iteration 74, loss = 0.00450153
Iteration 75, loss = 0.00441150
Iteration 76, loss = 0.00439998
Iteration 77, loss = 0.00435491
Iteration 78, loss = 0.00424036
Iteration 79, loss = 0.00429921
Iteration 80, loss = 0.00412402
Iteration 81, loss = 0.00407956
Iteration 82, loss = 0.00406299
Iteration 83, loss = 0.00402107
Iteration 84, loss = 0.00407329
Iteration 85, loss = 0.00388560
Iteration 86, loss = 0.00386054
Iteration 87, loss = 0.00387097
Iteration 88, loss = 0.00379388
Iteration 89, loss = 0.00382904
Iteration 90, loss = 0.00374755
Iteration 91, loss = 0.00372469
Iteration 92, loss = 0.00367385
Iteration 93, loss = 0.00365901
Iteration 94, loss = 0.00363709
Iteration 95, loss = 0.00370877
Iteration 96, loss = 0.00361168
Iteration 97, loss = 0.00353078
Iteration 98, loss = 0.00353217
Iteration 99, loss = 0.00350988
Iteration 100, loss = 0.00347873
Iteration 101, loss = 0.00351468
Iteration 102, loss = 0.00337402
Iteration 103, loss = 0.00344792
Iteration 104, loss = 0.00342485
Iteration 105, loss = 0.00331805
Iteration 106, loss = 0.00327217
Iteration 107, loss = 0.00345412
Iteration 108, loss = 0.00334071
Iteration 109, loss = 0.00329058
Iteration 110, loss = 0.00326326
Iteration 111, loss = 0.00328289
Iteration 112, loss = 0.00317922
Iteration 113, loss = 0.00328750
Iteration 114, loss = 0.00321029
Iteration 115, loss = 0.00338362
Iteration 116, loss = 0.00316412
Iteration 117, loss = 0.00320107
Iteration 118, loss = 0.00308993
Iteration 119, loss = 0.00318083
Iteration 120, loss = 0.00311031
Iteration 121, loss = 0.00315504
Iteration 122, loss = 0.00322334
Iteration 123, loss = 0.00309493
Iteration 124, loss = 0.00304779
Iteration 125, loss = 0.00313997
Iteration 126, loss = 0.00308353
Iteration 127, loss = 0.00311990
Iteration 128, loss = 0.00304965
Iteration 129, loss = 0.00307243
Iteration 130, loss = 0.00304540
Iteration 131, loss = 0.00303753
Iteration 132, loss = 0.00306968
Iteration 133, loss = 0.00299289
Iteration 134, loss = 0.00302432
Iteration 135, loss = 0.00295156
Iteration 136, loss = 0.00296942
Iteration 137, loss = 0.00308882
Iteration 138, loss = 0.00302571
Iteration 139, loss = 0.00294108
Iteration 140, loss = 0.00297247
Iteration 141, loss = 0.00302679
Iteration 142, loss = 0.00287359
Iteration 143, loss = 0.00297922
Iteration 144, loss = 0.00292991
Iteration 145, loss = 0.00297125
Iteration 146, loss = 0.00288205
Iteration 147, loss = 0.00295169
Iteration 148, loss = 0.00292630
Iteration 149, loss = 0.00287210
Iteration 150, loss = 0.00289446
Iteration 151, loss = 0.00290523
Iteration 152, loss = 0.00282555
Iteration 153, loss = 0.00295815
Iteration 154, loss = 0.00290655
Iteration 155, loss = 0.00286409
Iteration 156, loss = 0.00284172
Iteration 157, loss = 0.00290172
Iteration 158, loss = 0.00279029
Iteration 159, loss = 0.00282943
Iteration 160, loss = 0.00307544
Iteration 161, loss = 0.00286681
Iteration 162, loss = 0.00281186
Iteration 163, loss = 0.00281472
Iteration 164, loss = 0.00272684
Iteration 165, loss = 0.00277905
Iteration 166, loss = 0.00276792
Iteration 167, loss = 0.00290994
Iteration 168, loss = 0.00293725
Iteration 169, loss = 0.00293953
Iteration 170, loss = 0.00271218
Iteration 171, loss = 0.00268457
Iteration 172, loss = 0.00274474
Iteration 173, loss = 0.00313561
Iteration 174, loss = 0.00275326
Iteration 175, loss = 0.00264236
Iteration 176, loss = 0.00270792
Iteration 177, loss = 0.00283950
Iteration 178, loss = 0.00293818
Iteration 179, loss = 0.00271668
Iteration 180, loss = 0.00272404
Iteration 181, loss = 0.00274334
Iteration 182, loss = 0.00269289
Iteration 183, loss = 0.00282206
Iteration 184, loss = 0.00279373
Iteration 185, loss = 0.00281133
Iteration 186, loss = 0.00265764
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13018926
Iteration 2, loss = 0.06275748
Iteration 3, loss = 0.05396109
Iteration 4, loss = 0.04594193
Iteration 5, loss = 0.03921180
Iteration 6, loss = 0.03437419
Iteration 7, loss = 0.03103947
Iteration 8, loss = 0.02828471
Iteration 9, loss = 0.02623064
Iteration 10, loss = 0.02439389
Iteration 11, loss = 0.02302935
Iteration 12, loss = 0.02174166
Iteration 13, loss = 0.02049531
Iteration 14, loss = 0.01944014
Iteration 15, loss = 0.01857879
Iteration 16, loss = 0.01794668
Iteration 17, loss = 0.01716949
Iteration 18, loss = 0.01640842
Iteration 19, loss = 0.01576308
Iteration 20, loss = 0.01517576
Iteration 21, loss = 0.01471578
Iteration 22, loss = 0.01410203
Iteration 23, loss = 0.01371492
Iteration 24, loss = 0.01320195
Iteration 25, loss = 0.01289271
Iteration 26, loss = 0.01234720
Iteration 27, loss = 0.01194519
Iteration 28, loss = 0.01156362
Iteration 29, loss = 0.01115538
Iteration 30, loss = 0.01096301
Iteration 31, loss = 0.01065559
Iteration 32, loss = 0.01026431
Iteration 33, loss = 0.01003002
Iteration 34, loss = 0.00977571
Iteration 35, loss = 0.00948309
Iteration 36, loss = 0.00920565
Iteration 37, loss = 0.00897386
Iteration 38, loss = 0.00882598
Iteration 39, loss = 0.00851376
Iteration 40, loss = 0.00839444
Iteration 41, loss = 0.00807697
Iteration 42, loss = 0.00796168
Iteration 43, loss = 0.00773572
Iteration 44, loss = 0.00752881
Iteration 45, loss = 0.00733771
Iteration 46, loss = 0.00725803
Iteration 47, loss = 0.00705815
Iteration 48, loss = 0.00684839
Iteration 49, loss = 0.00677774
Iteration 50, loss = 0.00656387
Iteration 51, loss = 0.00647493
Iteration 52, loss = 0.00632785
Iteration 53, loss = 0.00629186
Iteration 54, loss = 0.00609038
Iteration 55, loss = 0.00587403
Iteration 56, loss = 0.00583669
Iteration 57, loss = 0.00574181
Iteration 58, loss = 0.00564156
Iteration 59, loss = 0.00546066
Iteration 60, loss = 0.00543313
Iteration 61, loss = 0.00528063
Iteration 62, loss = 0.00518684
Iteration 63, loss = 0.00513036
Iteration 64, loss = 0.00506474
Iteration 65, loss = 0.00505080
Iteration 66, loss = 0.00485593
Iteration 67, loss = 0.00481421
Iteration 68, loss = 0.00473528
Iteration 69, loss = 0.00465883
Iteration 70, loss = 0.00462016
Iteration 71, loss = 0.00459073
Iteration 72, loss = 0.00448418
Iteration 73, loss = 0.00438569
Iteration 74, loss = 0.00446263
Iteration 75, loss = 0.00431674
Iteration 76, loss = 0.00424662
Iteration 77, loss = 0.00421020
Iteration 78, loss = 0.00418943
Iteration 79, loss = 0.00421392
Iteration 80, loss = 0.00395484
Iteration 81, loss = 0.00405217
Iteration 82, loss = 0.00404397
Iteration 83, loss = 0.00390415
Iteration 84, loss = 0.00385483
Iteration 85, loss = 0.00389848
Iteration 86, loss = 0.00377045
Iteration 87, loss = 0.00384912
Iteration 88, loss = 0.00379139
Iteration 89, loss = 0.00376647
Iteration 90, loss = 0.00359979
Iteration 91, loss = 0.00362553
Iteration 92, loss = 0.00363232
Iteration 93, loss = 0.00353748
Iteration 94, loss = 0.00355314
Iteration 95, loss = 0.00358609
Iteration 96, loss = 0.00355271
Iteration 97, loss = 0.00349110
Iteration 98, loss = 0.00347362
Iteration 99, loss = 0.00341591
Iteration 100, loss = 0.00344644
Iteration 101, loss = 0.00331972
Iteration 102, loss = 0.00347012
Iteration 103, loss = 0.00338736
Iteration 104, loss = 0.00335593
Iteration 105, loss = 0.00332694
Iteration 106, loss = 0.00325037
Iteration 107, loss = 0.00324902
Iteration 108, loss = 0.00326517
Iteration 109, loss = 0.00332212
Iteration 110, loss = 0.00337369
Iteration 111, loss = 0.00318870
Iteration 112, loss = 0.00322334
Iteration 113, loss = 0.00326769
Iteration 114, loss = 0.00317955
Iteration 115, loss = 0.00316003
Iteration 116, loss = 0.00309749
Iteration 117, loss = 0.00317446
Iteration 118, loss = 0.00313181
Iteration 119, loss = 0.00312424
Iteration 120, loss = 0.00317993
Iteration 121, loss = 0.00312686
Iteration 122, loss = 0.00306235
Iteration 123, loss = 0.00308983
Iteration 124, loss = 0.00305225
Iteration 125, loss = 0.00308455
Iteration 126, loss = 0.00329893
Iteration 127, loss = 0.00294583
Iteration 128, loss = 0.00298719
Iteration 129, loss = 0.00305024
Iteration 130, loss = 0.00300914
Iteration 131, loss = 0.00306940
Iteration 132, loss = 0.00303448
Iteration 133, loss = 0.00301242
Iteration 134, loss = 0.00290947
Iteration 135, loss = 0.00302437
Iteration 136, loss = 0.00305881
Iteration 137, loss = 0.00295714
Iteration 138, loss = 0.00295812
Iteration 139, loss = 0.00293411
Iteration 140, loss = 0.00288339
Iteration 141, loss = 0.00293901
Iteration 142, loss = 0.00307385
Iteration 143, loss = 0.00305042
Iteration 144, loss = 0.00284018
Iteration 145, loss = 0.00286876
Iteration 146, loss = 0.00298747
Iteration 147, loss = 0.00284504
Iteration 148, loss = 0.00290810
Iteration 149, loss = 0.00295223
Iteration 150, loss = 0.00281432
Iteration 151, loss = 0.00281636
Iteration 152, loss = 0.00302979
Iteration 153, loss = 0.00297438
Iteration 154, loss = 0.00281453
Iteration 155, loss = 0.00285753
Iteration 156, loss = 0.00301758
Iteration 157, loss = 0.00277555
Iteration 158, loss = 0.00278555
Iteration 159, loss = 0.00284304
Iteration 160, loss = 0.00300690
Iteration 161, loss = 0.00275118
Iteration 162, loss = 0.00277017
Iteration 163, loss = 0.00287420
Iteration 164, loss = 0.00279110
Iteration 165, loss = 0.00281508
Iteration 166, loss = 0.00282335
Iteration 167, loss = 0.00292847
Iteration 168, loss = 0.00285389
Iteration 169, loss = 0.00280446
Iteration 170, loss = 0.00274641
Iteration 171, loss = 0.00274640
Iteration 172, loss = 0.00280412
Iteration 173, loss = 0.00278597
Iteration 174, loss = 0.00273979
Iteration 175, loss = 0.00273819
Iteration 176, loss = 0.00275954
Iteration 177, loss = 0.00277014
Iteration 178, loss = 0.00281216
Iteration 179, loss = 0.00273870
Iteration 180, loss = 0.00282614
Iteration 181, loss = 0.00270254
Iteration 182, loss = 0.00269074
Iteration 183, loss = 0.00271070
Iteration 184, loss = 0.00295998
Iteration 185, loss = 0.00274208
Iteration 186, loss = 0.00271942
Iteration 187, loss = 0.00264464
Iteration 188, loss = 0.00269349
Iteration 189, loss = 0.00293356
Iteration 190, loss = 0.00274087
Iteration 191, loss = 0.00262721
Iteration 192, loss = 0.00261335
Iteration 193, loss = 0.00272827
Iteration 194, loss = 0.00295608
Iteration 195, loss = 0.00267476
Iteration 196, loss = 0.00261576
Iteration 197, loss = 0.00266468
Iteration 198, loss = 0.00276585
Iteration 199, loss = 0.00270942
Iteration 200, loss = 0.00276553
Iteration 1, loss = 0.13100550
Iteration 2, loss = 0.06161311
Iteration 3, loss = 0.05086378
Iteration 4, loss = 0.04293429
Iteration 5, loss = 0.03740655
Iteration 6, loss = 0.03360411
Iteration 7, loss = 0.03059219
Iteration 8, loss = 0.02808380
Iteration 9, loss = 0.02606086
Iteration 10, loss = 0.02428786
Iteration 11, loss = 0.02276616
Iteration 12, loss = 0.02143147
Iteration 13, loss = 0.02026637
Iteration 14, loss = 0.01917767
Iteration 15, loss = 0.01815482
Iteration 16, loss = 0.01727852
Iteration 17, loss = 0.01654552
Iteration 18, loss = 0.01588820
Iteration 19, loss = 0.01512685
Iteration 20, loss = 0.01465439
Iteration 21, loss = 0.01402667
Iteration 22, loss = 0.01342444
Iteration 23, loss = 0.01301718
Iteration 24, loss = 0.01243552
Iteration 25, loss = 0.01209960
Iteration 26, loss = 0.01176379
Iteration 27, loss = 0.01135022
Iteration 28, loss = 0.01088992
Iteration 29, loss = 0.01055606
Iteration 30, loss = 0.01025331
Iteration 31, loss = 0.00994201
Iteration 32, loss = 0.00955880
Iteration 33, loss = 0.00945994
Iteration 34, loss = 0.00895963
Iteration 35, loss = 0.00872883
Iteration 36, loss = 0.00858727
Iteration 37, loss = 0.00839614
Iteration 38, loss = 0.00822797
Iteration 39, loss = 0.00785321
Iteration 40, loss = 0.00768850
Iteration 41, loss = 0.00755221
Iteration 42, loss = 0.00737047
Iteration 43, loss = 0.00707994
Iteration 44, loss = 0.00702512
Iteration 45, loss = 0.00670908
Iteration 46, loss = 0.00677329
Iteration 47, loss = 0.00646288
Iteration 48, loss = 0.00637761
Iteration 49, loss = 0.00619236
Iteration 50, loss = 0.00607399
Iteration 51, loss = 0.00599894
Iteration 52, loss = 0.00576092
Iteration 53, loss = 0.00571358
Iteration 54, loss = 0.00556650
Iteration 55, loss = 0.00550851
Iteration 56, loss = 0.00530208
Iteration 57, loss = 0.00526710
Iteration 58, loss = 0.00504226
Iteration 59, loss = 0.00506150
Iteration 60, loss = 0.00496700
Iteration 61, loss = 0.00480817
Iteration 62, loss = 0.00482500
Iteration 63, loss = 0.00471854
Iteration 64, loss = 0.00461580
Iteration 65, loss = 0.00461991
Iteration 66, loss = 0.00449493
Iteration 67, loss = 0.00441590
Iteration 68, loss = 0.00438095
Iteration 69, loss = 0.00433954
Iteration 70, loss = 0.00421646
Iteration 71, loss = 0.00414230
Iteration 72, loss = 0.00407165
Iteration 73, loss = 0.00410673
Iteration 74, loss = 0.00398951
Iteration 75, loss = 0.00395984
Iteration 76, loss = 0.00385324
Iteration 77, loss = 0.00384533
Iteration 78, loss = 0.00382755
Iteration 79, loss = 0.00375997
Iteration 80, loss = 0.00381213
Iteration 81, loss = 0.00365770
Iteration 82, loss = 0.00359994
Iteration 83, loss = 0.00355682
Iteration 84, loss = 0.00359171
Iteration 85, loss = 0.00353824
Iteration 86, loss = 0.00349164
Iteration 87, loss = 0.00342807
Iteration 88, loss = 0.00350283
Iteration 89, loss = 0.00345754
Iteration 90, loss = 0.00339452
Iteration 91, loss = 0.00340303
Iteration 92, loss = 0.00335250
Iteration 93, loss = 0.00337598
Iteration 94, loss = 0.00333000
Iteration 95, loss = 0.00341148
Iteration 96, loss = 0.00323292
Iteration 97, loss = 0.00323435
Iteration 98, loss = 0.00320684
Iteration 99, loss = 0.00331145
Iteration 100, loss = 0.00324622
Iteration 101, loss = 0.00322558
Iteration 102, loss = 0.00315977
Iteration 103, loss = 0.00314103
Iteration 104, loss = 0.00314684
Iteration 105, loss = 0.00310650
Iteration 106, loss = 0.00309084
Iteration 107, loss = 0.00316132
Iteration 108, loss = 0.00307285
Iteration 109, loss = 0.00306264
Iteration 110, loss = 0.00320588
Iteration 111, loss = 0.00309246
Iteration 112, loss = 0.00304638
Iteration 113, loss = 0.00302934
Iteration 114, loss = 0.00301984
Iteration 115, loss = 0.00299114
Iteration 116, loss = 0.00295127
Iteration 117, loss = 0.00307340
Iteration 118, loss = 0.00300042
Iteration 119, loss = 0.00295779
Iteration 120, loss = 0.00300016
Iteration 121, loss = 0.00292501
Iteration 122, loss = 0.00294552
Iteration 123, loss = 0.00290235
Iteration 124, loss = 0.00300715
Iteration 125, loss = 0.00295111
Iteration 126, loss = 0.00288637
Iteration 127, loss = 0.00300275
Iteration 128, loss = 0.00281165
Iteration 129, loss = 0.00285335
Iteration 130, loss = 0.00305178
Iteration 131, loss = 0.00303351
Iteration 132, loss = 0.00283251
Iteration 133, loss = 0.00284059
Iteration 134, loss = 0.00286860
Iteration 135, loss = 0.00283037
Iteration 136, loss = 0.00289563
Iteration 137, loss = 0.00290620
Iteration 138, loss = 0.00284245
Iteration 139, loss = 0.00279655
Iteration 140, loss = 0.00282602
Iteration 141, loss = 0.00280933
Iteration 142, loss = 0.00283349
Iteration 143, loss = 0.00292466
Iteration 144, loss = 0.00283051
Iteration 145, loss = 0.00275036
Iteration 146, loss = 0.00275168
Iteration 147, loss = 0.00281519
Iteration 148, loss = 0.00283869
Iteration 149, loss = 0.00289236
Iteration 150, loss = 0.00270253
Iteration 151, loss = 0.00267844
Iteration 152, loss = 0.00272177
Iteration 153, loss = 0.00274569
Iteration 154, loss = 0.00287132
Iteration 155, loss = 0.00276471
Iteration 156, loss = 0.00265418
Iteration 157, loss = 0.00285310
Iteration 158, loss = 0.00273208
Iteration 159, loss = 0.00284070
Iteration 160, loss = 0.00267641
Iteration 161, loss = 0.00274232
Iteration 162, loss = 0.00282831
Iteration 163, loss = 0.00273882
Iteration 164, loss = 0.00274769
Iteration 165, loss = 0.00262887
Iteration 166, loss = 0.00274518
Iteration 167, loss = 0.00264494
Iteration 168, loss = 0.00262528
Iteration 169, loss = 0.00284154
Iteration 170, loss = 0.00272123
Iteration 171, loss = 0.00260915
Iteration 172, loss = 0.00267040
Iteration 173, loss = 0.00281792
Iteration 174, loss = 0.00266427
Iteration 175, loss = 0.00261801
Iteration 176, loss = 0.00261860
Iteration 177, loss = 0.00263363
Iteration 178, loss = 0.00270803
Iteration 179, loss = 0.00268734
Iteration 180, loss = 0.00271662
Iteration 181, loss = 0.00263623
Iteration 182, loss = 0.00267269
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13461930
Iteration 2, loss = 0.06192339
Iteration 3, loss = 0.05226421
Iteration 4, loss = 0.04464628
Iteration 5, loss = 0.03882499
Iteration 6, loss = 0.03415623
Iteration 7, loss = 0.03059709
Iteration 8, loss = 0.02809273
Iteration 9, loss = 0.02576917
Iteration 10, loss = 0.02400830
Iteration 11, loss = 0.02269748
Iteration 12, loss = 0.02145199
Iteration 13, loss = 0.02026865
Iteration 14, loss = 0.01929932
Iteration 15, loss = 0.01841287
Iteration 16, loss = 0.01749570
Iteration 17, loss = 0.01680346
Iteration 18, loss = 0.01611707
Iteration 19, loss = 0.01547886
Iteration 20, loss = 0.01509347
Iteration 21, loss = 0.01434785
Iteration 22, loss = 0.01384466
Iteration 23, loss = 0.01343124
Iteration 24, loss = 0.01289649
Iteration 25, loss = 0.01256569
Iteration 26, loss = 0.01204425
Iteration 27, loss = 0.01156798
Iteration 28, loss = 0.01136159
Iteration 29, loss = 0.01083239
Iteration 30, loss = 0.01057541
Iteration 31, loss = 0.01033805
Iteration 32, loss = 0.01000649
Iteration 33, loss = 0.00978493
Iteration 34, loss = 0.00943107
Iteration 35, loss = 0.00919226
Iteration 36, loss = 0.00892007
Iteration 37, loss = 0.00859886
Iteration 38, loss = 0.00850763
Iteration 39, loss = 0.00813545
Iteration 40, loss = 0.00802885
Iteration 41, loss = 0.00772709
Iteration 42, loss = 0.00759711
Iteration 43, loss = 0.00736690
Iteration 44, loss = 0.00709728
Iteration 45, loss = 0.00704413
Iteration 46, loss = 0.00684072
Iteration 47, loss = 0.00675852
Iteration 48, loss = 0.00647891
Iteration 49, loss = 0.00641745
Iteration 50, loss = 0.00627389
Iteration 51, loss = 0.00610581
Iteration 52, loss = 0.00600241
Iteration 53, loss = 0.00584308
Iteration 54, loss = 0.00570166
Iteration 55, loss = 0.00555261
Iteration 56, loss = 0.00551740
Iteration 57, loss = 0.00530732
Iteration 58, loss = 0.00526890
Iteration 59, loss = 0.00516391
Iteration 60, loss = 0.00512199
Iteration 61, loss = 0.00501788
Iteration 62, loss = 0.00487421
Iteration 63, loss = 0.00477909
Iteration 64, loss = 0.00478118
Iteration 65, loss = 0.00467264
Iteration 66, loss = 0.00458074
Iteration 67, loss = 0.00445918
Iteration 68, loss = 0.00437413
Iteration 69, loss = 0.00441801
Iteration 70, loss = 0.00435216
Iteration 71, loss = 0.00428836
Iteration 72, loss = 0.00414534
Iteration 73, loss = 0.00416406
Iteration 74, loss = 0.00412415
Iteration 75, loss = 0.00407602
Iteration 76, loss = 0.00405751
Iteration 77, loss = 0.00390830
Iteration 78, loss = 0.00394858
Iteration 79, loss = 0.00388224
Iteration 80, loss = 0.00380752
Iteration 81, loss = 0.00379640
Iteration 82, loss = 0.00377703
Iteration 83, loss = 0.00369826
Iteration 84, loss = 0.00375480
Iteration 85, loss = 0.00371301
Iteration 86, loss = 0.00354303
Iteration 87, loss = 0.00361746
Iteration 88, loss = 0.00350211
Iteration 89, loss = 0.00362872
Iteration 90, loss = 0.00354843
Iteration 91, loss = 0.00348334
Iteration 92, loss = 0.00340245
Iteration 93, loss = 0.00340774
Iteration 94, loss = 0.00345657
Iteration 95, loss = 0.00337909
Iteration 96, loss = 0.00338878
Iteration 97, loss = 0.00332486
Iteration 98, loss = 0.00330490
Iteration 99, loss = 0.00334121
Iteration 100, loss = 0.00341106
Iteration 101, loss = 0.00332301
Iteration 102, loss = 0.00321575
Iteration 103, loss = 0.00319417
Iteration 104, loss = 0.00319255
Iteration 105, loss = 0.00323264
Iteration 106, loss = 0.00322197
Iteration 107, loss = 0.00315358
Iteration 108, loss = 0.00315326
Iteration 109, loss = 0.00310628
Iteration 110, loss = 0.00307833
Iteration 111, loss = 0.00310013
Iteration 112, loss = 0.00315732
Iteration 113, loss = 0.00309948
Iteration 114, loss = 0.00316218
Iteration 115, loss = 0.00309062
Iteration 116, loss = 0.00300803
Iteration 117, loss = 0.00299762
Iteration 118, loss = 0.00305163
Iteration 119, loss = 0.00300730
Iteration 120, loss = 0.00307681
Iteration 121, loss = 0.00298945
Iteration 122, loss = 0.00306709
Iteration 123, loss = 0.00302704
Iteration 124, loss = 0.00301011
Iteration 125, loss = 0.00294113
Iteration 126, loss = 0.00303351
Iteration 127, loss = 0.00292293
Iteration 128, loss = 0.00293420
Iteration 129, loss = 0.00290064
Iteration 130, loss = 0.00295396
Iteration 131, loss = 0.00292280
Iteration 132, loss = 0.00295294
Iteration 133, loss = 0.00298826
Iteration 134, loss = 0.00291948
Iteration 135, loss = 0.00287943
Iteration 136, loss = 0.00292654
Iteration 137, loss = 0.00295990
Iteration 138, loss = 0.00292280
Iteration 139, loss = 0.00286865
Iteration 140, loss = 0.00285901
Iteration 141, loss = 0.00281762
Iteration 142, loss = 0.00282492
Iteration 143, loss = 0.00291888
Iteration 144, loss = 0.00296347
Iteration 145, loss = 0.00283526
Iteration 146, loss = 0.00279541
Iteration 147, loss = 0.00278531
Iteration 148, loss = 0.00286356
Iteration 149, loss = 0.00299517
Iteration 150, loss = 0.00294721
Iteration 151, loss = 0.00275752
Iteration 152, loss = 0.00273650
Iteration 153, loss = 0.00277884
Iteration 154, loss = 0.00298324
Iteration 155, loss = 0.00282367
Iteration 156, loss = 0.00273592
Iteration 157, loss = 0.00287218
Iteration 158, loss = 0.00291509
Iteration 159, loss = 0.00271574
Iteration 160, loss = 0.00268984
Iteration 161, loss = 0.00275597
Iteration 162, loss = 0.00281449
Iteration 163, loss = 0.00290761
Iteration 164, loss = 0.00274977
Iteration 165, loss = 0.00272237
Iteration 166, loss = 0.00273704
Iteration 167, loss = 0.00275763
Iteration 168, loss = 0.00274143
Iteration 169, loss = 0.00277972
Iteration 170, loss = 0.00280662
Iteration 171, loss = 0.00273397
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13692975
Iteration 2, loss = 0.06163383
Iteration 3, loss = 0.05082898
Iteration 4, loss = 0.04298605
Iteration 5, loss = 0.03745799
Iteration 6, loss = 0.03348116
Iteration 7, loss = 0.03025111
Iteration 8, loss = 0.02781552
Iteration 9, loss = 0.02577549
Iteration 10, loss = 0.02413486
Iteration 11, loss = 0.02269855
Iteration 12, loss = 0.02143692
Iteration 13, loss = 0.02027448
Iteration 14, loss = 0.01938098
Iteration 15, loss = 0.01845948
Iteration 16, loss = 0.01759134
Iteration 17, loss = 0.01686110
Iteration 18, loss = 0.01622653
Iteration 19, loss = 0.01558970
Iteration 20, loss = 0.01482657
Iteration 21, loss = 0.01445920
Iteration 22, loss = 0.01383009
Iteration 23, loss = 0.01342986
Iteration 24, loss = 0.01287705
Iteration 25, loss = 0.01242597
Iteration 26, loss = 0.01206991
Iteration 27, loss = 0.01165408
Iteration 28, loss = 0.01119205
Iteration 29, loss = 0.01078282
Iteration 30, loss = 0.01061526
Iteration 31, loss = 0.01019742
Iteration 32, loss = 0.00989649
Iteration 33, loss = 0.00967588
Iteration 34, loss = 0.00933736
Iteration 35, loss = 0.00916510
Iteration 36, loss = 0.00882599
Iteration 37, loss = 0.00852671
Iteration 38, loss = 0.00831179
Iteration 39, loss = 0.00811418
Iteration 40, loss = 0.00796089
Iteration 41, loss = 0.00770639
Iteration 42, loss = 0.00750491
Iteration 43, loss = 0.00728919
Iteration 44, loss = 0.00719187
Iteration 45, loss = 0.00703797
Iteration 46, loss = 0.00680213
Iteration 47, loss = 0.00665709
Iteration 48, loss = 0.00648951
Iteration 49, loss = 0.00629317
Iteration 50, loss = 0.00616323
Iteration 51, loss = 0.00601692
Iteration 52, loss = 0.00595868
Iteration 53, loss = 0.00584844
Iteration 54, loss = 0.00574119
Iteration 55, loss = 0.00560452
Iteration 56, loss = 0.00545106
Iteration 57, loss = 0.00536459
Iteration 58, loss = 0.00528635
Iteration 59, loss = 0.00516031
Iteration 60, loss = 0.00504961
Iteration 61, loss = 0.00495491
Iteration 62, loss = 0.00485265
Iteration 63, loss = 0.00479794
Iteration 64, loss = 0.00474935
Iteration 65, loss = 0.00463269
Iteration 66, loss = 0.00461282
Iteration 67, loss = 0.00449775
Iteration 68, loss = 0.00446214
Iteration 69, loss = 0.00438188
Iteration 70, loss = 0.00435554
Iteration 71, loss = 0.00428370
Iteration 72, loss = 0.00418565
Iteration 73, loss = 0.00425876
Iteration 74, loss = 0.00413432
Iteration 75, loss = 0.00404269
Iteration 76, loss = 0.00391880
Iteration 77, loss = 0.00388228
Iteration 78, loss = 0.00393838
Iteration 79, loss = 0.00392240
Iteration 80, loss = 0.00385648
Iteration 81, loss = 0.00371967
Iteration 82, loss = 0.00374332
Iteration 83, loss = 0.00375997
Iteration 84, loss = 0.00367640
Iteration 85, loss = 0.00363408
Iteration 86, loss = 0.00370516
Iteration 87, loss = 0.00362524
Iteration 88, loss = 0.00354159
Iteration 89, loss = 0.00348045
Iteration 90, loss = 0.00352021
Iteration 91, loss = 0.00354093
Iteration 92, loss = 0.00348069
Iteration 93, loss = 0.00333792
Iteration 94, loss = 0.00343662
Iteration 95, loss = 0.00338345
Iteration 96, loss = 0.00333914
Iteration 97, loss = 0.00330906
Iteration 98, loss = 0.00336329
Iteration 99, loss = 0.00327241
Iteration 100, loss = 0.00325278
Iteration 101, loss = 0.00324276
Iteration 102, loss = 0.00327252
Iteration 103, loss = 0.00319201
Iteration 104, loss = 0.00317727
Iteration 105, loss = 0.00316369
Iteration 106, loss = 0.00321492
Iteration 107, loss = 0.00321491
Iteration 108, loss = 0.00317520
Iteration 109, loss = 0.00314518
Iteration 110, loss = 0.00307309
Iteration 111, loss = 0.00306660
Iteration 112, loss = 0.00305579
Iteration 113, loss = 0.00317115
Iteration 114, loss = 0.00299769
Iteration 115, loss = 0.00300255
Iteration 116, loss = 0.00312526
Iteration 117, loss = 0.00307669
Iteration 118, loss = 0.00302134
Iteration 119, loss = 0.00298343
Iteration 120, loss = 0.00307457
Iteration 121, loss = 0.00304863
Iteration 122, loss = 0.00297583
Iteration 123, loss = 0.00299486
Iteration 124, loss = 0.00313363
Iteration 125, loss = 0.00294576
Iteration 126, loss = 0.00287937
Iteration 127, loss = 0.00286212
Iteration 128, loss = 0.00297577
Iteration 129, loss = 0.00296798
Iteration 130, loss = 0.00294499
Iteration 131, loss = 0.00290251
Iteration 132, loss = 0.00293008
Iteration 133, loss = 0.00285692
Iteration 134, loss = 0.00287201
Iteration 135, loss = 0.00312008
Iteration 136, loss = 0.00285754
Iteration 137, loss = 0.00284416
Iteration 138, loss = 0.00279395
Iteration 139, loss = 0.00279856
Iteration 140, loss = 0.00290699
Iteration 141, loss = 0.00287971
Iteration 142, loss = 0.00275999
Iteration 143, loss = 0.00286380
Iteration 144, loss = 0.00285788
Iteration 145, loss = 0.00283407
Iteration 146, loss = 0.00283092
Iteration 147, loss = 0.00280825
Iteration 148, loss = 0.00276589
Iteration 149, loss = 0.00285588
Iteration 150, loss = 0.00276244
Iteration 151, loss = 0.00284644
Iteration 152, loss = 0.00281448
Iteration 153, loss = 0.00271979
Iteration 154, loss = 0.00279323
Iteration 155, loss = 0.00278503
Iteration 156, loss = 0.00284130
Iteration 157, loss = 0.00273469
Iteration 158, loss = 0.00270898
Iteration 159, loss = 0.00269471
Iteration 160, loss = 0.00278392
Iteration 161, loss = 0.00284753
Iteration 162, loss = 0.00274577
Iteration 163, loss = 0.00271549
Iteration 164, loss = 0.00273338
Iteration 165, loss = 0.00284908
Iteration 166, loss = 0.00277225
Iteration 167, loss = 0.00271036
Iteration 168, loss = 0.00277538
Iteration 169, loss = 0.00281531
Iteration 170, loss = 0.00265841
Iteration 171, loss = 0.00267259
Iteration 172, loss = 0.00277749
Iteration 173, loss = 0.00268647
Iteration 174, loss = 0.00266981
Iteration 175, loss = 0.00276019
Iteration 176, loss = 0.00274318
Iteration 177, loss = 0.00262916
Iteration 178, loss = 0.00261092
Iteration 179, loss = 0.00279280
Iteration 180, loss = 0.00279416
Iteration 181, loss = 0.00271586
Iteration 182, loss = 0.00268082
Iteration 183, loss = 0.00259354
Iteration 184, loss = 0.00261230
Iteration 185, loss = 0.00268647
Iteration 186, loss = 0.00263997
Iteration 187, loss = 0.00304490
Iteration 188, loss = 0.00262310
Iteration 189, loss = 0.00255528
Iteration 190, loss = 0.00257172
Iteration 191, loss = 0.00261450
Iteration 192, loss = 0.00267575
Iteration 193, loss = 0.00290491
Iteration 194, loss = 0.00270085
Iteration 195, loss = 0.00260812
Iteration 196, loss = 0.00258517
Iteration 197, loss = 0.00264354
Iteration 198, loss = 0.00259115
Iteration 199, loss = 0.00264833
Iteration 200, loss = 0.00268718
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.11993754
Iteration 2, loss = 0.05954565
Iteration 3, loss = 0.04935589
Iteration 4, loss = 0.04147446
Iteration 5, loss = 0.03591902
Iteration 6, loss = 0.03173206
Iteration 7, loss = 0.02883534
Iteration 8, loss = 0.02647671
Iteration 9, loss = 0.02470476
Iteration 10, loss = 0.02299716
Iteration 11, loss = 0.02166719
Iteration 12, loss = 0.02055754
Iteration 13, loss = 0.01955233
Iteration 14, loss = 0.01864294
Iteration 15, loss = 0.01773999
Iteration 16, loss = 0.01695631
Iteration 17, loss = 0.01624123
Iteration 18, loss = 0.01570417
Iteration 19, loss = 0.01484916
Iteration 20, loss = 0.01441996
Iteration 21, loss = 0.01387440
Iteration 22, loss = 0.01344934
Iteration 23, loss = 0.01287427
Iteration 24, loss = 0.01240845
Iteration 25, loss = 0.01212661
Iteration 26, loss = 0.01180415
Iteration 27, loss = 0.01147572
Iteration 28, loss = 0.01091051
Iteration 29, loss = 0.01066165
Iteration 30, loss = 0.01033600
Iteration 31, loss = 0.01002464
Iteration 32, loss = 0.00990126
Iteration 33, loss = 0.00951653
Iteration 34, loss = 0.00918535
Iteration 35, loss = 0.00897326
Iteration 36, loss = 0.00880964
Iteration 37, loss = 0.00855108
Iteration 38, loss = 0.00834258
Iteration 39, loss = 0.00815929
Iteration 40, loss = 0.00789317
Iteration 41, loss = 0.00782465
Iteration 42, loss = 0.00749435
Iteration 43, loss = 0.00737823
Iteration 44, loss = 0.00720888
Iteration 45, loss = 0.00709893
Iteration 46, loss = 0.00688910
Iteration 47, loss = 0.00676332
Iteration 48, loss = 0.00664574
Iteration 49, loss = 0.00640889
Iteration 50, loss = 0.00630540
Iteration 51, loss = 0.00616185
Iteration 52, loss = 0.00615067
Iteration 53, loss = 0.00593570
Iteration 54, loss = 0.00585160
Iteration 55, loss = 0.00574656
Iteration 56, loss = 0.00554972
Iteration 57, loss = 0.00550439
Iteration 58, loss = 0.00550453
Iteration 59, loss = 0.00521266
Iteration 60, loss = 0.00523263
Iteration 61, loss = 0.00502084
Iteration 62, loss = 0.00501507
Iteration 63, loss = 0.00488100
Iteration 64, loss = 0.00478152
Iteration 65, loss = 0.00471096
Iteration 66, loss = 0.00473428
Iteration 67, loss = 0.00461338
Iteration 68, loss = 0.00450547
Iteration 69, loss = 0.00447416
Iteration 70, loss = 0.00442162
Iteration 71, loss = 0.00434256
Iteration 72, loss = 0.00429812
Iteration 73, loss = 0.00422387
Iteration 74, loss = 0.00419084
Iteration 75, loss = 0.00419509
Iteration 76, loss = 0.00404640
Iteration 77, loss = 0.00412928
Iteration 78, loss = 0.00401638
Iteration 79, loss = 0.00388666
Iteration 80, loss = 0.00394813
Iteration 81, loss = 0.00383316
Iteration 82, loss = 0.00377667
Iteration 83, loss = 0.00381982
Iteration 84, loss = 0.00378066
Iteration 85, loss = 0.00370111
Iteration 86, loss = 0.00366242
Iteration 87, loss = 0.00363839
Iteration 88, loss = 0.00366626
Iteration 89, loss = 0.00365382
Iteration 90, loss = 0.00364022
Iteration 91, loss = 0.00356955
Iteration 92, loss = 0.00353964
Iteration 93, loss = 0.00349672
Iteration 94, loss = 0.00343518
Iteration 95, loss = 0.00345852
Iteration 96, loss = 0.00342505
Iteration 97, loss = 0.00338427
Iteration 98, loss = 0.00335406
Iteration 99, loss = 0.00337246
Iteration 100, loss = 0.00340189
Iteration 101, loss = 0.00328209
Iteration 102, loss = 0.00325760
Iteration 103, loss = 0.00325538
Iteration 104, loss = 0.00338175
Iteration 105, loss = 0.00326648
Iteration 106, loss = 0.00323842
Iteration 107, loss = 0.00322504
Iteration 108, loss = 0.00325129
Iteration 109, loss = 0.00327362
Iteration 110, loss = 0.00316451
Iteration 111, loss = 0.00304240
Iteration 112, loss = 0.00318511
Iteration 113, loss = 0.00327624
Iteration 114, loss = 0.00308995
Iteration 115, loss = 0.00310049
Iteration 116, loss = 0.00306587
Iteration 117, loss = 0.00310793
Iteration 118, loss = 0.00304529
Iteration 119, loss = 0.00299736
Iteration 120, loss = 0.00306805
Iteration 121, loss = 0.00306450
Iteration 122, loss = 0.00301190
Iteration 123, loss = 0.00317671
Iteration 124, loss = 0.00298136
Iteration 125, loss = 0.00291880
Iteration 126, loss = 0.00293427
Iteration 127, loss = 0.00305672
Iteration 128, loss = 0.00306228
Iteration 129, loss = 0.00305148
Iteration 130, loss = 0.00296680
Iteration 131, loss = 0.00309760
Iteration 132, loss = 0.00297288
Iteration 133, loss = 0.00286544
Iteration 134, loss = 0.00297236
Iteration 135, loss = 0.00296867
Iteration 136, loss = 0.00294926
Iteration 137, loss = 0.00291165
Iteration 138, loss = 0.00294238
Iteration 139, loss = 0.00298193
Iteration 140, loss = 0.00281418
Iteration 141, loss = 0.00283387
Iteration 142, loss = 0.00296453
Iteration 143, loss = 0.00287668
Iteration 144, loss = 0.00283670
Iteration 145, loss = 0.00284580
Iteration 146, loss = 0.00305372
Iteration 147, loss = 0.00284845
Iteration 148, loss = 0.00276255
Iteration 149, loss = 0.00280069
Iteration 150, loss = 0.00277925
Iteration 151, loss = 0.00289353
Iteration 152, loss = 0.00293091
Iteration 153, loss = 0.00287007
Iteration 154, loss = 0.00273685
Iteration 155, loss = 0.00279423
Iteration 156, loss = 0.00288767
Iteration 157, loss = 0.00275342
Iteration 158, loss = 0.00281019
Iteration 159, loss = 0.00280370
Iteration 160, loss = 0.00279562
Iteration 161, loss = 0.00276586
Iteration 162, loss = 0.00281133
Iteration 163, loss = 0.00272628
Iteration 164, loss = 0.00284072
Iteration 165, loss = 0.00273809
Iteration 166, loss = 0.00275259
Iteration 167, loss = 0.00275801
Iteration 168, loss = 0.00284351
Iteration 169, loss = 0.00275975
Iteration 170, loss = 0.00281420
Iteration 171, loss = 0.00292280
Iteration 172, loss = 0.00265356
Iteration 173, loss = 0.00263127
Iteration 174, loss = 0.00270116
Iteration 175, loss = 0.00295459
Iteration 176, loss = 0.00281162
Iteration 177, loss = 0.00275068
Iteration 178, loss = 0.00264938
Iteration 179, loss = 0.00269614
Iteration 180, loss = 0.00271886
Iteration 181, loss = 0.00296575
Iteration 182, loss = 0.00264538
Iteration 183, loss = 0.00271495
Iteration 184, loss = 0.00268654
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.16579697
Iteration 2, loss = 0.07022857
Iteration 3, loss = 0.05963605
Iteration 4, loss = 0.05265203
Iteration 5, loss = 0.04607669
Iteration 6, loss = 0.04095288
Iteration 7, loss = 0.03703819
Iteration 8, loss = 0.03395737
Iteration 9, loss = 0.03161402
Iteration 10, loss = 0.02977248
Iteration 11, loss = 0.02815605
Iteration 12, loss = 0.02701444
Iteration 13, loss = 0.02573724
Iteration 14, loss = 0.02487056
Iteration 15, loss = 0.02403034
Iteration 16, loss = 0.02315508
Iteration 17, loss = 0.02237457
Iteration 18, loss = 0.02171442
Iteration 19, loss = 0.02108550
Iteration 20, loss = 0.02041383
Iteration 21, loss = 0.01994095
Iteration 22, loss = 0.01934813
Iteration 23, loss = 0.01884954
Iteration 24, loss = 0.01841027
Iteration 25, loss = 0.01792948
Iteration 26, loss = 0.01751426
Iteration 27, loss = 0.01717774
Iteration 28, loss = 0.01670646
Iteration 29, loss = 0.01628370
Iteration 30, loss = 0.01590118
Iteration 31, loss = 0.01557986
Iteration 32, loss = 0.01528291
Iteration 33, loss = 0.01490968
Iteration 34, loss = 0.01471022
Iteration 35, loss = 0.01428404
Iteration 36, loss = 0.01410146
Iteration 37, loss = 0.01387691
Iteration 38, loss = 0.01361822
Iteration 39, loss = 0.01337842
Iteration 40, loss = 0.01314707
Iteration 41, loss = 0.01285084
Iteration 42, loss = 0.01266916
Iteration 43, loss = 0.01241768
Iteration 44, loss = 0.01217169
Iteration 45, loss = 0.01206908
Iteration 46, loss = 0.01185177
Iteration 47, loss = 0.01166368
Iteration 48, loss = 0.01145278
Iteration 49, loss = 0.01129683
Iteration 50, loss = 0.01117557
Iteration 51, loss = 0.01097704
Iteration 52, loss = 0.01087226
Iteration 53, loss = 0.01068084
Iteration 54, loss = 0.01050387
Iteration 55, loss = 0.01044019
Iteration 56, loss = 0.01016508
Iteration 57, loss = 0.01018599
Iteration 58, loss = 0.00995203
Iteration 59, loss = 0.00989354
Iteration 60, loss = 0.00980466
Iteration 61, loss = 0.00962275
Iteration 62, loss = 0.00952427
Iteration 63, loss = 0.00939245
Iteration 64, loss = 0.00925904
Iteration 65, loss = 0.00916170
Iteration 66, loss = 0.00903261
Iteration 67, loss = 0.00905229
Iteration 68, loss = 0.00883565
Iteration 69, loss = 0.00879335
Iteration 70, loss = 0.00862737
Iteration 71, loss = 0.00866107
Iteration 72, loss = 0.00859428
Iteration 73, loss = 0.00838240
Iteration 74, loss = 0.00832538
Iteration 75, loss = 0.00825865
Iteration 76, loss = 0.00814300
Iteration 77, loss = 0.00816647
Iteration 78, loss = 0.00793552
Iteration 79, loss = 0.00797570
Iteration 80, loss = 0.00783927
Iteration 81, loss = 0.00776702
Iteration 82, loss = 0.00772115
Iteration 83, loss = 0.00766062
Iteration 84, loss = 0.00761331
Iteration 85, loss = 0.00747964
Iteration 86, loss = 0.00744247
Iteration 87, loss = 0.00737536
Iteration 88, loss = 0.00734231
Iteration 89, loss = 0.00715320
Iteration 90, loss = 0.00722567
Iteration 91, loss = 0.00717593
Iteration 92, loss = 0.00697474
Iteration 93, loss = 0.00696040
Iteration 94, loss = 0.00690539
Iteration 95, loss = 0.00682165
Iteration 96, loss = 0.00688523
Iteration 97, loss = 0.00680451
Iteration 98, loss = 0.00661621
Iteration 99, loss = 0.00670269
Iteration 100, loss = 0.00664457
Iteration 101, loss = 0.00645587
Iteration 102, loss = 0.00651985
Iteration 103, loss = 0.00641771
Iteration 104, loss = 0.00640077
Iteration 105, loss = 0.00636755
Iteration 106, loss = 0.00640019
Iteration 107, loss = 0.00627135
Iteration 108, loss = 0.00623245
Iteration 109, loss = 0.00616870
Iteration 110, loss = 0.00612071
Iteration 111, loss = 0.00604716
Iteration 112, loss = 0.00597941
Iteration 113, loss = 0.00608809
Iteration 114, loss = 0.00594955
Iteration 115, loss = 0.00590917
Iteration 116, loss = 0.00586970
Iteration 117, loss = 0.00587078
Iteration 118, loss = 0.00575713
Iteration 119, loss = 0.00572597
Iteration 120, loss = 0.00566743
Iteration 121, loss = 0.00568843
Iteration 122, loss = 0.00569891
Iteration 123, loss = 0.00563352
Iteration 124, loss = 0.00565326
Iteration 125, loss = 0.00553184
Iteration 126, loss = 0.00547790
Iteration 127, loss = 0.00546844
Iteration 128, loss = 0.00543271
Iteration 129, loss = 0.00539201
Iteration 130, loss = 0.00536718
Iteration 131, loss = 0.00533753
Iteration 132, loss = 0.00532691
Iteration 133, loss = 0.00536762
Iteration 134, loss = 0.00523838
Iteration 135, loss = 0.00520906
Iteration 136, loss = 0.00529604
Iteration 137, loss = 0.00512991
Iteration 138, loss = 0.00514343
Iteration 139, loss = 0.00512658
Iteration 140, loss = 0.00512870
Iteration 141, loss = 0.00509422
Iteration 142, loss = 0.00504545
Iteration 143, loss = 0.00498635
Iteration 144, loss = 0.00510548
Iteration 145, loss = 0.00497019
Iteration 146, loss = 0.00493319
Iteration 147, loss = 0.00492883
Iteration 148, loss = 0.00495820
Iteration 149, loss = 0.00492570
Iteration 150, loss = 0.00490179
Iteration 151, loss = 0.00481162
Iteration 152, loss = 0.00475002
Iteration 153, loss = 0.00485809
Iteration 154, loss = 0.00482857
Iteration 155, loss = 0.00472124
Iteration 156, loss = 0.00485669
Iteration 157, loss = 0.00473612
Iteration 158, loss = 0.00472275
Iteration 159, loss = 0.00475545
Iteration 160, loss = 0.00467434
Iteration 161, loss = 0.00467633
Iteration 162, loss = 0.00467366
Iteration 163, loss = 0.00468341
Iteration 164, loss = 0.00471152
Iteration 165, loss = 0.00465083
Iteration 166, loss = 0.00465880
Iteration 167, loss = 0.00454963
Iteration 168, loss = 0.00455095
Iteration 169, loss = 0.00457431
Iteration 170, loss = 0.00458183
Iteration 171, loss = 0.00447861
Iteration 172, loss = 0.00455883
Iteration 173, loss = 0.00457367
Iteration 174, loss = 0.00450850
Iteration 175, loss = 0.00437633
Iteration 176, loss = 0.00447370
Iteration 177, loss = 0.00447690
Iteration 178, loss = 0.00441041
Iteration 179, loss = 0.00443760
Iteration 180, loss = 0.00444302
Iteration 181, loss = 0.00450878
Iteration 182, loss = 0.00439345
Iteration 183, loss = 0.00438022
Iteration 184, loss = 0.00442516
Iteration 185, loss = 0.00432127
Iteration 186, loss = 0.00432918
Iteration 187, loss = 0.00427648
Iteration 188, loss = 0.00432425
Iteration 189, loss = 0.00432934
Iteration 190, loss = 0.00432156
Iteration 191, loss = 0.00436656
Iteration 192, loss = 0.00429815
Iteration 193, loss = 0.00428700
Iteration 194, loss = 0.00426317
Iteration 195, loss = 0.00425885
Iteration 196, loss = 0.00421055
Iteration 197, loss = 0.00427796
Iteration 198, loss = 0.00423051
Iteration 199, loss = 0.00424358
Iteration 200, loss = 0.00421980
Iteration 1, loss = 0.16876900
Iteration 2, loss = 0.07027609
Iteration 3, loss = 0.05963132
Iteration 4, loss = 0.05306259
Iteration 5, loss = 0.04727394
Iteration 6, loss = 0.04231655
Iteration 7, loss = 0.03859593
Iteration 8, loss = 0.03561290
Iteration 9, loss = 0.03317116
Iteration 10, loss = 0.03118551
Iteration 11, loss = 0.02953613
Iteration 12, loss = 0.02808499
Iteration 13, loss = 0.02670133
Iteration 14, loss = 0.02573625
Iteration 15, loss = 0.02466635
Iteration 16, loss = 0.02381433
Iteration 17, loss = 0.02307344
Iteration 18, loss = 0.02229841
Iteration 19, loss = 0.02156888
Iteration 20, loss = 0.02102685
Iteration 21, loss = 0.02034440
Iteration 22, loss = 0.01984020
Iteration 23, loss = 0.01940949
Iteration 24, loss = 0.01885026
Iteration 25, loss = 0.01841455
Iteration 26, loss = 0.01813210
Iteration 27, loss = 0.01763496
Iteration 28, loss = 0.01731256
Iteration 29, loss = 0.01691935
Iteration 30, loss = 0.01655074
Iteration 31, loss = 0.01628328
Iteration 32, loss = 0.01590988
Iteration 33, loss = 0.01571952
Iteration 34, loss = 0.01541688
Iteration 35, loss = 0.01503382
Iteration 36, loss = 0.01484968
Iteration 37, loss = 0.01453935
Iteration 38, loss = 0.01437524
Iteration 39, loss = 0.01400260
Iteration 40, loss = 0.01388432
Iteration 41, loss = 0.01368751
Iteration 42, loss = 0.01335647
Iteration 43, loss = 0.01312607
Iteration 44, loss = 0.01293221
Iteration 45, loss = 0.01270305
Iteration 46, loss = 0.01259503
Iteration 47, loss = 0.01232209
Iteration 48, loss = 0.01216042
Iteration 49, loss = 0.01199613
Iteration 50, loss = 0.01184031
Iteration 51, loss = 0.01163064
Iteration 52, loss = 0.01153667
Iteration 53, loss = 0.01137134
Iteration 54, loss = 0.01121846
Iteration 55, loss = 0.01104777
Iteration 56, loss = 0.01092514
Iteration 57, loss = 0.01077590
Iteration 58, loss = 0.01066946
Iteration 59, loss = 0.01051811
Iteration 60, loss = 0.01044551
Iteration 61, loss = 0.01020706
Iteration 62, loss = 0.01017116
Iteration 63, loss = 0.01000986
Iteration 64, loss = 0.00979589
Iteration 65, loss = 0.00976954
Iteration 66, loss = 0.00966181
Iteration 67, loss = 0.00950823
Iteration 68, loss = 0.00940111
Iteration 69, loss = 0.00940659
Iteration 70, loss = 0.00919923
Iteration 71, loss = 0.00915445
Iteration 72, loss = 0.00907090
Iteration 73, loss = 0.00886690
Iteration 74, loss = 0.00884906
Iteration 75, loss = 0.00872261
Iteration 76, loss = 0.00866037
Iteration 77, loss = 0.00849130
Iteration 78, loss = 0.00842936
Iteration 79, loss = 0.00840048
Iteration 80, loss = 0.00836755
Iteration 81, loss = 0.00816198
Iteration 82, loss = 0.00805472
Iteration 83, loss = 0.00809674
Iteration 84, loss = 0.00791859
Iteration 85, loss = 0.00791922
Iteration 86, loss = 0.00787591
Iteration 87, loss = 0.00781437
Iteration 88, loss = 0.00766920
Iteration 89, loss = 0.00761640
Iteration 90, loss = 0.00751247
Iteration 91, loss = 0.00746108
Iteration 92, loss = 0.00738725
Iteration 93, loss = 0.00734713
Iteration 94, loss = 0.00727782
Iteration 95, loss = 0.00719645
Iteration 96, loss = 0.00714291
Iteration 97, loss = 0.00713269
Iteration 98, loss = 0.00705624
Iteration 99, loss = 0.00693906
Iteration 100, loss = 0.00694568
Iteration 101, loss = 0.00683238
Iteration 102, loss = 0.00672910
Iteration 103, loss = 0.00668854
Iteration 104, loss = 0.00675319
Iteration 105, loss = 0.00665009
Iteration 106, loss = 0.00656542
Iteration 107, loss = 0.00652184
Iteration 108, loss = 0.00653793
Iteration 109, loss = 0.00642632
Iteration 110, loss = 0.00639503
Iteration 111, loss = 0.00638696
Iteration 112, loss = 0.00629384
Iteration 113, loss = 0.00624580
Iteration 114, loss = 0.00615885
Iteration 115, loss = 0.00618842
Iteration 116, loss = 0.00610162
Iteration 117, loss = 0.00608905
Iteration 118, loss = 0.00605171
Iteration 119, loss = 0.00604437
Iteration 120, loss = 0.00599968
Iteration 121, loss = 0.00592565
Iteration 122, loss = 0.00584471
Iteration 123, loss = 0.00592875
Iteration 124, loss = 0.00584287
Iteration 125, loss = 0.00582350
Iteration 126, loss = 0.00577215
Iteration 127, loss = 0.00567384
Iteration 128, loss = 0.00573790
Iteration 129, loss = 0.00563246
Iteration 130, loss = 0.00561857
Iteration 131, loss = 0.00551700
Iteration 132, loss = 0.00560307
Iteration 133, loss = 0.00555082
Iteration 134, loss = 0.00549179
Iteration 135, loss = 0.00552962
Iteration 136, loss = 0.00543269
Iteration 137, loss = 0.00546661
Iteration 138, loss = 0.00539105
Iteration 139, loss = 0.00538919
Iteration 140, loss = 0.00531242
Iteration 141, loss = 0.00527648
Iteration 142, loss = 0.00531945
Iteration 143, loss = 0.00518749
Iteration 144, loss = 0.00526959
Iteration 145, loss = 0.00526459
Iteration 146, loss = 0.00515984
Iteration 147, loss = 0.00515171
Iteration 148, loss = 0.00517191
Iteration 149, loss = 0.00515324
Iteration 150, loss = 0.00509921
Iteration 151, loss = 0.00511860
Iteration 152, loss = 0.00508744
Iteration 153, loss = 0.00506287
Iteration 154, loss = 0.00501960
Iteration 155, loss = 0.00494729
Iteration 156, loss = 0.00496985
Iteration 157, loss = 0.00495314
Iteration 158, loss = 0.00502373
Iteration 159, loss = 0.00493165
Iteration 160, loss = 0.00487337
Iteration 161, loss = 0.00488231
Iteration 162, loss = 0.00482781
Iteration 163, loss = 0.00486296
Iteration 164, loss = 0.00483072
Iteration 165, loss = 0.00479226
Iteration 166, loss = 0.00485289
Iteration 167, loss = 0.00479146
Iteration 168, loss = 0.00480820
Iteration 169, loss = 0.00471819
Iteration 170, loss = 0.00474800
Iteration 171, loss = 0.00468395
Iteration 172, loss = 0.00474037
Iteration 173, loss = 0.00472499
Iteration 174, loss = 0.00467101
Iteration 175, loss = 0.00465482
Iteration 176, loss = 0.00467649
Iteration 177, loss = 0.00460047
Iteration 178, loss = 0.00471415
Iteration 179, loss = 0.00463018
Iteration 180, loss = 0.00467603
Iteration 181, loss = 0.00457496
Iteration 182, loss = 0.00451802
Iteration 183, loss = 0.00461778
Iteration 184, loss = 0.00462432
Iteration 185, loss = 0.00456791
Iteration 186, loss = 0.00457814
Iteration 187, loss = 0.00456154
Iteration 188, loss = 0.00452127
Iteration 189, loss = 0.00450001
Iteration 190, loss = 0.00446793
Iteration 191, loss = 0.00449081
Iteration 192, loss = 0.00451336
Iteration 193, loss = 0.00443623
Iteration 194, loss = 0.00452897
Iteration 195, loss = 0.00445757
Iteration 196, loss = 0.00448705
Iteration 197, loss = 0.00441967
Iteration 198, loss = 0.00443005
Iteration 199, loss = 0.00436661
Iteration 200, loss = 0.00443237
Iteration 1, loss = 0.14419939
Iteration 2, loss = 0.06628464
Iteration 3, loss = 0.05717875
Iteration 4, loss = 0.05074266
Iteration 5, loss = 0.04504316
Iteration 6, loss = 0.04040382
Iteration 7, loss = 0.03681286
Iteration 8, loss = 0.03407008
Iteration 9, loss = 0.03185276
Iteration 10, loss = 0.03008012
Iteration 11, loss = 0.02839292
Iteration 12, loss = 0.02717240
Iteration 13, loss = 0.02597023
Iteration 14, loss = 0.02497030
Iteration 15, loss = 0.02401363
Iteration 16, loss = 0.02325812
Iteration 17, loss = 0.02249698
Iteration 18, loss = 0.02180769
Iteration 19, loss = 0.02113083
Iteration 20, loss = 0.02051365
Iteration 21, loss = 0.02011553
Iteration 22, loss = 0.01951521
Iteration 23, loss = 0.01908127
Iteration 24, loss = 0.01856790
Iteration 25, loss = 0.01806207
Iteration 26, loss = 0.01766261
Iteration 27, loss = 0.01728161
Iteration 28, loss = 0.01683721
Iteration 29, loss = 0.01664436
Iteration 30, loss = 0.01617985
Iteration 31, loss = 0.01596528
Iteration 32, loss = 0.01561038
Iteration 33, loss = 0.01522794
Iteration 34, loss = 0.01498349
Iteration 35, loss = 0.01472197
Iteration 36, loss = 0.01444455
Iteration 37, loss = 0.01414052
Iteration 38, loss = 0.01407405
Iteration 39, loss = 0.01374940
Iteration 40, loss = 0.01348420
Iteration 41, loss = 0.01332128
Iteration 42, loss = 0.01314837
Iteration 43, loss = 0.01293971
Iteration 44, loss = 0.01264339
Iteration 45, loss = 0.01257293
Iteration 46, loss = 0.01219931
Iteration 47, loss = 0.01214533
Iteration 48, loss = 0.01190847
Iteration 49, loss = 0.01184605
Iteration 50, loss = 0.01156417
Iteration 51, loss = 0.01153573
Iteration 52, loss = 0.01117733
Iteration 53, loss = 0.01113368
Iteration 54, loss = 0.01102126
Iteration 55, loss = 0.01081507
Iteration 56, loss = 0.01074821
Iteration 57, loss = 0.01058091
Iteration 58, loss = 0.01038229
Iteration 59, loss = 0.01031288
Iteration 60, loss = 0.01015923
Iteration 61, loss = 0.01018181
Iteration 62, loss = 0.00990729
Iteration 63, loss = 0.00979089
Iteration 64, loss = 0.00972364
Iteration 65, loss = 0.00953581
Iteration 66, loss = 0.00949524
Iteration 67, loss = 0.00945678
Iteration 68, loss = 0.00931538
Iteration 69, loss = 0.00912107
Iteration 70, loss = 0.00918388
Iteration 71, loss = 0.00898613
Iteration 72, loss = 0.00891746
Iteration 73, loss = 0.00869157
Iteration 74, loss = 0.00873119
Iteration 75, loss = 0.00857753
Iteration 76, loss = 0.00864087
Iteration 77, loss = 0.00845659
Iteration 78, loss = 0.00835338
Iteration 79, loss = 0.00839222
Iteration 80, loss = 0.00820410
Iteration 81, loss = 0.00816209
Iteration 82, loss = 0.00803821
Iteration 83, loss = 0.00792890
Iteration 84, loss = 0.00788445
Iteration 85, loss = 0.00781514
Iteration 86, loss = 0.00774472
Iteration 87, loss = 0.00766671
Iteration 88, loss = 0.00763626
Iteration 89, loss = 0.00756946
Iteration 90, loss = 0.00752850
Iteration 91, loss = 0.00741079
Iteration 92, loss = 0.00741046
Iteration 93, loss = 0.00731990
Iteration 94, loss = 0.00726332
Iteration 95, loss = 0.00712431
Iteration 96, loss = 0.00709667
Iteration 97, loss = 0.00703810
Iteration 98, loss = 0.00686180
Iteration 99, loss = 0.00697361
Iteration 100, loss = 0.00686157
Iteration 101, loss = 0.00689072
Iteration 102, loss = 0.00681473
Iteration 103, loss = 0.00671628
Iteration 104, loss = 0.00667651
Iteration 105, loss = 0.00654733
Iteration 106, loss = 0.00660344
Iteration 107, loss = 0.00648350
Iteration 108, loss = 0.00649444
Iteration 109, loss = 0.00640852
Iteration 110, loss = 0.00640061
Iteration 111, loss = 0.00642013
Iteration 112, loss = 0.00628710
Iteration 113, loss = 0.00626038
Iteration 114, loss = 0.00625371
Iteration 115, loss = 0.00622363
Iteration 116, loss = 0.00618181
Iteration 117, loss = 0.00612592
Iteration 118, loss = 0.00608387
Iteration 119, loss = 0.00600446
Iteration 120, loss = 0.00594793
Iteration 121, loss = 0.00593761
Iteration 122, loss = 0.00592465
Iteration 123, loss = 0.00599334
Iteration 124, loss = 0.00590349
Iteration 125, loss = 0.00583984
Iteration 126, loss = 0.00582060
Iteration 127, loss = 0.00578023
Iteration 128, loss = 0.00567975
Iteration 129, loss = 0.00565831
Iteration 130, loss = 0.00573048
Iteration 131, loss = 0.00562886
Iteration 132, loss = 0.00564288
Iteration 133, loss = 0.00567594
Iteration 134, loss = 0.00556095
Iteration 135, loss = 0.00553195
Iteration 136, loss = 0.00553334
Iteration 137, loss = 0.00550584
Iteration 138, loss = 0.00547879
Iteration 139, loss = 0.00536994
Iteration 140, loss = 0.00549386
Iteration 141, loss = 0.00536976
Iteration 142, loss = 0.00530934
Iteration 143, loss = 0.00536363
Iteration 144, loss = 0.00530983
Iteration 145, loss = 0.00541919
Iteration 146, loss = 0.00525597
Iteration 147, loss = 0.00526126
Iteration 148, loss = 0.00520929
Iteration 149, loss = 0.00519658
Iteration 150, loss = 0.00518087
Iteration 151, loss = 0.00514014
Iteration 152, loss = 0.00514724
Iteration 153, loss = 0.00512851
Iteration 154, loss = 0.00510267
Iteration 155, loss = 0.00501925
Iteration 156, loss = 0.00509257
Iteration 157, loss = 0.00498208
Iteration 158, loss = 0.00497095
Iteration 159, loss = 0.00505569
Iteration 160, loss = 0.00499920
Iteration 161, loss = 0.00500106
Iteration 162, loss = 0.00499865
Iteration 163, loss = 0.00491382
Iteration 164, loss = 0.00496659
Iteration 165, loss = 0.00489783
Iteration 166, loss = 0.00484651
Iteration 167, loss = 0.00489270
Iteration 168, loss = 0.00492488
Iteration 169, loss = 0.00493130
Iteration 170, loss = 0.00479503
Iteration 171, loss = 0.00490324
Iteration 172, loss = 0.00477413
Iteration 173, loss = 0.00479875
Iteration 174, loss = 0.00478853
Iteration 175, loss = 0.00472807
Iteration 176, loss = 0.00475711
Iteration 177, loss = 0.00470491
Iteration 178, loss = 0.00478802
Iteration 179, loss = 0.00463513
Iteration 180, loss = 0.00472228
Iteration 181, loss = 0.00463544
Iteration 182, loss = 0.00465758
Iteration 183, loss = 0.00464278
Iteration 184, loss = 0.00474567
Iteration 185, loss = 0.00461913
Iteration 186, loss = 0.00463131
Iteration 187, loss = 0.00466951
Iteration 188, loss = 0.00459475
Iteration 189, loss = 0.00456288
Iteration 190, loss = 0.00455817
Iteration 191, loss = 0.00459679
Iteration 192, loss = 0.00456794
Iteration 193, loss = 0.00448141
Iteration 194, loss = 0.00441475
Iteration 195, loss = 0.00446250
Iteration 196, loss = 0.00454598
Iteration 197, loss = 0.00449901
Iteration 198, loss = 0.00453325
Iteration 199, loss = 0.00459615
Iteration 200, loss = 0.00442487
Iteration 1, loss = 0.15309395
Iteration 2, loss = 0.06808910
Iteration 3, loss = 0.05799526
Iteration 4, loss = 0.05072436
Iteration 5, loss = 0.04427375
Iteration 6, loss = 0.03938192
Iteration 7, loss = 0.03570132
Iteration 8, loss = 0.03297344
Iteration 9, loss = 0.03075851
Iteration 10, loss = 0.02881888
Iteration 11, loss = 0.02730419
Iteration 12, loss = 0.02590039
Iteration 13, loss = 0.02458940
Iteration 14, loss = 0.02350707
Iteration 15, loss = 0.02269169
Iteration 16, loss = 0.02163271
Iteration 17, loss = 0.02090797
Iteration 18, loss = 0.02019514
Iteration 19, loss = 0.01945575
Iteration 20, loss = 0.01889969
Iteration 21, loss = 0.01817778
Iteration 22, loss = 0.01772005
Iteration 23, loss = 0.01697192
Iteration 24, loss = 0.01668751
Iteration 25, loss = 0.01612659
Iteration 26, loss = 0.01573067
Iteration 27, loss = 0.01522508
Iteration 28, loss = 0.01493233
Iteration 29, loss = 0.01458905
Iteration 30, loss = 0.01427975
Iteration 31, loss = 0.01398999
Iteration 32, loss = 0.01359258
Iteration 33, loss = 0.01324497
Iteration 34, loss = 0.01299476
Iteration 35, loss = 0.01277455
Iteration 36, loss = 0.01245775
Iteration 37, loss = 0.01216024
Iteration 38, loss = 0.01196962
Iteration 39, loss = 0.01170292
Iteration 40, loss = 0.01144509
Iteration 41, loss = 0.01108919
Iteration 42, loss = 0.01109443
Iteration 43, loss = 0.01085451
Iteration 44, loss = 0.01054639
Iteration 45, loss = 0.01041994
Iteration 46, loss = 0.01027161
Iteration 47, loss = 0.01006143
Iteration 48, loss = 0.00981897
Iteration 49, loss = 0.00981238
Iteration 50, loss = 0.00951614
Iteration 51, loss = 0.00932099
Iteration 52, loss = 0.00916673
Iteration 53, loss = 0.00907264
Iteration 54, loss = 0.00885085
Iteration 55, loss = 0.00888673
Iteration 56, loss = 0.00876483
Iteration 57, loss = 0.00849408
Iteration 58, loss = 0.00833911
Iteration 59, loss = 0.00826374
Iteration 60, loss = 0.00823598
Iteration 61, loss = 0.00809811
Iteration 62, loss = 0.00791192
Iteration 63, loss = 0.00777401
Iteration 64, loss = 0.00773006
Iteration 65, loss = 0.00762943
Iteration 66, loss = 0.00744778
Iteration 67, loss = 0.00745300
Iteration 68, loss = 0.00723647
Iteration 69, loss = 0.00718596
Iteration 70, loss = 0.00720724
Iteration 71, loss = 0.00703496
Iteration 72, loss = 0.00695061
Iteration 73, loss = 0.00683498
Iteration 74, loss = 0.00676972
Iteration 75, loss = 0.00669105
Iteration 76, loss = 0.00674169
Iteration 77, loss = 0.00654999
Iteration 78, loss = 0.00635240
Iteration 79, loss = 0.00641749
Iteration 80, loss = 0.00637627
Iteration 81, loss = 0.00623447
Iteration 82, loss = 0.00617487
Iteration 83, loss = 0.00622136
Iteration 84, loss = 0.00604812
Iteration 85, loss = 0.00599137
Iteration 86, loss = 0.00595672
Iteration 87, loss = 0.00592366
Iteration 88, loss = 0.00575776
Iteration 89, loss = 0.00579292
Iteration 90, loss = 0.00569556
Iteration 91, loss = 0.00564251
Iteration 92, loss = 0.00559181
Iteration 93, loss = 0.00561498
Iteration 94, loss = 0.00555641
Iteration 95, loss = 0.00547285
Iteration 96, loss = 0.00542444
Iteration 97, loss = 0.00541743
Iteration 98, loss = 0.00527850
Iteration 99, loss = 0.00520719
Iteration 100, loss = 0.00515617
Iteration 101, loss = 0.00518608
Iteration 102, loss = 0.00511714
Iteration 103, loss = 0.00514112
Iteration 104, loss = 0.00504966
Iteration 105, loss = 0.00499229
Iteration 106, loss = 0.00493095
Iteration 107, loss = 0.00492703
Iteration 108, loss = 0.00497257
Iteration 109, loss = 0.00489811
Iteration 110, loss = 0.00475287
Iteration 111, loss = 0.00482418
Iteration 112, loss = 0.00474843
Iteration 113, loss = 0.00476224
Iteration 114, loss = 0.00470625
Iteration 115, loss = 0.00472573
Iteration 116, loss = 0.00466002
Iteration 117, loss = 0.00461978
Iteration 118, loss = 0.00462628
Iteration 119, loss = 0.00456632
Iteration 120, loss = 0.00450402
Iteration 121, loss = 0.00448921
Iteration 122, loss = 0.00446974
Iteration 123, loss = 0.00451296
Iteration 124, loss = 0.00448556
Iteration 125, loss = 0.00442155
Iteration 126, loss = 0.00445555
Iteration 127, loss = 0.00434124
Iteration 128, loss = 0.00432131
Iteration 129, loss = 0.00437056
Iteration 130, loss = 0.00432951
Iteration 131, loss = 0.00425763
Iteration 132, loss = 0.00423916
Iteration 133, loss = 0.00429464
Iteration 134, loss = 0.00429652
Iteration 135, loss = 0.00420594
Iteration 136, loss = 0.00421931
Iteration 137, loss = 0.00416285
Iteration 138, loss = 0.00424077
Iteration 139, loss = 0.00416112
Iteration 140, loss = 0.00421370
Iteration 141, loss = 0.00410092
Iteration 142, loss = 0.00416064
Iteration 143, loss = 0.00424185
Iteration 144, loss = 0.00412572
Iteration 145, loss = 0.00412266
Iteration 146, loss = 0.00409100
Iteration 147, loss = 0.00410464
Iteration 148, loss = 0.00406438
Iteration 149, loss = 0.00403642
Iteration 150, loss = 0.00400314
Iteration 151, loss = 0.00400664
Iteration 152, loss = 0.00400064
Iteration 153, loss = 0.00407584
Iteration 154, loss = 0.00398170
Iteration 155, loss = 0.00406041
Iteration 156, loss = 0.00399081
Iteration 157, loss = 0.00400045
Iteration 158, loss = 0.00393426
Iteration 159, loss = 0.00392038
Iteration 160, loss = 0.00395214
Iteration 161, loss = 0.00395440
Iteration 162, loss = 0.00395260
Iteration 163, loss = 0.00393974
Iteration 164, loss = 0.00392502
Iteration 165, loss = 0.00387308
Iteration 166, loss = 0.00391809
Iteration 167, loss = 0.00386838
Iteration 168, loss = 0.00385721
Iteration 169, loss = 0.00394375
Iteration 170, loss = 0.00384327
Iteration 171, loss = 0.00387572
Iteration 172, loss = 0.00384638
Iteration 173, loss = 0.00389885
Iteration 174, loss = 0.00383761
Iteration 175, loss = 0.00390648
Iteration 176, loss = 0.00384601
Iteration 177, loss = 0.00381661
Iteration 178, loss = 0.00375449
Iteration 179, loss = 0.00381395
Iteration 180, loss = 0.00378150
Iteration 181, loss = 0.00382200
Iteration 182, loss = 0.00388281
Iteration 183, loss = 0.00381899
Iteration 184, loss = 0.00372548
Iteration 185, loss = 0.00378829
Iteration 186, loss = 0.00376020
Iteration 187, loss = 0.00383433
Iteration 188, loss = 0.00375420
Iteration 189, loss = 0.00373345
Iteration 190, loss = 0.00380220
Iteration 191, loss = 0.00374395
Iteration 192, loss = 0.00373315
Iteration 193, loss = 0.00367202
Iteration 194, loss = 0.00375903
Iteration 195, loss = 0.00373757
Iteration 196, loss = 0.00375620
Iteration 197, loss = 0.00370794
Iteration 198, loss = 0.00372371
Iteration 199, loss = 0.00371934
Iteration 200, loss = 0.00371424
Iteration 1, loss = 0.13976016
Iteration 2, loss = 0.06531484
Iteration 3, loss = 0.05486280
Iteration 4, loss = 0.04706731
Iteration 5, loss = 0.04115808
Iteration 6, loss = 0.03677670
Iteration 7, loss = 0.03358396
Iteration 8, loss = 0.03107615
Iteration 9, loss = 0.02917128
Iteration 10, loss = 0.02744331
Iteration 11, loss = 0.02597835
Iteration 12, loss = 0.02460700
Iteration 13, loss = 0.02352764
Iteration 14, loss = 0.02253946
Iteration 15, loss = 0.02158689
Iteration 16, loss = 0.02083070
Iteration 17, loss = 0.01990890
Iteration 18, loss = 0.01919078
Iteration 19, loss = 0.01862001
Iteration 20, loss = 0.01807553
Iteration 21, loss = 0.01742940
Iteration 22, loss = 0.01688422
Iteration 23, loss = 0.01634551
Iteration 24, loss = 0.01606888
Iteration 25, loss = 0.01546955
Iteration 26, loss = 0.01518672
Iteration 27, loss = 0.01476078
Iteration 28, loss = 0.01432490
Iteration 29, loss = 0.01413497
Iteration 30, loss = 0.01376270
Iteration 31, loss = 0.01345559
Iteration 32, loss = 0.01304695
Iteration 33, loss = 0.01279322
Iteration 34, loss = 0.01247319
Iteration 35, loss = 0.01236310
Iteration 36, loss = 0.01201563
Iteration 37, loss = 0.01176714
Iteration 38, loss = 0.01156775
Iteration 39, loss = 0.01135701
Iteration 40, loss = 0.01117981
Iteration 41, loss = 0.01079189
Iteration 42, loss = 0.01061528
Iteration 43, loss = 0.01058736
Iteration 44, loss = 0.01035684
Iteration 45, loss = 0.01018346
Iteration 46, loss = 0.00991445
Iteration 47, loss = 0.00986214
Iteration 48, loss = 0.00954103
Iteration 49, loss = 0.00937846
Iteration 50, loss = 0.00919784
Iteration 51, loss = 0.00907869
Iteration 52, loss = 0.00898976
Iteration 53, loss = 0.00880702
Iteration 54, loss = 0.00866106
Iteration 55, loss = 0.00865202
Iteration 56, loss = 0.00841615
Iteration 57, loss = 0.00836511
Iteration 58, loss = 0.00811024
Iteration 59, loss = 0.00796850
Iteration 60, loss = 0.00787169
Iteration 61, loss = 0.00787085
Iteration 62, loss = 0.00774152
Iteration 63, loss = 0.00761075
Iteration 64, loss = 0.00743295
Iteration 65, loss = 0.00740040
Iteration 66, loss = 0.00726747
Iteration 67, loss = 0.00718174
Iteration 68, loss = 0.00707081
Iteration 69, loss = 0.00708066
Iteration 70, loss = 0.00695494
Iteration 71, loss = 0.00677126
Iteration 72, loss = 0.00677648
Iteration 73, loss = 0.00665009
Iteration 74, loss = 0.00664399
Iteration 75, loss = 0.00650272
Iteration 76, loss = 0.00653260
Iteration 77, loss = 0.00638082
Iteration 78, loss = 0.00635505
Iteration 79, loss = 0.00615252
Iteration 80, loss = 0.00614389
Iteration 81, loss = 0.00607256
Iteration 82, loss = 0.00604205
Iteration 83, loss = 0.00600440
Iteration 84, loss = 0.00588779
Iteration 85, loss = 0.00596774
Iteration 86, loss = 0.00578863
Iteration 87, loss = 0.00578062
Iteration 88, loss = 0.00568631
Iteration 89, loss = 0.00568362
Iteration 90, loss = 0.00554451
Iteration 91, loss = 0.00561006
Iteration 92, loss = 0.00555076
Iteration 93, loss = 0.00538648
Iteration 94, loss = 0.00538706
Iteration 95, loss = 0.00540865
Iteration 96, loss = 0.00543488
Iteration 97, loss = 0.00540844
Iteration 98, loss = 0.00522713
Iteration 99, loss = 0.00517450
Iteration 100, loss = 0.00523208
Iteration 101, loss = 0.00516657
Iteration 102, loss = 0.00515382
Iteration 103, loss = 0.00514127
Iteration 104, loss = 0.00497791
Iteration 105, loss = 0.00495739
Iteration 106, loss = 0.00505774
Iteration 107, loss = 0.00497244
Iteration 108, loss = 0.00490258
Iteration 109, loss = 0.00491006
Iteration 110, loss = 0.00491329
Iteration 111, loss = 0.00481011
Iteration 112, loss = 0.00469078
Iteration 113, loss = 0.00476395
Iteration 114, loss = 0.00482851
Iteration 115, loss = 0.00478532
Iteration 116, loss = 0.00463966
Iteration 117, loss = 0.00470738
Iteration 118, loss = 0.00465238
Iteration 119, loss = 0.00466468
Iteration 120, loss = 0.00456039
Iteration 121, loss = 0.00454479
Iteration 122, loss = 0.00458786
Iteration 123, loss = 0.00453509
Iteration 124, loss = 0.00453964
Iteration 125, loss = 0.00449288
Iteration 126, loss = 0.00446115
Iteration 127, loss = 0.00445025
Iteration 128, loss = 0.00448362
Iteration 129, loss = 0.00442148
Iteration 130, loss = 0.00442623
Iteration 131, loss = 0.00441483
Iteration 132, loss = 0.00438765
Iteration 133, loss = 0.00443269
Iteration 134, loss = 0.00435230
Iteration 135, loss = 0.00428216
Iteration 136, loss = 0.00437294
Iteration 137, loss = 0.00426242
Iteration 138, loss = 0.00426589
Iteration 139, loss = 0.00432608
Iteration 140, loss = 0.00430284
Iteration 141, loss = 0.00426517
Iteration 142, loss = 0.00423291
Iteration 143, loss = 0.00417975
Iteration 144, loss = 0.00422511
Iteration 145, loss = 0.00421755
Iteration 146, loss = 0.00416584
Iteration 147, loss = 0.00417230
Iteration 148, loss = 0.00418656
Iteration 149, loss = 0.00412210
Iteration 150, loss = 0.00417828
Iteration 151, loss = 0.00410129
Iteration 152, loss = 0.00405707
Iteration 153, loss = 0.00411581
Iteration 154, loss = 0.00407799
Iteration 155, loss = 0.00406240
Iteration 156, loss = 0.00402735
Iteration 157, loss = 0.00410322
Iteration 158, loss = 0.00404140
Iteration 159, loss = 0.00401880
Iteration 160, loss = 0.00404622
Iteration 161, loss = 0.00401016
Iteration 162, loss = 0.00401824
Iteration 163, loss = 0.00408280
Iteration 164, loss = 0.00395535
Iteration 165, loss = 0.00399252
Iteration 166, loss = 0.00395647
Iteration 167, loss = 0.00403194
Iteration 168, loss = 0.00399724
Iteration 169, loss = 0.00394937
Iteration 170, loss = 0.00398762
Iteration 171, loss = 0.00396001
Iteration 172, loss = 0.00385887
Iteration 173, loss = 0.00392266
Iteration 174, loss = 0.00400283
Iteration 175, loss = 0.00395612
Iteration 176, loss = 0.00386720
Iteration 177, loss = 0.00385659
Iteration 178, loss = 0.00388772
Iteration 179, loss = 0.00397561
Iteration 180, loss = 0.00388762
Iteration 181, loss = 0.00388671
Iteration 182, loss = 0.00392952
Iteration 183, loss = 0.00388355
Iteration 184, loss = 0.00388397
Iteration 185, loss = 0.00386825
Iteration 186, loss = 0.00382712
Iteration 187, loss = 0.00383204
Iteration 188, loss = 0.00389029
Iteration 189, loss = 0.00380403
Iteration 190, loss = 0.00381135
Iteration 191, loss = 0.00388242
Iteration 192, loss = 0.00378124
Iteration 193, loss = 0.00375937
Iteration 194, loss = 0.00378663
Iteration 195, loss = 0.00390782
Iteration 196, loss = 0.00376453
Iteration 197, loss = 0.00382028
Iteration 198, loss = 0.00379274
Iteration 199, loss = 0.00385037
Iteration 200, loss = 0.00370499
Iteration 1, loss = 0.14977445
Iteration 2, loss = 0.06465033
Iteration 3, loss = 0.05465336
Iteration 4, loss = 0.04755764
Iteration 5, loss = 0.04196733
Iteration 6, loss = 0.03754986
Iteration 7, loss = 0.03413122
Iteration 8, loss = 0.03130012
Iteration 9, loss = 0.02913947
Iteration 10, loss = 0.02731119
Iteration 11, loss = 0.02566668
Iteration 12, loss = 0.02445395
Iteration 13, loss = 0.02335032
Iteration 14, loss = 0.02250559
Iteration 15, loss = 0.02152355
Iteration 16, loss = 0.02064630
Iteration 17, loss = 0.01994879
Iteration 18, loss = 0.01923755
Iteration 19, loss = 0.01878828
Iteration 20, loss = 0.01815770
Iteration 21, loss = 0.01755582
Iteration 22, loss = 0.01716101
Iteration 23, loss = 0.01666581
Iteration 24, loss = 0.01618721
Iteration 25, loss = 0.01588139
Iteration 26, loss = 0.01543830
Iteration 27, loss = 0.01514685
Iteration 28, loss = 0.01472312
Iteration 29, loss = 0.01433250
Iteration 30, loss = 0.01411309
Iteration 31, loss = 0.01382408
Iteration 32, loss = 0.01347451
Iteration 33, loss = 0.01323826
Iteration 34, loss = 0.01284648
Iteration 35, loss = 0.01271613
Iteration 36, loss = 0.01248208
Iteration 37, loss = 0.01219918
Iteration 38, loss = 0.01207397
Iteration 39, loss = 0.01173000
Iteration 40, loss = 0.01151950
Iteration 41, loss = 0.01133503
Iteration 42, loss = 0.01115015
Iteration 43, loss = 0.01096132
Iteration 44, loss = 0.01082124
Iteration 45, loss = 0.01062578
Iteration 46, loss = 0.01038291
Iteration 47, loss = 0.01026366
Iteration 48, loss = 0.01013453
Iteration 49, loss = 0.00995305
Iteration 50, loss = 0.00975612
Iteration 51, loss = 0.00959989
Iteration 52, loss = 0.00950867
Iteration 53, loss = 0.00942996
Iteration 54, loss = 0.00917464
Iteration 55, loss = 0.00912546
Iteration 56, loss = 0.00897345
Iteration 57, loss = 0.00876346
Iteration 58, loss = 0.00866459
Iteration 59, loss = 0.00856555
Iteration 60, loss = 0.00835762
Iteration 61, loss = 0.00834392
Iteration 62, loss = 0.00818458
Iteration 63, loss = 0.00805819
Iteration 64, loss = 0.00793596
Iteration 65, loss = 0.00788465
Iteration 66, loss = 0.00777839
Iteration 67, loss = 0.00771680
Iteration 68, loss = 0.00747819
Iteration 69, loss = 0.00747654
Iteration 70, loss = 0.00734353
Iteration 71, loss = 0.00738103
Iteration 72, loss = 0.00718906
Iteration 73, loss = 0.00713787
Iteration 74, loss = 0.00708450
Iteration 75, loss = 0.00694939
Iteration 76, loss = 0.00685997
Iteration 77, loss = 0.00675146
Iteration 78, loss = 0.00679699
Iteration 79, loss = 0.00670744
Iteration 80, loss = 0.00664058
Iteration 81, loss = 0.00650540
Iteration 82, loss = 0.00642679
Iteration 83, loss = 0.00638163
Iteration 84, loss = 0.00624358
Iteration 85, loss = 0.00627167
Iteration 86, loss = 0.00620198
Iteration 87, loss = 0.00623290
Iteration 88, loss = 0.00614681
Iteration 89, loss = 0.00605734
Iteration 90, loss = 0.00592456
Iteration 91, loss = 0.00592920
Iteration 92, loss = 0.00592341
Iteration 93, loss = 0.00578647
Iteration 94, loss = 0.00574231
Iteration 95, loss = 0.00569078
Iteration 96, loss = 0.00572813
Iteration 97, loss = 0.00563777
Iteration 98, loss = 0.00557961
Iteration 99, loss = 0.00552923
Iteration 100, loss = 0.00551412
Iteration 101, loss = 0.00544439
Iteration 102, loss = 0.00544934
Iteration 103, loss = 0.00538815
Iteration 104, loss = 0.00531042
Iteration 105, loss = 0.00527979
Iteration 106, loss = 0.00526154
Iteration 107, loss = 0.00522060
Iteration 108, loss = 0.00528145
Iteration 109, loss = 0.00516632
Iteration 110, loss = 0.00509260
Iteration 111, loss = 0.00518279
Iteration 112, loss = 0.00503393
Iteration 113, loss = 0.00503071
Iteration 114, loss = 0.00504532
Iteration 115, loss = 0.00498304
Iteration 116, loss = 0.00488688
Iteration 117, loss = 0.00481815
Iteration 118, loss = 0.00490773
Iteration 119, loss = 0.00483778
Iteration 120, loss = 0.00478230
Iteration 121, loss = 0.00486111
Iteration 122, loss = 0.00481163
Iteration 123, loss = 0.00486449
Iteration 124, loss = 0.00477754
Iteration 125, loss = 0.00467056
Iteration 126, loss = 0.00460466
Iteration 127, loss = 0.00459812
Iteration 128, loss = 0.00459920
Iteration 129, loss = 0.00461105
Iteration 130, loss = 0.00463804
Iteration 131, loss = 0.00464553
Iteration 132, loss = 0.00454993
Iteration 133, loss = 0.00447963
Iteration 134, loss = 0.00450294
Iteration 135, loss = 0.00453142
Iteration 136, loss = 0.00446511
Iteration 137, loss = 0.00441670
Iteration 138, loss = 0.00445521
Iteration 139, loss = 0.00451271
Iteration 140, loss = 0.00435296
Iteration 141, loss = 0.00435623
Iteration 142, loss = 0.00438212
Iteration 143, loss = 0.00435470
Iteration 144, loss = 0.00439649
Iteration 145, loss = 0.00434972
Iteration 146, loss = 0.00432523
Iteration 147, loss = 0.00427118
Iteration 148, loss = 0.00427189
Iteration 149, loss = 0.00425357
Iteration 150, loss = 0.00424896
Iteration 151, loss = 0.00421490
Iteration 152, loss = 0.00432830
Iteration 153, loss = 0.00421530
Iteration 154, loss = 0.00413168
Iteration 155, loss = 0.00415857
Iteration 156, loss = 0.00419657
Iteration 157, loss = 0.00421734
Iteration 158, loss = 0.00413935
Iteration 159, loss = 0.00408524
Iteration 160, loss = 0.00420561
Iteration 161, loss = 0.00408457
Iteration 162, loss = 0.00411331
Iteration 163, loss = 0.00410452
Iteration 164, loss = 0.00414071
Iteration 165, loss = 0.00407470
Iteration 166, loss = 0.00409429
Iteration 167, loss = 0.00409029
Iteration 168, loss = 0.00408774
Iteration 169, loss = 0.00402514
Iteration 170, loss = 0.00402324
Iteration 171, loss = 0.00403342
Iteration 172, loss = 0.00408049
Iteration 173, loss = 0.00398056
Iteration 174, loss = 0.00402405
Iteration 175, loss = 0.00398979
Iteration 176, loss = 0.00399358
Iteration 177, loss = 0.00403656
Iteration 178, loss = 0.00397032
Iteration 179, loss = 0.00392772
Iteration 180, loss = 0.00399011
Iteration 181, loss = 0.00396772
Iteration 182, loss = 0.00394587
Iteration 183, loss = 0.00403970
Iteration 184, loss = 0.00394047
Iteration 185, loss = 0.00391261
Iteration 186, loss = 0.00396874
Iteration 187, loss = 0.00387466
Iteration 188, loss = 0.00390693
Iteration 189, loss = 0.00389848
Iteration 190, loss = 0.00393399
Iteration 191, loss = 0.00393696
Iteration 192, loss = 0.00387677
Iteration 193, loss = 0.00390979
Iteration 194, loss = 0.00383751
Iteration 195, loss = 0.00381814
Iteration 196, loss = 0.00393226
Iteration 197, loss = 0.00386117
Iteration 198, loss = 0.00384479
Iteration 199, loss = 0.00390128
Iteration 200, loss = 0.00385560
Iteration 1, loss = 0.15505947
Iteration 2, loss = 0.06487635
Iteration 3, loss = 0.05468808
Iteration 4, loss = 0.04756910
Iteration 5, loss = 0.04175086
Iteration 6, loss = 0.03703669
Iteration 7, loss = 0.03340083
Iteration 8, loss = 0.03052614
Iteration 9, loss = 0.02840119
Iteration 10, loss = 0.02666597
Iteration 11, loss = 0.02517842
Iteration 12, loss = 0.02376171
Iteration 13, loss = 0.02263199
Iteration 14, loss = 0.02160898
Iteration 15, loss = 0.02075188
Iteration 16, loss = 0.01981241
Iteration 17, loss = 0.01894252
Iteration 18, loss = 0.01832563
Iteration 19, loss = 0.01767853
Iteration 20, loss = 0.01703236
Iteration 21, loss = 0.01649006
Iteration 22, loss = 0.01593725
Iteration 23, loss = 0.01540469
Iteration 24, loss = 0.01504565
Iteration 25, loss = 0.01443939
Iteration 26, loss = 0.01409283
Iteration 27, loss = 0.01362349
Iteration 28, loss = 0.01328255
Iteration 29, loss = 0.01293586
Iteration 30, loss = 0.01248443
Iteration 31, loss = 0.01229577
Iteration 32, loss = 0.01190635
Iteration 33, loss = 0.01164959
Iteration 34, loss = 0.01134032
Iteration 35, loss = 0.01109055
Iteration 36, loss = 0.01072966
Iteration 37, loss = 0.01055089
Iteration 38, loss = 0.01027308
Iteration 39, loss = 0.01012783
Iteration 40, loss = 0.00981937
Iteration 41, loss = 0.00958705
Iteration 42, loss = 0.00933669
Iteration 43, loss = 0.00921193
Iteration 44, loss = 0.00894119
Iteration 45, loss = 0.00882306
Iteration 46, loss = 0.00852831
Iteration 47, loss = 0.00855631
Iteration 48, loss = 0.00828866
Iteration 49, loss = 0.00822375
Iteration 50, loss = 0.00806550
Iteration 51, loss = 0.00779999
Iteration 52, loss = 0.00769928
Iteration 53, loss = 0.00755531
Iteration 54, loss = 0.00741079
Iteration 55, loss = 0.00729773
Iteration 56, loss = 0.00721477
Iteration 57, loss = 0.00703531
Iteration 58, loss = 0.00700705
Iteration 59, loss = 0.00681687
Iteration 60, loss = 0.00675391
Iteration 61, loss = 0.00665737
Iteration 62, loss = 0.00659100
Iteration 63, loss = 0.00642461
Iteration 64, loss = 0.00633834
Iteration 65, loss = 0.00622612
Iteration 66, loss = 0.00610357
Iteration 67, loss = 0.00604283
Iteration 68, loss = 0.00611411
Iteration 69, loss = 0.00592873
Iteration 70, loss = 0.00592134
Iteration 71, loss = 0.00581932
Iteration 72, loss = 0.00578654
Iteration 73, loss = 0.00559019
Iteration 74, loss = 0.00559636
Iteration 75, loss = 0.00554898
Iteration 76, loss = 0.00544898
Iteration 77, loss = 0.00542515
Iteration 78, loss = 0.00543704
Iteration 79, loss = 0.00532082
Iteration 80, loss = 0.00524522
Iteration 81, loss = 0.00513914
Iteration 82, loss = 0.00522083
Iteration 83, loss = 0.00504233
Iteration 84, loss = 0.00509706
Iteration 85, loss = 0.00506504
Iteration 86, loss = 0.00496734
Iteration 87, loss = 0.00495675
Iteration 88, loss = 0.00484595
Iteration 89, loss = 0.00496076
Iteration 90, loss = 0.00479590
Iteration 91, loss = 0.00477334
Iteration 92, loss = 0.00475511
Iteration 93, loss = 0.00470078
Iteration 94, loss = 0.00471095
Iteration 95, loss = 0.00462176
Iteration 96, loss = 0.00460721
Iteration 97, loss = 0.00464538
Iteration 98, loss = 0.00454839
Iteration 99, loss = 0.00451620
Iteration 100, loss = 0.00450927
Iteration 101, loss = 0.00453078
Iteration 102, loss = 0.00445887
Iteration 103, loss = 0.00436009
Iteration 104, loss = 0.00445773
Iteration 105, loss = 0.00436659
Iteration 106, loss = 0.00436680
Iteration 107, loss = 0.00439502
Iteration 108, loss = 0.00429754
Iteration 109, loss = 0.00419664
Iteration 110, loss = 0.00421110
Iteration 111, loss = 0.00430870
Iteration 112, loss = 0.00424307
Iteration 113, loss = 0.00422780
Iteration 114, loss = 0.00422507
Iteration 115, loss = 0.00413882
Iteration 116, loss = 0.00416157
Iteration 117, loss = 0.00423446
Iteration 118, loss = 0.00405849
Iteration 119, loss = 0.00416711
Iteration 120, loss = 0.00408697
Iteration 121, loss = 0.00407377
Iteration 122, loss = 0.00407906
Iteration 123, loss = 0.00405009
Iteration 124, loss = 0.00407218
Iteration 125, loss = 0.00406472
Iteration 126, loss = 0.00400234
Iteration 127, loss = 0.00401664
Iteration 128, loss = 0.00400825
Iteration 129, loss = 0.00397144
Iteration 130, loss = 0.00393434
Iteration 131, loss = 0.00391316
Iteration 132, loss = 0.00393321
Iteration 133, loss = 0.00393632
Iteration 134, loss = 0.00402650
Iteration 135, loss = 0.00387218
Iteration 136, loss = 0.00397439
Iteration 137, loss = 0.00388124
Iteration 138, loss = 0.00385482
Iteration 139, loss = 0.00391921
Iteration 140, loss = 0.00384153
Iteration 141, loss = 0.00386624
Iteration 142, loss = 0.00382759
Iteration 143, loss = 0.00383469
Iteration 144, loss = 0.00382610
Iteration 145, loss = 0.00378391
Iteration 146, loss = 0.00386274
Iteration 147, loss = 0.00382404
Iteration 148, loss = 0.00383997
Iteration 149, loss = 0.00396237
Iteration 150, loss = 0.00376520
Iteration 151, loss = 0.00370387
Iteration 152, loss = 0.00375501
Iteration 153, loss = 0.00374978
Iteration 154, loss = 0.00380206
Iteration 155, loss = 0.00377715
Iteration 156, loss = 0.00376125
Iteration 157, loss = 0.00370275
Iteration 158, loss = 0.00371960
Iteration 159, loss = 0.00373193
Iteration 160, loss = 0.00377294
Iteration 161, loss = 0.00379209
Iteration 162, loss = 0.00367737
Iteration 163, loss = 0.00364499
Iteration 164, loss = 0.00379401
Iteration 165, loss = 0.00366409
Iteration 166, loss = 0.00363591
Iteration 167, loss = 0.00369230
Iteration 168, loss = 0.00365307
Iteration 169, loss = 0.00362539
Iteration 170, loss = 0.00364022
Iteration 171, loss = 0.00367032
Iteration 172, loss = 0.00361862
Iteration 173, loss = 0.00371630
Iteration 174, loss = 0.00358285
Iteration 175, loss = 0.00368662
Iteration 176, loss = 0.00363847
Iteration 177, loss = 0.00360392
Iteration 178, loss = 0.00358852
Iteration 179, loss = 0.00364896
Iteration 180, loss = 0.00360375
Iteration 181, loss = 0.00356372
Iteration 182, loss = 0.00360378
Iteration 183, loss = 0.00375613
Iteration 184, loss = 0.00356794
Iteration 185, loss = 0.00359833
Iteration 186, loss = 0.00359647
Iteration 187, loss = 0.00357191
Iteration 188, loss = 0.00350324
Iteration 189, loss = 0.00354016
Iteration 190, loss = 0.00359435
Iteration 191, loss = 0.00372774
Iteration 192, loss = 0.00353120
Iteration 193, loss = 0.00354417
Iteration 194, loss = 0.00369189
Iteration 195, loss = 0.00357775
Iteration 196, loss = 0.00351496
Iteration 197, loss = 0.00352579
Iteration 198, loss = 0.00349527
Iteration 199, loss = 0.00361611
Iteration 200, loss = 0.00352740
Iteration 1, loss = 0.13759443
Iteration 2, loss = 0.06315517
Iteration 3, loss = 0.05347545
Iteration 4, loss = 0.04529546
Iteration 5, loss = 0.03906233
Iteration 6, loss = 0.03466573
Iteration 7, loss = 0.03140008
Iteration 8, loss = 0.02883934
Iteration 9, loss = 0.02681326
Iteration 10, loss = 0.02525648
Iteration 11, loss = 0.02376449
Iteration 12, loss = 0.02248186
Iteration 13, loss = 0.02149868
Iteration 14, loss = 0.02048764
Iteration 15, loss = 0.01954331
Iteration 16, loss = 0.01874145
Iteration 17, loss = 0.01813684
Iteration 18, loss = 0.01745670
Iteration 19, loss = 0.01681592
Iteration 20, loss = 0.01624562
Iteration 21, loss = 0.01567572
Iteration 22, loss = 0.01520087
Iteration 23, loss = 0.01464262
Iteration 24, loss = 0.01429837
Iteration 25, loss = 0.01381276
Iteration 26, loss = 0.01346634
Iteration 27, loss = 0.01290491
Iteration 28, loss = 0.01263265
Iteration 29, loss = 0.01228921
Iteration 30, loss = 0.01193854
Iteration 31, loss = 0.01162411
Iteration 32, loss = 0.01144505
Iteration 33, loss = 0.01120347
Iteration 34, loss = 0.01067481
Iteration 35, loss = 0.01054061
Iteration 36, loss = 0.01027790
Iteration 37, loss = 0.00995452
Iteration 38, loss = 0.00976844
Iteration 39, loss = 0.00957100
Iteration 40, loss = 0.00935349
Iteration 41, loss = 0.00913718
Iteration 42, loss = 0.00901815
Iteration 43, loss = 0.00873534
Iteration 44, loss = 0.00858654
Iteration 45, loss = 0.00845748
Iteration 46, loss = 0.00827433
Iteration 47, loss = 0.00801349
Iteration 48, loss = 0.00803284
Iteration 49, loss = 0.00771128
Iteration 50, loss = 0.00762752
Iteration 51, loss = 0.00754643
Iteration 52, loss = 0.00740214
Iteration 53, loss = 0.00718482
Iteration 54, loss = 0.00714062
Iteration 55, loss = 0.00698623
Iteration 56, loss = 0.00689588
Iteration 57, loss = 0.00676602
Iteration 58, loss = 0.00665661
Iteration 59, loss = 0.00651563
Iteration 60, loss = 0.00648541
Iteration 61, loss = 0.00630262
Iteration 62, loss = 0.00629617
Iteration 63, loss = 0.00620326
Iteration 64, loss = 0.00610118
Iteration 65, loss = 0.00591101
Iteration 66, loss = 0.00589178
Iteration 67, loss = 0.00579082
Iteration 68, loss = 0.00580743
Iteration 69, loss = 0.00562297
Iteration 70, loss = 0.00559376
Iteration 71, loss = 0.00552995
Iteration 72, loss = 0.00545917
Iteration 73, loss = 0.00542398
Iteration 74, loss = 0.00535699
Iteration 75, loss = 0.00522511
Iteration 76, loss = 0.00524223
Iteration 77, loss = 0.00507284
Iteration 78, loss = 0.00511852
Iteration 79, loss = 0.00511686
Iteration 80, loss = 0.00497628
Iteration 81, loss = 0.00497317
Iteration 82, loss = 0.00489161
Iteration 83, loss = 0.00486397
Iteration 84, loss = 0.00488033
Iteration 85, loss = 0.00481524
Iteration 86, loss = 0.00470004
Iteration 87, loss = 0.00464711
Iteration 88, loss = 0.00462800
Iteration 89, loss = 0.00473073
Iteration 90, loss = 0.00462416
Iteration 91, loss = 0.00463451
Iteration 92, loss = 0.00446841
Iteration 93, loss = 0.00447881
Iteration 94, loss = 0.00450261
Iteration 95, loss = 0.00440670
Iteration 96, loss = 0.00443345
Iteration 97, loss = 0.00432303
Iteration 98, loss = 0.00437823
Iteration 99, loss = 0.00434575
Iteration 100, loss = 0.00433235
Iteration 101, loss = 0.00429586
Iteration 102, loss = 0.00435336
Iteration 103, loss = 0.00419793
Iteration 104, loss = 0.00420482
Iteration 105, loss = 0.00417436
Iteration 106, loss = 0.00414772
Iteration 107, loss = 0.00413503
Iteration 108, loss = 0.00416563
Iteration 109, loss = 0.00425376
Iteration 110, loss = 0.00409217
Iteration 111, loss = 0.00398690
Iteration 112, loss = 0.00402426
Iteration 113, loss = 0.00402786
Iteration 114, loss = 0.00403902
Iteration 115, loss = 0.00398200
Iteration 116, loss = 0.00400516
Iteration 117, loss = 0.00398971
Iteration 118, loss = 0.00404058
Iteration 119, loss = 0.00393965
Iteration 120, loss = 0.00397985
Iteration 121, loss = 0.00391246
Iteration 122, loss = 0.00394694
Iteration 123, loss = 0.00386220
Iteration 124, loss = 0.00390195
Iteration 125, loss = 0.00390059
Iteration 126, loss = 0.00393010
Iteration 127, loss = 0.00384783
Iteration 128, loss = 0.00384577
Iteration 129, loss = 0.00383623
Iteration 130, loss = 0.00387443
Iteration 131, loss = 0.00381039
Iteration 132, loss = 0.00383311
Iteration 133, loss = 0.00381820
Iteration 134, loss = 0.00373569
Iteration 135, loss = 0.00380103
Iteration 136, loss = 0.00382290
Iteration 137, loss = 0.00372900
Iteration 138, loss = 0.00371681
Iteration 139, loss = 0.00379268
Iteration 140, loss = 0.00373307
Iteration 141, loss = 0.00380275
Iteration 142, loss = 0.00370454
Iteration 143, loss = 0.00374697
Iteration 144, loss = 0.00376242
Iteration 145, loss = 0.00374119
Iteration 146, loss = 0.00370842
Iteration 147, loss = 0.00363975
Iteration 148, loss = 0.00365131
Iteration 149, loss = 0.00371470
Iteration 150, loss = 0.00368097
Iteration 151, loss = 0.00363282
Iteration 152, loss = 0.00365974
Iteration 153, loss = 0.00359501
Iteration 154, loss = 0.00377844
Iteration 155, loss = 0.00360103
Iteration 156, loss = 0.00371348
Iteration 157, loss = 0.00362162
Iteration 158, loss = 0.00364640
Iteration 159, loss = 0.00365440
Iteration 160, loss = 0.00357395
Iteration 161, loss = 0.00355385
Iteration 162, loss = 0.00356092
Iteration 163, loss = 0.00365969
Iteration 164, loss = 0.00360693
Iteration 165, loss = 0.00368668
Iteration 166, loss = 0.00355667
Iteration 167, loss = 0.00357551
Iteration 168, loss = 0.00362859
Iteration 169, loss = 0.00354444
Iteration 170, loss = 0.00354119
Iteration 171, loss = 0.00352558
Iteration 172, loss = 0.00354516
Iteration 173, loss = 0.00354448
Iteration 174, loss = 0.00363790
Iteration 175, loss = 0.00353584
Iteration 176, loss = 0.00360117
Iteration 177, loss = 0.00354758
Iteration 178, loss = 0.00353317
Iteration 179, loss = 0.00346381
Iteration 180, loss = 0.00349636
Iteration 181, loss = 0.00354209
Iteration 182, loss = 0.00359185
Iteration 183, loss = 0.00354094
Iteration 184, loss = 0.00352339
Iteration 185, loss = 0.00345748
Iteration 186, loss = 0.00351330
Iteration 187, loss = 0.00351762
Iteration 188, loss = 0.00349764
Iteration 189, loss = 0.00350253
Iteration 190, loss = 0.00347413
Iteration 191, loss = 0.00353814
Iteration 192, loss = 0.00345519
Iteration 193, loss = 0.00349695
Iteration 194, loss = 0.00346632
Iteration 195, loss = 0.00346470
Iteration 196, loss = 0.00356442
Iteration 197, loss = 0.00346261
Iteration 198, loss = 0.00350756
Iteration 199, loss = 0.00349461
Iteration 200, loss = 0.00343147
Iteration 1, loss = 0.14904770
Iteration 2, loss = 0.06504007
Iteration 3, loss = 0.05377013
Iteration 4, loss = 0.04538148
Iteration 5, loss = 0.03907732
Iteration 6, loss = 0.03461971
Iteration 7, loss = 0.03134592
Iteration 8, loss = 0.02896078
Iteration 9, loss = 0.02699345
Iteration 10, loss = 0.02529867
Iteration 11, loss = 0.02399197
Iteration 12, loss = 0.02282563
Iteration 13, loss = 0.02157658
Iteration 14, loss = 0.02084962
Iteration 15, loss = 0.01991569
Iteration 16, loss = 0.01911901
Iteration 17, loss = 0.01838563
Iteration 18, loss = 0.01783374
Iteration 19, loss = 0.01721018
Iteration 20, loss = 0.01678332
Iteration 21, loss = 0.01613727
Iteration 22, loss = 0.01573287
Iteration 23, loss = 0.01511425
Iteration 24, loss = 0.01483752
Iteration 25, loss = 0.01437620
Iteration 26, loss = 0.01404131
Iteration 27, loss = 0.01377554
Iteration 28, loss = 0.01331807
Iteration 29, loss = 0.01295316
Iteration 30, loss = 0.01251111
Iteration 31, loss = 0.01246834
Iteration 32, loss = 0.01207029
Iteration 33, loss = 0.01178442
Iteration 34, loss = 0.01158711
Iteration 35, loss = 0.01134563
Iteration 36, loss = 0.01112927
Iteration 37, loss = 0.01077489
Iteration 38, loss = 0.01059099
Iteration 39, loss = 0.01047508
Iteration 40, loss = 0.01019359
Iteration 41, loss = 0.00994135
Iteration 42, loss = 0.00985959
Iteration 43, loss = 0.00953057
Iteration 44, loss = 0.00940963
Iteration 45, loss = 0.00927908
Iteration 46, loss = 0.00901968
Iteration 47, loss = 0.00895048
Iteration 48, loss = 0.00876012
Iteration 49, loss = 0.00853767
Iteration 50, loss = 0.00834905
Iteration 51, loss = 0.00820643
Iteration 52, loss = 0.00818249
Iteration 53, loss = 0.00808413
Iteration 54, loss = 0.00785007
Iteration 55, loss = 0.00767534
Iteration 56, loss = 0.00761259
Iteration 57, loss = 0.00739805
Iteration 58, loss = 0.00745094
Iteration 59, loss = 0.00720674
Iteration 60, loss = 0.00712030
Iteration 61, loss = 0.00711756
Iteration 62, loss = 0.00694541
Iteration 63, loss = 0.00689311
Iteration 64, loss = 0.00671523
Iteration 65, loss = 0.00663270
Iteration 66, loss = 0.00655346
Iteration 67, loss = 0.00638819
Iteration 68, loss = 0.00637970
Iteration 69, loss = 0.00624230
Iteration 70, loss = 0.00618709
Iteration 71, loss = 0.00611710
Iteration 72, loss = 0.00603310
Iteration 73, loss = 0.00593063
Iteration 74, loss = 0.00596094
Iteration 75, loss = 0.00585866
Iteration 76, loss = 0.00584321
Iteration 77, loss = 0.00573422
Iteration 78, loss = 0.00567481
Iteration 79, loss = 0.00563874
Iteration 80, loss = 0.00552043
Iteration 81, loss = 0.00552726
Iteration 82, loss = 0.00542810
Iteration 83, loss = 0.00539180
Iteration 84, loss = 0.00533763
Iteration 85, loss = 0.00522609
Iteration 86, loss = 0.00524381
Iteration 87, loss = 0.00517237
Iteration 88, loss = 0.00514054
Iteration 89, loss = 0.00511450
Iteration 90, loss = 0.00501421
Iteration 91, loss = 0.00509119
Iteration 92, loss = 0.00497667
Iteration 93, loss = 0.00491447
Iteration 94, loss = 0.00487560
Iteration 95, loss = 0.00479265
Iteration 96, loss = 0.00483919
Iteration 97, loss = 0.00482277
Iteration 98, loss = 0.00476938
Iteration 99, loss = 0.00464818
Iteration 100, loss = 0.00467321
Iteration 101, loss = 0.00472258
Iteration 102, loss = 0.00461864
Iteration 103, loss = 0.00457755
Iteration 104, loss = 0.00454848
Iteration 105, loss = 0.00447093
Iteration 106, loss = 0.00453068
Iteration 107, loss = 0.00447918
Iteration 108, loss = 0.00447099
Iteration 109, loss = 0.00444521
Iteration 110, loss = 0.00443632
Iteration 111, loss = 0.00440207
Iteration 112, loss = 0.00435802
Iteration 113, loss = 0.00445863
Iteration 114, loss = 0.00426541
Iteration 115, loss = 0.00432241
Iteration 116, loss = 0.00428050
Iteration 117, loss = 0.00422044
Iteration 118, loss = 0.00426206
Iteration 119, loss = 0.00421669
Iteration 120, loss = 0.00419023
Iteration 121, loss = 0.00423494
Iteration 122, loss = 0.00421582
Iteration 123, loss = 0.00416168
Iteration 124, loss = 0.00417602
Iteration 125, loss = 0.00409833
Iteration 126, loss = 0.00412814
Iteration 127, loss = 0.00414165
Iteration 128, loss = 0.00413822
Iteration 129, loss = 0.00407291
Iteration 130, loss = 0.00407401
Iteration 131, loss = 0.00409128
Iteration 132, loss = 0.00403609
Iteration 133, loss = 0.00404437
Iteration 134, loss = 0.00400566
Iteration 135, loss = 0.00399403
Iteration 136, loss = 0.00399202
Iteration 137, loss = 0.00402960
Iteration 138, loss = 0.00401605
Iteration 139, loss = 0.00393739
Iteration 140, loss = 0.00402053
Iteration 141, loss = 0.00395468
Iteration 142, loss = 0.00392714
Iteration 143, loss = 0.00395011
Iteration 144, loss = 0.00388294
Iteration 145, loss = 0.00399188
Iteration 146, loss = 0.00392229
Iteration 147, loss = 0.00399392
Iteration 148, loss = 0.00385216
Iteration 149, loss = 0.00385473
Iteration 150, loss = 0.00386440
Iteration 151, loss = 0.00390157
Iteration 152, loss = 0.00377947
Iteration 153, loss = 0.00383455
Iteration 154, loss = 0.00393403
Iteration 155, loss = 0.00379264
Iteration 156, loss = 0.00379535
Iteration 157, loss = 0.00380850
Iteration 158, loss = 0.00383415
Iteration 159, loss = 0.00380411
Iteration 160, loss = 0.00377294
Iteration 161, loss = 0.00386201
Iteration 162, loss = 0.00378502
Iteration 163, loss = 0.00374977
Iteration 164, loss = 0.00371030
Iteration 165, loss = 0.00371832
Iteration 166, loss = 0.00376629
Iteration 167, loss = 0.00375450
Iteration 168, loss = 0.00379442
Iteration 169, loss = 0.00377940
Iteration 170, loss = 0.00376103
Iteration 171, loss = 0.00371272
Iteration 172, loss = 0.00372458
Iteration 173, loss = 0.00375600
Iteration 174, loss = 0.00384275
Iteration 175, loss = 0.00371838
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13760043
Iteration 2, loss = 0.06205971
Iteration 3, loss = 0.05074629
Iteration 4, loss = 0.04304105
Iteration 5, loss = 0.03771542
Iteration 6, loss = 0.03379778
Iteration 7, loss = 0.03077831
Iteration 8, loss = 0.02834384
Iteration 9, loss = 0.02640310
Iteration 10, loss = 0.02454133
Iteration 11, loss = 0.02331249
Iteration 12, loss = 0.02197975
Iteration 13, loss = 0.02090319
Iteration 14, loss = 0.02008796
Iteration 15, loss = 0.01910821
Iteration 16, loss = 0.01837612
Iteration 17, loss = 0.01762371
Iteration 18, loss = 0.01702318
Iteration 19, loss = 0.01641776
Iteration 20, loss = 0.01575057
Iteration 21, loss = 0.01527165
Iteration 22, loss = 0.01478825
Iteration 23, loss = 0.01414368
Iteration 24, loss = 0.01388233
Iteration 25, loss = 0.01340965
Iteration 26, loss = 0.01300185
Iteration 27, loss = 0.01256985
Iteration 28, loss = 0.01215493
Iteration 29, loss = 0.01190129
Iteration 30, loss = 0.01155540
Iteration 31, loss = 0.01123856
Iteration 32, loss = 0.01111517
Iteration 33, loss = 0.01054007
Iteration 34, loss = 0.01042153
Iteration 35, loss = 0.01014386
Iteration 36, loss = 0.00986549
Iteration 37, loss = 0.00971027
Iteration 38, loss = 0.00937219
Iteration 39, loss = 0.00922880
Iteration 40, loss = 0.00895862
Iteration 41, loss = 0.00870863
Iteration 42, loss = 0.00852750
Iteration 43, loss = 0.00835158
Iteration 44, loss = 0.00831344
Iteration 45, loss = 0.00809855
Iteration 46, loss = 0.00782116
Iteration 47, loss = 0.00763419
Iteration 48, loss = 0.00755378
Iteration 49, loss = 0.00732032
Iteration 50, loss = 0.00726935
Iteration 51, loss = 0.00720345
Iteration 52, loss = 0.00697223
Iteration 53, loss = 0.00684903
Iteration 54, loss = 0.00679415
Iteration 55, loss = 0.00666359
Iteration 56, loss = 0.00652098
Iteration 57, loss = 0.00638085
Iteration 58, loss = 0.00633540
Iteration 59, loss = 0.00611862
Iteration 60, loss = 0.00611218
Iteration 61, loss = 0.00598032
Iteration 62, loss = 0.00589972
Iteration 63, loss = 0.00593901
Iteration 64, loss = 0.00578608
Iteration 65, loss = 0.00561558
Iteration 66, loss = 0.00563094
Iteration 67, loss = 0.00547888
Iteration 68, loss = 0.00546542
Iteration 69, loss = 0.00540131
Iteration 70, loss = 0.00533886
Iteration 71, loss = 0.00529078
Iteration 72, loss = 0.00520286
Iteration 73, loss = 0.00505439
Iteration 74, loss = 0.00509592
Iteration 75, loss = 0.00502290
Iteration 76, loss = 0.00493467
Iteration 77, loss = 0.00488909
Iteration 78, loss = 0.00482142
Iteration 79, loss = 0.00485147
Iteration 80, loss = 0.00478420
Iteration 81, loss = 0.00472990
Iteration 82, loss = 0.00473730
Iteration 83, loss = 0.00465184
Iteration 84, loss = 0.00455554
Iteration 85, loss = 0.00466033
Iteration 86, loss = 0.00458412
Iteration 87, loss = 0.00444973
Iteration 88, loss = 0.00451409
Iteration 89, loss = 0.00444906
Iteration 90, loss = 0.00439885
Iteration 91, loss = 0.00430923
Iteration 92, loss = 0.00432302
Iteration 93, loss = 0.00436426
Iteration 94, loss = 0.00425639
Iteration 95, loss = 0.00425531
Iteration 96, loss = 0.00426455
Iteration 97, loss = 0.00425596
Iteration 98, loss = 0.00413136
Iteration 99, loss = 0.00412183
Iteration 100, loss = 0.00413508
Iteration 101, loss = 0.00415026
Iteration 102, loss = 0.00410874
Iteration 103, loss = 0.00417287
Iteration 104, loss = 0.00401075
Iteration 105, loss = 0.00403599
Iteration 106, loss = 0.00402112
Iteration 107, loss = 0.00409069
Iteration 108, loss = 0.00401359
Iteration 109, loss = 0.00399383
Iteration 110, loss = 0.00402098
Iteration 111, loss = 0.00396253
Iteration 112, loss = 0.00398258
Iteration 113, loss = 0.00391502
Iteration 114, loss = 0.00387983
Iteration 115, loss = 0.00389576
Iteration 116, loss = 0.00405706
Iteration 117, loss = 0.00382739
Iteration 118, loss = 0.00396680
Iteration 119, loss = 0.00386993
Iteration 120, loss = 0.00378691
Iteration 121, loss = 0.00379654
Iteration 122, loss = 0.00382263
Iteration 123, loss = 0.00377415
Iteration 124, loss = 0.00390625
Iteration 125, loss = 0.00380257
Iteration 126, loss = 0.00381924
Iteration 127, loss = 0.00380072
Iteration 128, loss = 0.00382348
Iteration 129, loss = 0.00377087
Iteration 130, loss = 0.00372030
Iteration 131, loss = 0.00368293
Iteration 132, loss = 0.00371969
Iteration 133, loss = 0.00377463
Iteration 134, loss = 0.00372966
Iteration 135, loss = 0.00375130
Iteration 136, loss = 0.00372658
Iteration 137, loss = 0.00366847
Iteration 138, loss = 0.00373175
Iteration 139, loss = 0.00370858
Iteration 140, loss = 0.00366487
Iteration 141, loss = 0.00372977
Iteration 142, loss = 0.00369285
Iteration 143, loss = 0.00368662
Iteration 144, loss = 0.00368891
Iteration 145, loss = 0.00371317
Iteration 146, loss = 0.00357412
Iteration 147, loss = 0.00359709
Iteration 148, loss = 0.00362567
Iteration 149, loss = 0.00370074
Iteration 150, loss = 0.00366554
Iteration 151, loss = 0.00354568
Iteration 152, loss = 0.00357492
Iteration 153, loss = 0.00374046
Iteration 154, loss = 0.00356721
Iteration 155, loss = 0.00374202
Iteration 156, loss = 0.00353070
Iteration 157, loss = 0.00349554
Iteration 158, loss = 0.00350557
Iteration 159, loss = 0.00366953
Iteration 160, loss = 0.00370337
Iteration 161, loss = 0.00354829
Iteration 162, loss = 0.00350533
Iteration 163, loss = 0.00351723
Iteration 164, loss = 0.00361905
Iteration 165, loss = 0.00351359
Iteration 166, loss = 0.00357043
Iteration 167, loss = 0.00352231
Iteration 168, loss = 0.00352396
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13235850
Iteration 2, loss = 0.06206340
Iteration 3, loss = 0.05151359
Iteration 4, loss = 0.04376233
Iteration 5, loss = 0.03820207
Iteration 6, loss = 0.03411066
Iteration 7, loss = 0.03115508
Iteration 8, loss = 0.02872913
Iteration 9, loss = 0.02655244
Iteration 10, loss = 0.02491140
Iteration 11, loss = 0.02331729
Iteration 12, loss = 0.02229051
Iteration 13, loss = 0.02107162
Iteration 14, loss = 0.02005033
Iteration 15, loss = 0.01918106
Iteration 16, loss = 0.01848746
Iteration 17, loss = 0.01772409
Iteration 18, loss = 0.01701736
Iteration 19, loss = 0.01635633
Iteration 20, loss = 0.01581749
Iteration 21, loss = 0.01509578
Iteration 22, loss = 0.01471891
Iteration 23, loss = 0.01419429
Iteration 24, loss = 0.01388750
Iteration 25, loss = 0.01340484
Iteration 26, loss = 0.01288438
Iteration 27, loss = 0.01249563
Iteration 28, loss = 0.01210411
Iteration 29, loss = 0.01182474
Iteration 30, loss = 0.01149381
Iteration 31, loss = 0.01113296
Iteration 32, loss = 0.01082644
Iteration 33, loss = 0.01060049
Iteration 34, loss = 0.01016603
Iteration 35, loss = 0.00995725
Iteration 36, loss = 0.00965359
Iteration 37, loss = 0.00952136
Iteration 38, loss = 0.00929288
Iteration 39, loss = 0.00900167
Iteration 40, loss = 0.00874888
Iteration 41, loss = 0.00861153
Iteration 42, loss = 0.00842634
Iteration 43, loss = 0.00835098
Iteration 44, loss = 0.00803004
Iteration 45, loss = 0.00794872
Iteration 46, loss = 0.00774598
Iteration 47, loss = 0.00761078
Iteration 48, loss = 0.00748269
Iteration 49, loss = 0.00727399
Iteration 50, loss = 0.00715600
Iteration 51, loss = 0.00687761
Iteration 52, loss = 0.00697897
Iteration 53, loss = 0.00678493
Iteration 54, loss = 0.00659800
Iteration 55, loss = 0.00649723
Iteration 56, loss = 0.00642073
Iteration 57, loss = 0.00626033
Iteration 58, loss = 0.00635099
Iteration 59, loss = 0.00598601
Iteration 60, loss = 0.00616017
Iteration 61, loss = 0.00598859
Iteration 62, loss = 0.00583204
Iteration 63, loss = 0.00575075
Iteration 64, loss = 0.00568199
Iteration 65, loss = 0.00561709
Iteration 66, loss = 0.00554947
Iteration 67, loss = 0.00547857
Iteration 68, loss = 0.00535503
Iteration 69, loss = 0.00536050
Iteration 70, loss = 0.00531204
Iteration 71, loss = 0.00520634
Iteration 72, loss = 0.00520513
Iteration 73, loss = 0.00515127
Iteration 74, loss = 0.00511628
Iteration 75, loss = 0.00506205
Iteration 76, loss = 0.00493660
Iteration 77, loss = 0.00493918
Iteration 78, loss = 0.00481318
Iteration 79, loss = 0.00477845
Iteration 80, loss = 0.00474437
Iteration 81, loss = 0.00473147
Iteration 82, loss = 0.00468213
Iteration 83, loss = 0.00467064
Iteration 84, loss = 0.00464898
Iteration 85, loss = 0.00462838
Iteration 86, loss = 0.00468053
Iteration 87, loss = 0.00454306
Iteration 88, loss = 0.00443649
Iteration 89, loss = 0.00447486
Iteration 90, loss = 0.00439134
Iteration 91, loss = 0.00444021
Iteration 92, loss = 0.00432037
Iteration 93, loss = 0.00435758
Iteration 94, loss = 0.00430596
Iteration 95, loss = 0.00435235
Iteration 96, loss = 0.00424487
Iteration 97, loss = 0.00419590
Iteration 98, loss = 0.00420000
Iteration 99, loss = 0.00418226
Iteration 100, loss = 0.00420791
Iteration 101, loss = 0.00419242
Iteration 102, loss = 0.00418903
Iteration 103, loss = 0.00410807
Iteration 104, loss = 0.00404223
Iteration 105, loss = 0.00418051
Iteration 106, loss = 0.00405688
Iteration 107, loss = 0.00400674
Iteration 108, loss = 0.00404558
Iteration 109, loss = 0.00397229
Iteration 110, loss = 0.00403667
Iteration 111, loss = 0.00401239
Iteration 112, loss = 0.00403805
Iteration 113, loss = 0.00392394
Iteration 114, loss = 0.00381449
Iteration 115, loss = 0.00398221
Iteration 116, loss = 0.00391720
Iteration 117, loss = 0.00391540
Iteration 118, loss = 0.00390026
Iteration 119, loss = 0.00393791
Iteration 120, loss = 0.00381738
Iteration 121, loss = 0.00390044
Iteration 122, loss = 0.00398736
Iteration 123, loss = 0.00381351
Iteration 124, loss = 0.00373313
Iteration 125, loss = 0.00383800
Iteration 126, loss = 0.00383158
Iteration 127, loss = 0.00374202
Iteration 128, loss = 0.00377670
Iteration 129, loss = 0.00374521
Iteration 130, loss = 0.00375318
Iteration 131, loss = 0.00377462
Iteration 132, loss = 0.00391923
Iteration 133, loss = 0.00375239
Iteration 134, loss = 0.00373791
Iteration 135, loss = 0.00373927
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13074449
Iteration 2, loss = 0.06053108
Iteration 3, loss = 0.04981807
Iteration 4, loss = 0.04252233
Iteration 5, loss = 0.03771817
Iteration 6, loss = 0.03405071
Iteration 7, loss = 0.03103970
Iteration 8, loss = 0.02868535
Iteration 9, loss = 0.02670319
Iteration 10, loss = 0.02498230
Iteration 11, loss = 0.02354749
Iteration 12, loss = 0.02218846
Iteration 13, loss = 0.02117559
Iteration 14, loss = 0.02005794
Iteration 15, loss = 0.01935649
Iteration 16, loss = 0.01848506
Iteration 17, loss = 0.01766724
Iteration 18, loss = 0.01703458
Iteration 19, loss = 0.01641860
Iteration 20, loss = 0.01578337
Iteration 21, loss = 0.01525659
Iteration 22, loss = 0.01463597
Iteration 23, loss = 0.01426802
Iteration 24, loss = 0.01384306
Iteration 25, loss = 0.01339017
Iteration 26, loss = 0.01283669
Iteration 27, loss = 0.01250699
Iteration 28, loss = 0.01216521
Iteration 29, loss = 0.01172917
Iteration 30, loss = 0.01164317
Iteration 31, loss = 0.01109748
Iteration 32, loss = 0.01091773
Iteration 33, loss = 0.01057432
Iteration 34, loss = 0.01041418
Iteration 35, loss = 0.01006351
Iteration 36, loss = 0.00978044
Iteration 37, loss = 0.00962018
Iteration 38, loss = 0.00944064
Iteration 39, loss = 0.00911516
Iteration 40, loss = 0.00897931
Iteration 41, loss = 0.00876284
Iteration 42, loss = 0.00851016
Iteration 43, loss = 0.00840920
Iteration 44, loss = 0.00827225
Iteration 45, loss = 0.00807530
Iteration 46, loss = 0.00789567
Iteration 47, loss = 0.00766840
Iteration 48, loss = 0.00756133
Iteration 49, loss = 0.00739768
Iteration 50, loss = 0.00720108
Iteration 51, loss = 0.00715725
Iteration 52, loss = 0.00702582
Iteration 53, loss = 0.00696097
Iteration 54, loss = 0.00686047
Iteration 55, loss = 0.00678962
Iteration 56, loss = 0.00659294
Iteration 57, loss = 0.00645684
Iteration 58, loss = 0.00632067
Iteration 59, loss = 0.00624166
Iteration 60, loss = 0.00610892
Iteration 61, loss = 0.00605488
Iteration 62, loss = 0.00588260
Iteration 63, loss = 0.00592391
Iteration 64, loss = 0.00577065
Iteration 65, loss = 0.00568917
Iteration 66, loss = 0.00553800
Iteration 67, loss = 0.00559508
Iteration 68, loss = 0.00546600
Iteration 69, loss = 0.00552967
Iteration 70, loss = 0.00550242
Iteration 71, loss = 0.00538986
Iteration 72, loss = 0.00524598
Iteration 73, loss = 0.00512791
Iteration 74, loss = 0.00519999
Iteration 75, loss = 0.00506686
Iteration 76, loss = 0.00498987
Iteration 77, loss = 0.00498376
Iteration 78, loss = 0.00492362
Iteration 79, loss = 0.00495541
Iteration 80, loss = 0.00480843
Iteration 81, loss = 0.00483205
Iteration 82, loss = 0.00477421
Iteration 83, loss = 0.00467403
Iteration 84, loss = 0.00463934
Iteration 85, loss = 0.00464313
Iteration 86, loss = 0.00462992
Iteration 87, loss = 0.00456398
Iteration 88, loss = 0.00445148
Iteration 89, loss = 0.00448243
Iteration 90, loss = 0.00439592
Iteration 91, loss = 0.00447180
Iteration 92, loss = 0.00437853
Iteration 93, loss = 0.00440883
Iteration 94, loss = 0.00438452
Iteration 95, loss = 0.00437778
Iteration 96, loss = 0.00424656
Iteration 97, loss = 0.00427739
Iteration 98, loss = 0.00426098
Iteration 99, loss = 0.00414465
Iteration 100, loss = 0.00416472
Iteration 101, loss = 0.00423173
Iteration 102, loss = 0.00425525
Iteration 103, loss = 0.00414509
Iteration 104, loss = 0.00404301
Iteration 105, loss = 0.00405839
Iteration 106, loss = 0.00407294
Iteration 107, loss = 0.00407926
Iteration 108, loss = 0.00407076
Iteration 109, loss = 0.00409808
Iteration 110, loss = 0.00391462
Iteration 111, loss = 0.00404921
Iteration 112, loss = 0.00392463
Iteration 113, loss = 0.00393307
Iteration 114, loss = 0.00395521
Iteration 115, loss = 0.00394193
Iteration 116, loss = 0.00390817
Iteration 117, loss = 0.00390586
Iteration 118, loss = 0.00387468
Iteration 119, loss = 0.00388365
Iteration 120, loss = 0.00387105
Iteration 121, loss = 0.00395186
Iteration 122, loss = 0.00398452
Iteration 123, loss = 0.00375766
Iteration 124, loss = 0.00372808
Iteration 125, loss = 0.00387079
Iteration 126, loss = 0.00377590
Iteration 127, loss = 0.00373244
Iteration 128, loss = 0.00383140
Iteration 129, loss = 0.00372321
Iteration 130, loss = 0.00380227
Iteration 131, loss = 0.00381299
Iteration 132, loss = 0.00371142
Iteration 133, loss = 0.00368223
Iteration 134, loss = 0.00379599
Iteration 135, loss = 0.00380682
Iteration 136, loss = 0.00374617
Iteration 137, loss = 0.00365065
Iteration 138, loss = 0.00361588
Iteration 139, loss = 0.00373122
Iteration 140, loss = 0.00370358
Iteration 141, loss = 0.00380835
Iteration 142, loss = 0.00376575
Iteration 143, loss = 0.00358256
Iteration 144, loss = 0.00367997
Iteration 145, loss = 0.00359419
Iteration 146, loss = 0.00361190
Iteration 147, loss = 0.00362998
Iteration 148, loss = 0.00374563
Iteration 149, loss = 0.00361458
Iteration 150, loss = 0.00365797
Iteration 151, loss = 0.00367331
Iteration 152, loss = 0.00362691
Iteration 153, loss = 0.00361324
Iteration 154, loss = 0.00354878
Iteration 155, loss = 0.00366081
Iteration 156, loss = 0.00361387
Iteration 157, loss = 0.00364311
Iteration 158, loss = 0.00349446
Iteration 159, loss = 0.00353788
Iteration 160, loss = 0.00350888
Iteration 161, loss = 0.00352042
Iteration 162, loss = 0.00356434
Iteration 163, loss = 0.00364611
Iteration 164, loss = 0.00370130
Iteration 165, loss = 0.00350600
Iteration 166, loss = 0.00353170
Iteration 167, loss = 0.00350911
Iteration 168, loss = 0.00348482
Iteration 169, loss = 0.00348539
Iteration 170, loss = 0.00355933
Iteration 171, loss = 0.00365400
Iteration 172, loss = 0.00347931
Iteration 173, loss = 0.00356212
Iteration 174, loss = 0.00356126
Iteration 175, loss = 0.00345510
Iteration 176, loss = 0.00363052
Iteration 177, loss = 0.00352791
Iteration 178, loss = 0.00342253
Iteration 179, loss = 0.00344546
Iteration 180, loss = 0.00354122
Iteration 181, loss = 0.00373627
Iteration 182, loss = 0.00344188
Iteration 183, loss = 0.00343572
Iteration 184, loss = 0.00343162
Iteration 185, loss = 0.00347397
Iteration 186, loss = 0.00356803
Iteration 187, loss = 0.00358723
Iteration 188, loss = 0.00342104
Iteration 189, loss = 0.00349185
Iteration 190, loss = 0.00337277
Iteration 191, loss = 0.00346739
Iteration 192, loss = 0.00385186
Iteration 193, loss = 0.00342762
Iteration 194, loss = 0.00335945
Iteration 195, loss = 0.00335082
Iteration 196, loss = 0.00341988
Iteration 197, loss = 0.00341527
Iteration 198, loss = 0.00369691
Iteration 199, loss = 0.00355379
Iteration 200, loss = 0.00337967
Iteration 1, loss = 0.12167042
Iteration 2, loss = 0.06026467
Iteration 3, loss = 0.04957377
Iteration 4, loss = 0.04155795
Iteration 5, loss = 0.03627608
Iteration 6, loss = 0.03259535
Iteration 7, loss = 0.02966630
Iteration 8, loss = 0.02732910
Iteration 9, loss = 0.02550610
Iteration 10, loss = 0.02394113
Iteration 11, loss = 0.02267217
Iteration 12, loss = 0.02123943
Iteration 13, loss = 0.02028943
Iteration 14, loss = 0.01931587
Iteration 15, loss = 0.01848434
Iteration 16, loss = 0.01776315
Iteration 17, loss = 0.01705417
Iteration 18, loss = 0.01643312
Iteration 19, loss = 0.01579029
Iteration 20, loss = 0.01512454
Iteration 21, loss = 0.01463000
Iteration 22, loss = 0.01418413
Iteration 23, loss = 0.01366967
Iteration 24, loss = 0.01331721
Iteration 25, loss = 0.01276024
Iteration 26, loss = 0.01244742
Iteration 27, loss = 0.01210277
Iteration 28, loss = 0.01172851
Iteration 29, loss = 0.01135310
Iteration 30, loss = 0.01101098
Iteration 31, loss = 0.01076999
Iteration 32, loss = 0.01040667
Iteration 33, loss = 0.01007778
Iteration 34, loss = 0.00994352
Iteration 35, loss = 0.00960016
Iteration 36, loss = 0.00928808
Iteration 37, loss = 0.00910639
Iteration 38, loss = 0.00902229
Iteration 39, loss = 0.00865884
Iteration 40, loss = 0.00851568
Iteration 41, loss = 0.00825409
Iteration 42, loss = 0.00792317
Iteration 43, loss = 0.00799571
Iteration 44, loss = 0.00772490
Iteration 45, loss = 0.00764315
Iteration 46, loss = 0.00735900
Iteration 47, loss = 0.00727746
Iteration 48, loss = 0.00708220
Iteration 49, loss = 0.00706467
Iteration 50, loss = 0.00686799
Iteration 51, loss = 0.00667768
Iteration 52, loss = 0.00659252
Iteration 53, loss = 0.00643331
Iteration 54, loss = 0.00631233
Iteration 55, loss = 0.00623564
Iteration 56, loss = 0.00615956
Iteration 57, loss = 0.00602935
Iteration 58, loss = 0.00593377
Iteration 59, loss = 0.00589824
Iteration 60, loss = 0.00571147
Iteration 61, loss = 0.00565628
Iteration 62, loss = 0.00553895
Iteration 63, loss = 0.00548694
Iteration 64, loss = 0.00545585
Iteration 65, loss = 0.00533745
Iteration 66, loss = 0.00530372
Iteration 67, loss = 0.00517322
Iteration 68, loss = 0.00514374
Iteration 69, loss = 0.00505458
Iteration 70, loss = 0.00499911
Iteration 71, loss = 0.00502638
Iteration 72, loss = 0.00492228
Iteration 73, loss = 0.00476966
Iteration 74, loss = 0.00476608
Iteration 75, loss = 0.00482116
Iteration 76, loss = 0.00468868
Iteration 77, loss = 0.00466212
Iteration 78, loss = 0.00460793
Iteration 79, loss = 0.00457039
Iteration 80, loss = 0.00451298
Iteration 81, loss = 0.00448161
Iteration 82, loss = 0.00449091
Iteration 83, loss = 0.00439300
Iteration 84, loss = 0.00443789
Iteration 85, loss = 0.00441097
Iteration 86, loss = 0.00429307
Iteration 87, loss = 0.00441789
Iteration 88, loss = 0.00424172
Iteration 89, loss = 0.00425417
Iteration 90, loss = 0.00420917
Iteration 91, loss = 0.00421241
Iteration 92, loss = 0.00424155
Iteration 93, loss = 0.00415559
Iteration 94, loss = 0.00409952
Iteration 95, loss = 0.00413640
Iteration 96, loss = 0.00409564
Iteration 97, loss = 0.00407351
Iteration 98, loss = 0.00402874
Iteration 99, loss = 0.00410886
Iteration 100, loss = 0.00400531
Iteration 101, loss = 0.00409225
Iteration 102, loss = 0.00402253
Iteration 103, loss = 0.00388427
Iteration 104, loss = 0.00398245
Iteration 105, loss = 0.00387981
Iteration 106, loss = 0.00388454
Iteration 107, loss = 0.00387693
Iteration 108, loss = 0.00390349
Iteration 109, loss = 0.00393537
Iteration 110, loss = 0.00393254
Iteration 111, loss = 0.00388070
Iteration 112, loss = 0.00383884
Iteration 113, loss = 0.00377578
Iteration 114, loss = 0.00373749
Iteration 115, loss = 0.00386779
Iteration 116, loss = 0.00378748
Iteration 117, loss = 0.00381776
Iteration 118, loss = 0.00373503
Iteration 119, loss = 0.00374848
Iteration 120, loss = 0.00383384
Iteration 121, loss = 0.00378285
Iteration 122, loss = 0.00366613
Iteration 123, loss = 0.00371004
Iteration 124, loss = 0.00378293
Iteration 125, loss = 0.00365690
Iteration 126, loss = 0.00369956
Iteration 127, loss = 0.00369120
Iteration 128, loss = 0.00373856
Iteration 129, loss = 0.00368763
Iteration 130, loss = 0.00362829
Iteration 131, loss = 0.00369799
Iteration 132, loss = 0.00362228
Iteration 133, loss = 0.00368268
Iteration 134, loss = 0.00361429
Iteration 135, loss = 0.00364387
Iteration 136, loss = 0.00360484
Iteration 137, loss = 0.00369679
Iteration 138, loss = 0.00363171
Iteration 139, loss = 0.00364686
Iteration 140, loss = 0.00353850
Iteration 141, loss = 0.00355904
Iteration 142, loss = 0.00355059
Iteration 143, loss = 0.00363563
Iteration 144, loss = 0.00364007
Iteration 145, loss = 0.00349644
Iteration 146, loss = 0.00356207
Iteration 147, loss = 0.00370781
Iteration 148, loss = 0.00362155
Iteration 149, loss = 0.00350475
Iteration 150, loss = 0.00351817
Iteration 151, loss = 0.00350146
Iteration 152, loss = 0.00349588
Iteration 153, loss = 0.00357334
Iteration 154, loss = 0.00357459
Iteration 155, loss = 0.00360078
Iteration 156, loss = 0.00351896
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.11863161
Iteration 2, loss = 0.06024946
Iteration 3, loss = 0.04979808
Iteration 4, loss = 0.04226210
Iteration 5, loss = 0.03680087
Iteration 6, loss = 0.03270177
Iteration 7, loss = 0.02963796
Iteration 8, loss = 0.02719702
Iteration 9, loss = 0.02523976
Iteration 10, loss = 0.02351037
Iteration 11, loss = 0.02206397
Iteration 12, loss = 0.02097674
Iteration 13, loss = 0.01981511
Iteration 14, loss = 0.01875554
Iteration 15, loss = 0.01792119
Iteration 16, loss = 0.01724435
Iteration 17, loss = 0.01645399
Iteration 18, loss = 0.01588356
Iteration 19, loss = 0.01523198
Iteration 20, loss = 0.01482481
Iteration 21, loss = 0.01424319
Iteration 22, loss = 0.01378235
Iteration 23, loss = 0.01331633
Iteration 24, loss = 0.01295428
Iteration 25, loss = 0.01245569
Iteration 26, loss = 0.01193656
Iteration 27, loss = 0.01176059
Iteration 28, loss = 0.01146953
Iteration 29, loss = 0.01110808
Iteration 30, loss = 0.01071010
Iteration 31, loss = 0.01045599
Iteration 32, loss = 0.01012694
Iteration 33, loss = 0.01001352
Iteration 34, loss = 0.00963545
Iteration 35, loss = 0.00943356
Iteration 36, loss = 0.00922059
Iteration 37, loss = 0.00892250
Iteration 38, loss = 0.00870219
Iteration 39, loss = 0.00859900
Iteration 40, loss = 0.00827411
Iteration 41, loss = 0.00820414
Iteration 42, loss = 0.00807381
Iteration 43, loss = 0.00776690
Iteration 44, loss = 0.00758456
Iteration 45, loss = 0.00742626
Iteration 46, loss = 0.00733040
Iteration 47, loss = 0.00727463
Iteration 48, loss = 0.00698532
Iteration 49, loss = 0.00684945
Iteration 50, loss = 0.00665969
Iteration 51, loss = 0.00666550
Iteration 52, loss = 0.00649857
Iteration 53, loss = 0.00637346
Iteration 54, loss = 0.00631026
Iteration 55, loss = 0.00625164
Iteration 56, loss = 0.00600497
Iteration 57, loss = 0.00600300
Iteration 58, loss = 0.00587056
Iteration 59, loss = 0.00576630
Iteration 60, loss = 0.00571940
Iteration 61, loss = 0.00565979
Iteration 62, loss = 0.00548938
Iteration 63, loss = 0.00545265
Iteration 64, loss = 0.00540911
Iteration 65, loss = 0.00523869
Iteration 66, loss = 0.00518678
Iteration 67, loss = 0.00509545
Iteration 68, loss = 0.00511635
Iteration 69, loss = 0.00505392
Iteration 70, loss = 0.00512037
Iteration 71, loss = 0.00492965
Iteration 72, loss = 0.00483028
Iteration 73, loss = 0.00479932
Iteration 74, loss = 0.00478365
Iteration 75, loss = 0.00473609
Iteration 76, loss = 0.00468743
Iteration 77, loss = 0.00463173
Iteration 78, loss = 0.00460230
Iteration 79, loss = 0.00456280
Iteration 80, loss = 0.00449524
Iteration 81, loss = 0.00448830
Iteration 82, loss = 0.00447392
Iteration 83, loss = 0.00437909
Iteration 84, loss = 0.00434786
Iteration 85, loss = 0.00440180
Iteration 86, loss = 0.00428740
Iteration 87, loss = 0.00429431
Iteration 88, loss = 0.00422710
Iteration 89, loss = 0.00428098
Iteration 90, loss = 0.00429795
Iteration 91, loss = 0.00418556
Iteration 92, loss = 0.00414697
Iteration 93, loss = 0.00409721
Iteration 94, loss = 0.00412213
Iteration 95, loss = 0.00407185
Iteration 96, loss = 0.00405117
Iteration 97, loss = 0.00404751
Iteration 98, loss = 0.00400189
Iteration 99, loss = 0.00404142
Iteration 100, loss = 0.00410015
Iteration 101, loss = 0.00394165
Iteration 102, loss = 0.00394121
Iteration 103, loss = 0.00390891
Iteration 104, loss = 0.00394933
Iteration 105, loss = 0.00392194
Iteration 106, loss = 0.00391522
Iteration 107, loss = 0.00384209
Iteration 108, loss = 0.00396150
Iteration 109, loss = 0.00388179
Iteration 110, loss = 0.00380269
Iteration 111, loss = 0.00380125
Iteration 112, loss = 0.00390594
Iteration 113, loss = 0.00380947
Iteration 114, loss = 0.00383586
Iteration 115, loss = 0.00378181
Iteration 116, loss = 0.00373728
Iteration 117, loss = 0.00373757
Iteration 118, loss = 0.00375224
Iteration 119, loss = 0.00370803
Iteration 120, loss = 0.00373907
Iteration 121, loss = 0.00382908
Iteration 122, loss = 0.00373789
Iteration 123, loss = 0.00378559
Iteration 124, loss = 0.00362213
Iteration 125, loss = 0.00359212
Iteration 126, loss = 0.00369315
Iteration 127, loss = 0.00365198
Iteration 128, loss = 0.00363530
Iteration 129, loss = 0.00372795
Iteration 130, loss = 0.00371849
Iteration 131, loss = 0.00369128
Iteration 132, loss = 0.00360212
Iteration 133, loss = 0.00364792
Iteration 134, loss = 0.00364633
Iteration 135, loss = 0.00357517
Iteration 136, loss = 0.00363975
Iteration 137, loss = 0.00371262
Iteration 138, loss = 0.00360176
Iteration 139, loss = 0.00361267
Iteration 140, loss = 0.00350576
Iteration 141, loss = 0.00354910
Iteration 142, loss = 0.00364444
Iteration 143, loss = 0.00362398
Iteration 144, loss = 0.00352862
Iteration 145, loss = 0.00353537
Iteration 146, loss = 0.00361365
Iteration 147, loss = 0.00355301
Iteration 148, loss = 0.00347918
Iteration 149, loss = 0.00368395
Iteration 150, loss = 0.00353575
Iteration 151, loss = 0.00347990
Iteration 152, loss = 0.00350190
Iteration 153, loss = 0.00362250
Iteration 154, loss = 0.00350444
Iteration 155, loss = 0.00347881
Iteration 156, loss = 0.00349165
Iteration 157, loss = 0.00348415
Iteration 158, loss = 0.00352203
Iteration 159, loss = 0.00344462
Iteration 160, loss = 0.00358207
Iteration 161, loss = 0.00342628
Iteration 162, loss = 0.00356346
Iteration 163, loss = 0.00349650
Iteration 164, loss = 0.00342936
Iteration 165, loss = 0.00355143
Iteration 166, loss = 0.00359324
Iteration 167, loss = 0.00339663
Iteration 168, loss = 0.00337591
Iteration 169, loss = 0.00360046
Iteration 170, loss = 0.00341779
Iteration 171, loss = 0.00345267
Iteration 172, loss = 0.00339169
Iteration 173, loss = 0.00351761
Iteration 174, loss = 0.00342888
Iteration 175, loss = 0.00338322
Iteration 176, loss = 0.00338578
Iteration 177, loss = 0.00356653
Iteration 178, loss = 0.00347214
Iteration 179, loss = 0.00341116
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.11909656
Iteration 2, loss = 0.06074343
Iteration 3, loss = 0.05020350
Iteration 4, loss = 0.04201381
Iteration 5, loss = 0.03624824
Iteration 6, loss = 0.03245137
Iteration 7, loss = 0.02940224
Iteration 8, loss = 0.02721633
Iteration 9, loss = 0.02532668
Iteration 10, loss = 0.02371042
Iteration 11, loss = 0.02239441
Iteration 12, loss = 0.02115563
Iteration 13, loss = 0.02000806
Iteration 14, loss = 0.01905494
Iteration 15, loss = 0.01823625
Iteration 16, loss = 0.01740041
Iteration 17, loss = 0.01675079
Iteration 18, loss = 0.01603450
Iteration 19, loss = 0.01550443
Iteration 20, loss = 0.01485573
Iteration 21, loss = 0.01441777
Iteration 22, loss = 0.01388839
Iteration 23, loss = 0.01331556
Iteration 24, loss = 0.01288511
Iteration 25, loss = 0.01253305
Iteration 26, loss = 0.01206279
Iteration 27, loss = 0.01169573
Iteration 28, loss = 0.01137672
Iteration 29, loss = 0.01102073
Iteration 30, loss = 0.01066028
Iteration 31, loss = 0.01041602
Iteration 32, loss = 0.00997112
Iteration 33, loss = 0.00981362
Iteration 34, loss = 0.00959348
Iteration 35, loss = 0.00935512
Iteration 36, loss = 0.00904773
Iteration 37, loss = 0.00883922
Iteration 38, loss = 0.00866308
Iteration 39, loss = 0.00838804
Iteration 40, loss = 0.00824090
Iteration 41, loss = 0.00811499
Iteration 42, loss = 0.00784140
Iteration 43, loss = 0.00765418
Iteration 44, loss = 0.00749888
Iteration 45, loss = 0.00740529
Iteration 46, loss = 0.00714795
Iteration 47, loss = 0.00699138
Iteration 48, loss = 0.00681430
Iteration 49, loss = 0.00667513
Iteration 50, loss = 0.00651525
Iteration 51, loss = 0.00640897
Iteration 52, loss = 0.00631454
Iteration 53, loss = 0.00627853
Iteration 54, loss = 0.00614851
Iteration 55, loss = 0.00602729
Iteration 56, loss = 0.00594764
Iteration 57, loss = 0.00585495
Iteration 58, loss = 0.00563361
Iteration 59, loss = 0.00562281
Iteration 60, loss = 0.00552487
Iteration 61, loss = 0.00537791
Iteration 62, loss = 0.00539715
Iteration 63, loss = 0.00539574
Iteration 64, loss = 0.00526797
Iteration 65, loss = 0.00511533
Iteration 66, loss = 0.00510914
Iteration 67, loss = 0.00506225
Iteration 68, loss = 0.00499796
Iteration 69, loss = 0.00489918
Iteration 70, loss = 0.00481578
Iteration 71, loss = 0.00482260
Iteration 72, loss = 0.00479151
Iteration 73, loss = 0.00468246
Iteration 74, loss = 0.00462287
Iteration 75, loss = 0.00462923
Iteration 76, loss = 0.00455405
Iteration 77, loss = 0.00453238
Iteration 78, loss = 0.00442945
Iteration 79, loss = 0.00448877
Iteration 80, loss = 0.00432102
Iteration 81, loss = 0.00435596
Iteration 82, loss = 0.00428678
Iteration 83, loss = 0.00441079
Iteration 84, loss = 0.00429776
Iteration 85, loss = 0.00429740
Iteration 86, loss = 0.00417591
Iteration 87, loss = 0.00434219
Iteration 88, loss = 0.00414524
Iteration 89, loss = 0.00414523
Iteration 90, loss = 0.00408025
Iteration 91, loss = 0.00409670
Iteration 92, loss = 0.00412082
Iteration 93, loss = 0.00405505
Iteration 94, loss = 0.00410357
Iteration 95, loss = 0.00405126
Iteration 96, loss = 0.00396688
Iteration 97, loss = 0.00392352
Iteration 98, loss = 0.00396390
Iteration 99, loss = 0.00392826
Iteration 100, loss = 0.00392060
Iteration 101, loss = 0.00393669
Iteration 102, loss = 0.00393978
Iteration 103, loss = 0.00393906
Iteration 104, loss = 0.00393279
Iteration 105, loss = 0.00380342
Iteration 106, loss = 0.00383179
Iteration 107, loss = 0.00379169
Iteration 108, loss = 0.00380869
Iteration 109, loss = 0.00387423
Iteration 110, loss = 0.00381278
Iteration 111, loss = 0.00375251
Iteration 112, loss = 0.00373566
Iteration 113, loss = 0.00379045
Iteration 114, loss = 0.00373163
Iteration 115, loss = 0.00378892
Iteration 116, loss = 0.00367869
Iteration 117, loss = 0.00380151
Iteration 118, loss = 0.00367532
Iteration 119, loss = 0.00376555
Iteration 120, loss = 0.00368217
Iteration 121, loss = 0.00369653
Iteration 122, loss = 0.00362550
Iteration 123, loss = 0.00375809
Iteration 124, loss = 0.00363003
Iteration 125, loss = 0.00360601
Iteration 126, loss = 0.00375345
Iteration 127, loss = 0.00358833
Iteration 128, loss = 0.00363496
Iteration 129, loss = 0.00356905
Iteration 130, loss = 0.00370797
Iteration 131, loss = 0.00371814
Iteration 132, loss = 0.00354944
Iteration 133, loss = 0.00348972
Iteration 134, loss = 0.00355176
Iteration 135, loss = 0.00357468
Iteration 136, loss = 0.00366595
Iteration 137, loss = 0.00362572
Iteration 138, loss = 0.00352187
Iteration 139, loss = 0.00356441
Iteration 140, loss = 0.00351092
Iteration 141, loss = 0.00360750
Iteration 142, loss = 0.00349178
Iteration 143, loss = 0.00350353
Iteration 144, loss = 0.00349944
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.15132273
Iteration 2, loss = 0.06708254
Iteration 3, loss = 0.05710033
Iteration 4, loss = 0.05066465
Iteration 5, loss = 0.04532040
Iteration 6, loss = 0.04107744
Iteration 7, loss = 0.03765098
Iteration 8, loss = 0.03466305
Iteration 9, loss = 0.03250143
Iteration 10, loss = 0.03072321
Iteration 11, loss = 0.02909520
Iteration 12, loss = 0.02776215
Iteration 13, loss = 0.02653715
Iteration 14, loss = 0.02554358
Iteration 15, loss = 0.02465186
Iteration 16, loss = 0.02380090
Iteration 17, loss = 0.02292527
Iteration 18, loss = 0.02228624
Iteration 19, loss = 0.02160408
Iteration 20, loss = 0.02098872
Iteration 21, loss = 0.02044598
Iteration 22, loss = 0.01999436
Iteration 23, loss = 0.01950962
Iteration 24, loss = 0.01903399
Iteration 25, loss = 0.01863219
Iteration 26, loss = 0.01822544
Iteration 27, loss = 0.01775464
Iteration 28, loss = 0.01745838
Iteration 29, loss = 0.01721638
Iteration 30, loss = 0.01685035
Iteration 31, loss = 0.01649692
Iteration 32, loss = 0.01613485
Iteration 33, loss = 0.01587185
Iteration 34, loss = 0.01564336
Iteration 35, loss = 0.01530354
Iteration 36, loss = 0.01508260
Iteration 37, loss = 0.01486365
Iteration 38, loss = 0.01467679
Iteration 39, loss = 0.01436919
Iteration 40, loss = 0.01414829
Iteration 41, loss = 0.01400774
Iteration 42, loss = 0.01372482
Iteration 43, loss = 0.01350612
Iteration 44, loss = 0.01334659
Iteration 45, loss = 0.01319356
Iteration 46, loss = 0.01294328
Iteration 47, loss = 0.01285015
Iteration 48, loss = 0.01262484
Iteration 49, loss = 0.01253399
Iteration 50, loss = 0.01228880
Iteration 51, loss = 0.01216781
Iteration 52, loss = 0.01197916
Iteration 53, loss = 0.01188676
Iteration 54, loss = 0.01173043
Iteration 55, loss = 0.01147265
Iteration 56, loss = 0.01135836
Iteration 57, loss = 0.01131378
Iteration 58, loss = 0.01108019
Iteration 59, loss = 0.01097200
Iteration 60, loss = 0.01091434
Iteration 61, loss = 0.01074807
Iteration 62, loss = 0.01061056
Iteration 63, loss = 0.01049937
Iteration 64, loss = 0.01046041
Iteration 65, loss = 0.01022436
Iteration 66, loss = 0.01021897
Iteration 67, loss = 0.01011930
Iteration 68, loss = 0.00993624
Iteration 69, loss = 0.00988565
Iteration 70, loss = 0.00986079
Iteration 71, loss = 0.00969198
Iteration 72, loss = 0.00960406
Iteration 73, loss = 0.00947844
Iteration 74, loss = 0.00948610
Iteration 75, loss = 0.00930377
Iteration 76, loss = 0.00929808
Iteration 77, loss = 0.00920781
Iteration 78, loss = 0.00907788
Iteration 79, loss = 0.00899925
Iteration 80, loss = 0.00894306
Iteration 81, loss = 0.00889487
Iteration 82, loss = 0.00876919
Iteration 83, loss = 0.00871010
Iteration 84, loss = 0.00871318
Iteration 85, loss = 0.00857435
Iteration 86, loss = 0.00856753
Iteration 87, loss = 0.00842365
Iteration 88, loss = 0.00846681
Iteration 89, loss = 0.00823972
Iteration 90, loss = 0.00826948
Iteration 91, loss = 0.00814437
Iteration 92, loss = 0.00819509
Iteration 93, loss = 0.00807384
Iteration 94, loss = 0.00798722
Iteration 95, loss = 0.00800999
Iteration 96, loss = 0.00779541
Iteration 97, loss = 0.00791095
Iteration 98, loss = 0.00783905
Iteration 99, loss = 0.00776289
Iteration 100, loss = 0.00771674
Iteration 101, loss = 0.00767334
Iteration 102, loss = 0.00765189
Iteration 103, loss = 0.00765779
Iteration 104, loss = 0.00746806
Iteration 105, loss = 0.00741503
Iteration 106, loss = 0.00739047
Iteration 107, loss = 0.00734516
Iteration 108, loss = 0.00739635
Iteration 109, loss = 0.00720726
Iteration 110, loss = 0.00720999
Iteration 111, loss = 0.00726024
Iteration 112, loss = 0.00720149
Iteration 113, loss = 0.00715604
Iteration 114, loss = 0.00707443
Iteration 115, loss = 0.00700275
Iteration 116, loss = 0.00708056
Iteration 117, loss = 0.00698435
Iteration 118, loss = 0.00694746
Iteration 119, loss = 0.00693509
Iteration 120, loss = 0.00679451
Iteration 121, loss = 0.00690563
Iteration 122, loss = 0.00685617
Iteration 123, loss = 0.00672532
Iteration 124, loss = 0.00675578
Iteration 125, loss = 0.00665743
Iteration 126, loss = 0.00663800
Iteration 127, loss = 0.00674099
Iteration 128, loss = 0.00660228
Iteration 129, loss = 0.00653718
Iteration 130, loss = 0.00655993
Iteration 131, loss = 0.00658951
Iteration 132, loss = 0.00652404
Iteration 133, loss = 0.00648035
Iteration 134, loss = 0.00642355
Iteration 135, loss = 0.00645782
Iteration 136, loss = 0.00648317
Iteration 137, loss = 0.00632000
Iteration 138, loss = 0.00634132
Iteration 139, loss = 0.00637735
Iteration 140, loss = 0.00633839
Iteration 141, loss = 0.00628004
Iteration 142, loss = 0.00632375
Iteration 143, loss = 0.00615777
Iteration 144, loss = 0.00618245
Iteration 145, loss = 0.00613418
Iteration 146, loss = 0.00619701
Iteration 147, loss = 0.00615471
Iteration 148, loss = 0.00615902
Iteration 149, loss = 0.00610395
Iteration 150, loss = 0.00603094
Iteration 151, loss = 0.00606980
Iteration 152, loss = 0.00611311
Iteration 153, loss = 0.00602095
Iteration 154, loss = 0.00604614
Iteration 155, loss = 0.00601487
Iteration 156, loss = 0.00592431
Iteration 157, loss = 0.00600761
Iteration 158, loss = 0.00592934
Iteration 159, loss = 0.00594155
Iteration 160, loss = 0.00593806
Iteration 161, loss = 0.00584323
Iteration 162, loss = 0.00588226
Iteration 163, loss = 0.00595756
Iteration 164, loss = 0.00586496
Iteration 165, loss = 0.00584163
Iteration 166, loss = 0.00583205
Iteration 167, loss = 0.00577137
Iteration 168, loss = 0.00580644
Iteration 169, loss = 0.00574204
Iteration 170, loss = 0.00572637
Iteration 171, loss = 0.00573637
Iteration 172, loss = 0.00569801
Iteration 173, loss = 0.00568572
Iteration 174, loss = 0.00570025
Iteration 175, loss = 0.00571124
Iteration 176, loss = 0.00566073
Iteration 177, loss = 0.00569849
Iteration 178, loss = 0.00557968
Iteration 179, loss = 0.00558433
Iteration 180, loss = 0.00563893
Iteration 181, loss = 0.00557358
Iteration 182, loss = 0.00549721
Iteration 183, loss = 0.00555831
Iteration 184, loss = 0.00553678
Iteration 185, loss = 0.00551408
Iteration 186, loss = 0.00552948
Iteration 187, loss = 0.00557832
Iteration 188, loss = 0.00555621
Iteration 189, loss = 0.00554753
Iteration 190, loss = 0.00553136
Iteration 191, loss = 0.00549158
Iteration 192, loss = 0.00546000
Iteration 193, loss = 0.00547389
Iteration 194, loss = 0.00545626
Iteration 195, loss = 0.00545200
Iteration 196, loss = 0.00540466
Iteration 197, loss = 0.00536651
Iteration 198, loss = 0.00544408
Iteration 199, loss = 0.00540116
Iteration 200, loss = 0.00538532
Iteration 1, loss = 0.15656852
Iteration 2, loss = 0.06734950
Iteration 3, loss = 0.05787599
Iteration 4, loss = 0.05066257
Iteration 5, loss = 0.04477658
Iteration 6, loss = 0.04020106
Iteration 7, loss = 0.03669102
Iteration 8, loss = 0.03388017
Iteration 9, loss = 0.03153132
Iteration 10, loss = 0.02967777
Iteration 11, loss = 0.02814580
Iteration 12, loss = 0.02681436
Iteration 13, loss = 0.02567169
Iteration 14, loss = 0.02453270
Iteration 15, loss = 0.02371022
Iteration 16, loss = 0.02298148
Iteration 17, loss = 0.02215412
Iteration 18, loss = 0.02160551
Iteration 19, loss = 0.02086040
Iteration 20, loss = 0.02022330
Iteration 21, loss = 0.01975926
Iteration 22, loss = 0.01921988
Iteration 23, loss = 0.01884922
Iteration 24, loss = 0.01839617
Iteration 25, loss = 0.01793206
Iteration 26, loss = 0.01756646
Iteration 27, loss = 0.01724515
Iteration 28, loss = 0.01680554
Iteration 29, loss = 0.01648550
Iteration 30, loss = 0.01619541
Iteration 31, loss = 0.01581003
Iteration 32, loss = 0.01556696
Iteration 33, loss = 0.01515879
Iteration 34, loss = 0.01502822
Iteration 35, loss = 0.01475315
Iteration 36, loss = 0.01444994
Iteration 37, loss = 0.01425110
Iteration 38, loss = 0.01401460
Iteration 39, loss = 0.01377019
Iteration 40, loss = 0.01371427
Iteration 41, loss = 0.01346079
Iteration 42, loss = 0.01312170
Iteration 43, loss = 0.01292246
Iteration 44, loss = 0.01271198
Iteration 45, loss = 0.01260719
Iteration 46, loss = 0.01242391
Iteration 47, loss = 0.01228078
Iteration 48, loss = 0.01215610
Iteration 49, loss = 0.01193850
Iteration 50, loss = 0.01181093
Iteration 51, loss = 0.01161201
Iteration 52, loss = 0.01142966
Iteration 53, loss = 0.01144744
Iteration 54, loss = 0.01118287
Iteration 55, loss = 0.01108919
Iteration 56, loss = 0.01092614
Iteration 57, loss = 0.01078764
Iteration 58, loss = 0.01068786
Iteration 59, loss = 0.01062887
Iteration 60, loss = 0.01055719
Iteration 61, loss = 0.01049249
Iteration 62, loss = 0.01034770
Iteration 63, loss = 0.01023605
Iteration 64, loss = 0.01009651
Iteration 65, loss = 0.00997024
Iteration 66, loss = 0.00984044
Iteration 67, loss = 0.00978721
Iteration 68, loss = 0.00978938
Iteration 69, loss = 0.00962701
Iteration 70, loss = 0.00953741
Iteration 71, loss = 0.00947586
Iteration 72, loss = 0.00937785
Iteration 73, loss = 0.00924205
Iteration 74, loss = 0.00912731
Iteration 75, loss = 0.00911196
Iteration 76, loss = 0.00900860
Iteration 77, loss = 0.00893262
Iteration 78, loss = 0.00898633
Iteration 79, loss = 0.00873453
Iteration 80, loss = 0.00873726
Iteration 81, loss = 0.00869528
Iteration 82, loss = 0.00857528
Iteration 83, loss = 0.00855571
Iteration 84, loss = 0.00840016
Iteration 85, loss = 0.00836631
Iteration 86, loss = 0.00829867
Iteration 87, loss = 0.00821768
Iteration 88, loss = 0.00816701
Iteration 89, loss = 0.00810539
Iteration 90, loss = 0.00805220
Iteration 91, loss = 0.00798968
Iteration 92, loss = 0.00798542
Iteration 93, loss = 0.00786826
Iteration 94, loss = 0.00786368
Iteration 95, loss = 0.00780167
Iteration 96, loss = 0.00775630
Iteration 97, loss = 0.00762410
Iteration 98, loss = 0.00762985
Iteration 99, loss = 0.00748670
Iteration 100, loss = 0.00757668
Iteration 101, loss = 0.00738243
Iteration 102, loss = 0.00741785
Iteration 103, loss = 0.00736822
Iteration 104, loss = 0.00737281
Iteration 105, loss = 0.00728927
Iteration 106, loss = 0.00720912
Iteration 107, loss = 0.00716092
Iteration 108, loss = 0.00718817
Iteration 109, loss = 0.00719383
Iteration 110, loss = 0.00701299
Iteration 111, loss = 0.00707987
Iteration 112, loss = 0.00699527
Iteration 113, loss = 0.00694233
Iteration 114, loss = 0.00694328
Iteration 115, loss = 0.00691979
Iteration 116, loss = 0.00683194
Iteration 117, loss = 0.00679479
Iteration 118, loss = 0.00673596
Iteration 119, loss = 0.00664680
Iteration 120, loss = 0.00678937
Iteration 121, loss = 0.00664861
Iteration 122, loss = 0.00668382
Iteration 123, loss = 0.00665768
Iteration 124, loss = 0.00652455
Iteration 125, loss = 0.00653536
Iteration 126, loss = 0.00655623
Iteration 127, loss = 0.00649219
Iteration 128, loss = 0.00638706
Iteration 129, loss = 0.00642003
Iteration 130, loss = 0.00634323
Iteration 131, loss = 0.00638944
Iteration 132, loss = 0.00643249
Iteration 133, loss = 0.00626308
Iteration 134, loss = 0.00632095
Iteration 135, loss = 0.00622839
Iteration 136, loss = 0.00623058
Iteration 137, loss = 0.00625368
Iteration 138, loss = 0.00628218
Iteration 139, loss = 0.00618021
Iteration 140, loss = 0.00609381
Iteration 141, loss = 0.00613650
Iteration 142, loss = 0.00612506
Iteration 143, loss = 0.00610674
Iteration 144, loss = 0.00610807
Iteration 145, loss = 0.00603796
Iteration 146, loss = 0.00603802
Iteration 147, loss = 0.00601179
Iteration 148, loss = 0.00600977
Iteration 149, loss = 0.00594767
Iteration 150, loss = 0.00594910
Iteration 151, loss = 0.00598316
Iteration 152, loss = 0.00588099
Iteration 153, loss = 0.00588588
Iteration 154, loss = 0.00583276
Iteration 155, loss = 0.00578798
Iteration 156, loss = 0.00578709
Iteration 157, loss = 0.00586267
Iteration 158, loss = 0.00587808
Iteration 159, loss = 0.00577153
Iteration 160, loss = 0.00576300
Iteration 161, loss = 0.00582187
Iteration 162, loss = 0.00578596
Iteration 163, loss = 0.00568471
Iteration 164, loss = 0.00577018
Iteration 165, loss = 0.00570815
Iteration 166, loss = 0.00565980
Iteration 167, loss = 0.00567534
Iteration 168, loss = 0.00566450
Iteration 169, loss = 0.00561909
Iteration 170, loss = 0.00562894
Iteration 171, loss = 0.00558853
Iteration 172, loss = 0.00565218
Iteration 173, loss = 0.00555005
Iteration 174, loss = 0.00553651
Iteration 175, loss = 0.00559540
Iteration 176, loss = 0.00559641
Iteration 177, loss = 0.00551935
Iteration 178, loss = 0.00553210
Iteration 179, loss = 0.00550825
Iteration 180, loss = 0.00548008
Iteration 181, loss = 0.00542969
Iteration 182, loss = 0.00547838
Iteration 183, loss = 0.00545791
Iteration 184, loss = 0.00555779
Iteration 185, loss = 0.00547425
Iteration 186, loss = 0.00544486
Iteration 187, loss = 0.00547642
Iteration 188, loss = 0.00538596
Iteration 189, loss = 0.00539171
Iteration 190, loss = 0.00534780
Iteration 191, loss = 0.00541305
Iteration 192, loss = 0.00542362
Iteration 193, loss = 0.00537109
Iteration 194, loss = 0.00536513
Iteration 195, loss = 0.00530339
Iteration 196, loss = 0.00530179
Iteration 197, loss = 0.00532670
Iteration 198, loss = 0.00535778
Iteration 199, loss = 0.00532662
Iteration 200, loss = 0.00526725
Iteration 1, loss = 0.14861757
Iteration 2, loss = 0.06803808
Iteration 3, loss = 0.05855305
Iteration 4, loss = 0.05161913
Iteration 5, loss = 0.04556200
Iteration 6, loss = 0.04098902
Iteration 7, loss = 0.03744774
Iteration 8, loss = 0.03484409
Iteration 9, loss = 0.03274665
Iteration 10, loss = 0.03087124
Iteration 11, loss = 0.02934912
Iteration 12, loss = 0.02813313
Iteration 13, loss = 0.02705195
Iteration 14, loss = 0.02596351
Iteration 15, loss = 0.02499153
Iteration 16, loss = 0.02411808
Iteration 17, loss = 0.02319718
Iteration 18, loss = 0.02260431
Iteration 19, loss = 0.02194423
Iteration 20, loss = 0.02120125
Iteration 21, loss = 0.02059824
Iteration 22, loss = 0.02007218
Iteration 23, loss = 0.01946598
Iteration 24, loss = 0.01902699
Iteration 25, loss = 0.01852791
Iteration 26, loss = 0.01802027
Iteration 27, loss = 0.01763369
Iteration 28, loss = 0.01720936
Iteration 29, loss = 0.01681525
Iteration 30, loss = 0.01642094
Iteration 31, loss = 0.01627719
Iteration 32, loss = 0.01578942
Iteration 33, loss = 0.01542857
Iteration 34, loss = 0.01520595
Iteration 35, loss = 0.01494601
Iteration 36, loss = 0.01466382
Iteration 37, loss = 0.01430605
Iteration 38, loss = 0.01410844
Iteration 39, loss = 0.01386107
Iteration 40, loss = 0.01366455
Iteration 41, loss = 0.01345832
Iteration 42, loss = 0.01321900
Iteration 43, loss = 0.01301787
Iteration 44, loss = 0.01278805
Iteration 45, loss = 0.01256779
Iteration 46, loss = 0.01243862
Iteration 47, loss = 0.01217917
Iteration 48, loss = 0.01206110
Iteration 49, loss = 0.01180021
Iteration 50, loss = 0.01162447
Iteration 51, loss = 0.01153943
Iteration 52, loss = 0.01137392
Iteration 53, loss = 0.01113378
Iteration 54, loss = 0.01100579
Iteration 55, loss = 0.01086390
Iteration 56, loss = 0.01073326
Iteration 57, loss = 0.01054190
Iteration 58, loss = 0.01039296
Iteration 59, loss = 0.01016758
Iteration 60, loss = 0.01009359
Iteration 61, loss = 0.01000805
Iteration 62, loss = 0.00992217
Iteration 63, loss = 0.00982485
Iteration 64, loss = 0.00964612
Iteration 65, loss = 0.00960117
Iteration 66, loss = 0.00946295
Iteration 67, loss = 0.00934264
Iteration 68, loss = 0.00926696
Iteration 69, loss = 0.00923903
Iteration 70, loss = 0.00905510
Iteration 71, loss = 0.00898624
Iteration 72, loss = 0.00886961
Iteration 73, loss = 0.00878068
Iteration 74, loss = 0.00872476
Iteration 75, loss = 0.00871214
Iteration 76, loss = 0.00850155
Iteration 77, loss = 0.00855107
Iteration 78, loss = 0.00845760
Iteration 79, loss = 0.00830865
Iteration 80, loss = 0.00816858
Iteration 81, loss = 0.00817847
Iteration 82, loss = 0.00808241
Iteration 83, loss = 0.00804054
Iteration 84, loss = 0.00791563
Iteration 85, loss = 0.00791519
Iteration 86, loss = 0.00790753
Iteration 87, loss = 0.00769923
Iteration 88, loss = 0.00772302
Iteration 89, loss = 0.00767088
Iteration 90, loss = 0.00754123
Iteration 91, loss = 0.00744788
Iteration 92, loss = 0.00742635
Iteration 93, loss = 0.00748873
Iteration 94, loss = 0.00734343
Iteration 95, loss = 0.00727497
Iteration 96, loss = 0.00727690
Iteration 97, loss = 0.00723651
Iteration 98, loss = 0.00713922
Iteration 99, loss = 0.00707308
Iteration 100, loss = 0.00707152
Iteration 101, loss = 0.00694918
Iteration 102, loss = 0.00702536
Iteration 103, loss = 0.00691447
Iteration 104, loss = 0.00680719
Iteration 105, loss = 0.00689876
Iteration 106, loss = 0.00687009
Iteration 107, loss = 0.00675633
Iteration 108, loss = 0.00671068
Iteration 109, loss = 0.00667924
Iteration 110, loss = 0.00670337
Iteration 111, loss = 0.00662010
Iteration 112, loss = 0.00654467
Iteration 113, loss = 0.00659333
Iteration 114, loss = 0.00652712
Iteration 115, loss = 0.00642890
Iteration 116, loss = 0.00649707
Iteration 117, loss = 0.00634666
Iteration 118, loss = 0.00640764
Iteration 119, loss = 0.00639656
Iteration 120, loss = 0.00628759
Iteration 121, loss = 0.00627525
Iteration 122, loss = 0.00627605
Iteration 123, loss = 0.00629199
Iteration 124, loss = 0.00620756
Iteration 125, loss = 0.00619323
Iteration 126, loss = 0.00609560
Iteration 127, loss = 0.00611182
Iteration 128, loss = 0.00613439
Iteration 129, loss = 0.00604785
Iteration 130, loss = 0.00608841
Iteration 131, loss = 0.00602565
Iteration 132, loss = 0.00603388
Iteration 133, loss = 0.00598048
Iteration 134, loss = 0.00594483
Iteration 135, loss = 0.00590993
Iteration 136, loss = 0.00588499
Iteration 137, loss = 0.00580029
Iteration 138, loss = 0.00582324
Iteration 139, loss = 0.00587480
Iteration 140, loss = 0.00584605
Iteration 141, loss = 0.00577218
Iteration 142, loss = 0.00580550
Iteration 143, loss = 0.00576422
Iteration 144, loss = 0.00569853
Iteration 145, loss = 0.00581125
Iteration 146, loss = 0.00569391
Iteration 147, loss = 0.00574699
Iteration 148, loss = 0.00566141
Iteration 149, loss = 0.00565549
Iteration 150, loss = 0.00559658
Iteration 151, loss = 0.00559926
Iteration 152, loss = 0.00558133
Iteration 153, loss = 0.00558599
Iteration 154, loss = 0.00551460
Iteration 155, loss = 0.00554225
Iteration 156, loss = 0.00553553
Iteration 157, loss = 0.00560794
Iteration 158, loss = 0.00547503
Iteration 159, loss = 0.00542512
Iteration 160, loss = 0.00551268
Iteration 161, loss = 0.00549591
Iteration 162, loss = 0.00543676
Iteration 163, loss = 0.00543874
Iteration 164, loss = 0.00546292
Iteration 165, loss = 0.00543542
Iteration 166, loss = 0.00542422
Iteration 167, loss = 0.00535151
Iteration 168, loss = 0.00540319
Iteration 169, loss = 0.00533731
Iteration 170, loss = 0.00538570
Iteration 171, loss = 0.00531861
Iteration 172, loss = 0.00531423
Iteration 173, loss = 0.00537642
Iteration 174, loss = 0.00535400
Iteration 175, loss = 0.00527919
Iteration 176, loss = 0.00521311
Iteration 177, loss = 0.00526260
Iteration 178, loss = 0.00528820
Iteration 179, loss = 0.00523276
Iteration 180, loss = 0.00528410
Iteration 181, loss = 0.00524400
Iteration 182, loss = 0.00523418
Iteration 183, loss = 0.00521837
Iteration 184, loss = 0.00519833
Iteration 185, loss = 0.00515855
Iteration 186, loss = 0.00516651
Iteration 187, loss = 0.00522983
Iteration 188, loss = 0.00523837
Iteration 189, loss = 0.00516884
Iteration 190, loss = 0.00517249
Iteration 191, loss = 0.00523933
Iteration 192, loss = 0.00514094
Iteration 193, loss = 0.00510010
Iteration 194, loss = 0.00510258
Iteration 195, loss = 0.00510389
Iteration 196, loss = 0.00509327
Iteration 197, loss = 0.00514558
Iteration 198, loss = 0.00505359
Iteration 199, loss = 0.00516744
Iteration 200, loss = 0.00505024
Iteration 1, loss = 0.14318590
Iteration 2, loss = 0.06519368
Iteration 3, loss = 0.05469323
Iteration 4, loss = 0.04797394
Iteration 5, loss = 0.04262600
Iteration 6, loss = 0.03830817
Iteration 7, loss = 0.03493677
Iteration 8, loss = 0.03230930
Iteration 9, loss = 0.02996487
Iteration 10, loss = 0.02822544
Iteration 11, loss = 0.02653861
Iteration 12, loss = 0.02535859
Iteration 13, loss = 0.02417763
Iteration 14, loss = 0.02314823
Iteration 15, loss = 0.02224176
Iteration 16, loss = 0.02148081
Iteration 17, loss = 0.02072558
Iteration 18, loss = 0.02004347
Iteration 19, loss = 0.01946664
Iteration 20, loss = 0.01889694
Iteration 21, loss = 0.01826706
Iteration 22, loss = 0.01790214
Iteration 23, loss = 0.01732104
Iteration 24, loss = 0.01699001
Iteration 25, loss = 0.01646036
Iteration 26, loss = 0.01609593
Iteration 27, loss = 0.01561427
Iteration 28, loss = 0.01543995
Iteration 29, loss = 0.01496316
Iteration 30, loss = 0.01462496
Iteration 31, loss = 0.01435091
Iteration 32, loss = 0.01412044
Iteration 33, loss = 0.01374042
Iteration 34, loss = 0.01347538
Iteration 35, loss = 0.01313183
Iteration 36, loss = 0.01291617
Iteration 37, loss = 0.01272666
Iteration 38, loss = 0.01251323
Iteration 39, loss = 0.01222065
Iteration 40, loss = 0.01201105
Iteration 41, loss = 0.01177921
Iteration 42, loss = 0.01161023
Iteration 43, loss = 0.01140878
Iteration 44, loss = 0.01122202
Iteration 45, loss = 0.01104141
Iteration 46, loss = 0.01080067
Iteration 47, loss = 0.01069666
Iteration 48, loss = 0.01049988
Iteration 49, loss = 0.01026815
Iteration 50, loss = 0.01019382
Iteration 51, loss = 0.01001104
Iteration 52, loss = 0.00987166
Iteration 53, loss = 0.00969562
Iteration 54, loss = 0.00961815
Iteration 55, loss = 0.00953690
Iteration 56, loss = 0.00931237
Iteration 57, loss = 0.00920884
Iteration 58, loss = 0.00923209
Iteration 59, loss = 0.00897935
Iteration 60, loss = 0.00883628
Iteration 61, loss = 0.00872164
Iteration 62, loss = 0.00875839
Iteration 63, loss = 0.00864950
Iteration 64, loss = 0.00848363
Iteration 65, loss = 0.00839375
Iteration 66, loss = 0.00827866
Iteration 67, loss = 0.00819969
Iteration 68, loss = 0.00820417
Iteration 69, loss = 0.00795941
Iteration 70, loss = 0.00803842
Iteration 71, loss = 0.00794090
Iteration 72, loss = 0.00771447
Iteration 73, loss = 0.00771047
Iteration 74, loss = 0.00760726
Iteration 75, loss = 0.00758732
Iteration 76, loss = 0.00756392
Iteration 77, loss = 0.00753608
Iteration 78, loss = 0.00731884
Iteration 79, loss = 0.00725032
Iteration 80, loss = 0.00718529
Iteration 81, loss = 0.00709228
Iteration 82, loss = 0.00699364
Iteration 83, loss = 0.00698502
Iteration 84, loss = 0.00690481
Iteration 85, loss = 0.00687116
Iteration 86, loss = 0.00688742
Iteration 87, loss = 0.00688756
Iteration 88, loss = 0.00673805
Iteration 89, loss = 0.00660917
Iteration 90, loss = 0.00656936
Iteration 91, loss = 0.00659163
Iteration 92, loss = 0.00653191
Iteration 93, loss = 0.00662210
Iteration 94, loss = 0.00643584
Iteration 95, loss = 0.00645001
Iteration 96, loss = 0.00639412
Iteration 97, loss = 0.00635899
Iteration 98, loss = 0.00623804
Iteration 99, loss = 0.00626506
Iteration 100, loss = 0.00619323
Iteration 101, loss = 0.00617202
Iteration 102, loss = 0.00613183
Iteration 103, loss = 0.00605726
Iteration 104, loss = 0.00602827
Iteration 105, loss = 0.00595342
Iteration 106, loss = 0.00607347
Iteration 107, loss = 0.00604081
Iteration 108, loss = 0.00587915
Iteration 109, loss = 0.00593594
Iteration 110, loss = 0.00585405
Iteration 111, loss = 0.00584182
Iteration 112, loss = 0.00579470
Iteration 113, loss = 0.00574021
Iteration 114, loss = 0.00580368
Iteration 115, loss = 0.00583786
Iteration 116, loss = 0.00571522
Iteration 117, loss = 0.00570134
Iteration 118, loss = 0.00569945
Iteration 119, loss = 0.00557742
Iteration 120, loss = 0.00573117
Iteration 121, loss = 0.00562357
Iteration 122, loss = 0.00556057
Iteration 123, loss = 0.00562028
Iteration 124, loss = 0.00552449
Iteration 125, loss = 0.00547052
Iteration 126, loss = 0.00550635
Iteration 127, loss = 0.00551011
Iteration 128, loss = 0.00553097
Iteration 129, loss = 0.00543326
Iteration 130, loss = 0.00538300
Iteration 131, loss = 0.00539355
Iteration 132, loss = 0.00540505
Iteration 133, loss = 0.00539273
Iteration 134, loss = 0.00539561
Iteration 135, loss = 0.00531755
Iteration 136, loss = 0.00531396
Iteration 137, loss = 0.00528942
Iteration 138, loss = 0.00525660
Iteration 139, loss = 0.00529027
Iteration 140, loss = 0.00523033
Iteration 141, loss = 0.00526442
Iteration 142, loss = 0.00525121
Iteration 143, loss = 0.00526077
Iteration 144, loss = 0.00519648
Iteration 145, loss = 0.00513779
Iteration 146, loss = 0.00515617
Iteration 147, loss = 0.00513192
Iteration 148, loss = 0.00508593
Iteration 149, loss = 0.00512622
Iteration 150, loss = 0.00519868
Iteration 151, loss = 0.00508350
Iteration 152, loss = 0.00507690
Iteration 153, loss = 0.00517721
Iteration 154, loss = 0.00515136
Iteration 155, loss = 0.00505048
Iteration 156, loss = 0.00503853
Iteration 157, loss = 0.00502056
Iteration 158, loss = 0.00504132
Iteration 159, loss = 0.00504644
Iteration 160, loss = 0.00509620
Iteration 161, loss = 0.00500054
Iteration 162, loss = 0.00505433
Iteration 163, loss = 0.00509805
Iteration 164, loss = 0.00500281
Iteration 165, loss = 0.00501760
Iteration 166, loss = 0.00495290
Iteration 167, loss = 0.00498192
Iteration 168, loss = 0.00494353
Iteration 169, loss = 0.00491714
Iteration 170, loss = 0.00495211
Iteration 171, loss = 0.00486811
Iteration 172, loss = 0.00492135
Iteration 173, loss = 0.00490796
Iteration 174, loss = 0.00491834
Iteration 175, loss = 0.00487877
Iteration 176, loss = 0.00484824
Iteration 177, loss = 0.00490969
Iteration 178, loss = 0.00499426
Iteration 179, loss = 0.00484092
Iteration 180, loss = 0.00485381
Iteration 181, loss = 0.00488720
Iteration 182, loss = 0.00488808
Iteration 183, loss = 0.00487347
Iteration 184, loss = 0.00490315
Iteration 185, loss = 0.00486389
Iteration 186, loss = 0.00482396
Iteration 187, loss = 0.00480483
Iteration 188, loss = 0.00483313
Iteration 189, loss = 0.00486024
Iteration 190, loss = 0.00479405
Iteration 191, loss = 0.00479674
Iteration 192, loss = 0.00482132
Iteration 193, loss = 0.00484848
Iteration 194, loss = 0.00478072
Iteration 195, loss = 0.00478428
Iteration 196, loss = 0.00485097
Iteration 197, loss = 0.00476408
Iteration 198, loss = 0.00477891
Iteration 199, loss = 0.00478695
Iteration 200, loss = 0.00471798
Iteration 1, loss = 0.12799844
Iteration 2, loss = 0.06304519
Iteration 3, loss = 0.05341790
Iteration 4, loss = 0.04639747
Iteration 5, loss = 0.04108070
Iteration 6, loss = 0.03718578
Iteration 7, loss = 0.03413257
Iteration 8, loss = 0.03157721
Iteration 9, loss = 0.02957405
Iteration 10, loss = 0.02776177
Iteration 11, loss = 0.02637656
Iteration 12, loss = 0.02505259
Iteration 13, loss = 0.02385944
Iteration 14, loss = 0.02289699
Iteration 15, loss = 0.02201881
Iteration 16, loss = 0.02111556
Iteration 17, loss = 0.02043847
Iteration 18, loss = 0.01972774
Iteration 19, loss = 0.01919190
Iteration 20, loss = 0.01856669
Iteration 21, loss = 0.01811370
Iteration 22, loss = 0.01745382
Iteration 23, loss = 0.01703596
Iteration 24, loss = 0.01649507
Iteration 25, loss = 0.01608285
Iteration 26, loss = 0.01579264
Iteration 27, loss = 0.01541695
Iteration 28, loss = 0.01492702
Iteration 29, loss = 0.01476612
Iteration 30, loss = 0.01430520
Iteration 31, loss = 0.01399537
Iteration 32, loss = 0.01370710
Iteration 33, loss = 0.01345007
Iteration 34, loss = 0.01329052
Iteration 35, loss = 0.01285650
Iteration 36, loss = 0.01264785
Iteration 37, loss = 0.01238973
Iteration 38, loss = 0.01213931
Iteration 39, loss = 0.01190363
Iteration 40, loss = 0.01179224
Iteration 41, loss = 0.01155418
Iteration 42, loss = 0.01132403
Iteration 43, loss = 0.01116768
Iteration 44, loss = 0.01086386
Iteration 45, loss = 0.01078011
Iteration 46, loss = 0.01071106
Iteration 47, loss = 0.01046164
Iteration 48, loss = 0.01030456
Iteration 49, loss = 0.01019986
Iteration 50, loss = 0.01002438
Iteration 51, loss = 0.00986700
Iteration 52, loss = 0.00973623
Iteration 53, loss = 0.00958183
Iteration 54, loss = 0.00947212
Iteration 55, loss = 0.00949376
Iteration 56, loss = 0.00928526
Iteration 57, loss = 0.00915570
Iteration 58, loss = 0.00910846
Iteration 59, loss = 0.00889938
Iteration 60, loss = 0.00885195
Iteration 61, loss = 0.00878874
Iteration 62, loss = 0.00861626
Iteration 63, loss = 0.00857361
Iteration 64, loss = 0.00850955
Iteration 65, loss = 0.00823661
Iteration 66, loss = 0.00822476
Iteration 67, loss = 0.00817223
Iteration 68, loss = 0.00815673
Iteration 69, loss = 0.00800710
Iteration 70, loss = 0.00794364
Iteration 71, loss = 0.00788953
Iteration 72, loss = 0.00773398
Iteration 73, loss = 0.00763342
Iteration 74, loss = 0.00767873
Iteration 75, loss = 0.00757478
Iteration 76, loss = 0.00745348
Iteration 77, loss = 0.00745493
Iteration 78, loss = 0.00745070
Iteration 79, loss = 0.00735198
Iteration 80, loss = 0.00712027
Iteration 81, loss = 0.00719654
Iteration 82, loss = 0.00708246
Iteration 83, loss = 0.00707473
Iteration 84, loss = 0.00697301
Iteration 85, loss = 0.00689220
Iteration 86, loss = 0.00705495
Iteration 87, loss = 0.00690621
Iteration 88, loss = 0.00680783
Iteration 89, loss = 0.00677345
Iteration 90, loss = 0.00674620
Iteration 91, loss = 0.00666117
Iteration 92, loss = 0.00663389
Iteration 93, loss = 0.00660875
Iteration 94, loss = 0.00659110
Iteration 95, loss = 0.00650115
Iteration 96, loss = 0.00645379
Iteration 97, loss = 0.00641177
Iteration 98, loss = 0.00636540
Iteration 99, loss = 0.00628766
Iteration 100, loss = 0.00634437
Iteration 101, loss = 0.00627558
Iteration 102, loss = 0.00619935
Iteration 103, loss = 0.00621670
Iteration 104, loss = 0.00616763
Iteration 105, loss = 0.00604873
Iteration 106, loss = 0.00615010
Iteration 107, loss = 0.00604589
Iteration 108, loss = 0.00602227
Iteration 109, loss = 0.00599559
Iteration 110, loss = 0.00597629
Iteration 111, loss = 0.00591963
Iteration 112, loss = 0.00586403
Iteration 113, loss = 0.00591699
Iteration 114, loss = 0.00586372
Iteration 115, loss = 0.00583766
Iteration 116, loss = 0.00587747
Iteration 117, loss = 0.00582775
Iteration 118, loss = 0.00576102
Iteration 119, loss = 0.00579443
Iteration 120, loss = 0.00573301
Iteration 121, loss = 0.00573016
Iteration 122, loss = 0.00562316
Iteration 123, loss = 0.00561295
Iteration 124, loss = 0.00567518
Iteration 125, loss = 0.00552378
Iteration 126, loss = 0.00566932
Iteration 127, loss = 0.00561124
Iteration 128, loss = 0.00562333
Iteration 129, loss = 0.00560367
Iteration 130, loss = 0.00552571
Iteration 131, loss = 0.00550482
Iteration 132, loss = 0.00544147
Iteration 133, loss = 0.00548911
Iteration 134, loss = 0.00546626
Iteration 135, loss = 0.00540334
Iteration 136, loss = 0.00545433
Iteration 137, loss = 0.00543369
Iteration 138, loss = 0.00543780
Iteration 139, loss = 0.00538227
Iteration 140, loss = 0.00538833
Iteration 141, loss = 0.00537161
Iteration 142, loss = 0.00531209
Iteration 143, loss = 0.00539146
Iteration 144, loss = 0.00532503
Iteration 145, loss = 0.00522544
Iteration 146, loss = 0.00535231
Iteration 147, loss = 0.00526257
Iteration 148, loss = 0.00527531
Iteration 149, loss = 0.00520822
Iteration 150, loss = 0.00521782
Iteration 151, loss = 0.00534055
Iteration 152, loss = 0.00527870
Iteration 153, loss = 0.00524797
Iteration 154, loss = 0.00518552
Iteration 155, loss = 0.00513198
Iteration 156, loss = 0.00516555
Iteration 157, loss = 0.00514364
Iteration 158, loss = 0.00517702
Iteration 159, loss = 0.00520285
Iteration 160, loss = 0.00517332
Iteration 161, loss = 0.00511120
Iteration 162, loss = 0.00509727
Iteration 163, loss = 0.00508732
Iteration 164, loss = 0.00516625
Iteration 165, loss = 0.00517015
Iteration 166, loss = 0.00508569
Iteration 167, loss = 0.00508058
Iteration 168, loss = 0.00506924
Iteration 169, loss = 0.00512298
Iteration 170, loss = 0.00504326
Iteration 171, loss = 0.00508898
Iteration 172, loss = 0.00508907
Iteration 173, loss = 0.00496547
Iteration 174, loss = 0.00500406
Iteration 175, loss = 0.00496446
Iteration 176, loss = 0.00503872
Iteration 177, loss = 0.00501895
Iteration 178, loss = 0.00502116
Iteration 179, loss = 0.00501560
Iteration 180, loss = 0.00492884
Iteration 181, loss = 0.00497138
Iteration 182, loss = 0.00510333
Iteration 183, loss = 0.00496391
Iteration 184, loss = 0.00491532
Iteration 185, loss = 0.00493184
Iteration 186, loss = 0.00501456
Iteration 187, loss = 0.00493684
Iteration 188, loss = 0.00492202
Iteration 189, loss = 0.00494181
Iteration 190, loss = 0.00491951
Iteration 191, loss = 0.00488504
Iteration 192, loss = 0.00497091
Iteration 193, loss = 0.00489476
Iteration 194, loss = 0.00498682
Iteration 195, loss = 0.00488298
Iteration 196, loss = 0.00490856
Iteration 197, loss = 0.00491476
Iteration 198, loss = 0.00488464
Iteration 199, loss = 0.00482619
Iteration 200, loss = 0.00487310
Iteration 1, loss = 0.15451954
Iteration 2, loss = 0.06711817
Iteration 3, loss = 0.05677983
Iteration 4, loss = 0.04993887
Iteration 5, loss = 0.04401943
Iteration 6, loss = 0.03919062
Iteration 7, loss = 0.03527509
Iteration 8, loss = 0.03229932
Iteration 9, loss = 0.02984108
Iteration 10, loss = 0.02810949
Iteration 11, loss = 0.02639968
Iteration 12, loss = 0.02511730
Iteration 13, loss = 0.02405695
Iteration 14, loss = 0.02307818
Iteration 15, loss = 0.02219726
Iteration 16, loss = 0.02140458
Iteration 17, loss = 0.02062711
Iteration 18, loss = 0.02006686
Iteration 19, loss = 0.01937276
Iteration 20, loss = 0.01883023
Iteration 21, loss = 0.01822807
Iteration 22, loss = 0.01772948
Iteration 23, loss = 0.01719331
Iteration 24, loss = 0.01694839
Iteration 25, loss = 0.01636749
Iteration 26, loss = 0.01593686
Iteration 27, loss = 0.01557549
Iteration 28, loss = 0.01527324
Iteration 29, loss = 0.01483010
Iteration 30, loss = 0.01454529
Iteration 31, loss = 0.01412006
Iteration 32, loss = 0.01382288
Iteration 33, loss = 0.01360764
Iteration 34, loss = 0.01318698
Iteration 35, loss = 0.01290505
Iteration 36, loss = 0.01272775
Iteration 37, loss = 0.01248979
Iteration 38, loss = 0.01221496
Iteration 39, loss = 0.01194046
Iteration 40, loss = 0.01172315
Iteration 41, loss = 0.01154814
Iteration 42, loss = 0.01130430
Iteration 43, loss = 0.01112822
Iteration 44, loss = 0.01090188
Iteration 45, loss = 0.01070700
Iteration 46, loss = 0.01056386
Iteration 47, loss = 0.01033409
Iteration 48, loss = 0.01027505
Iteration 49, loss = 0.01006097
Iteration 50, loss = 0.00989210
Iteration 51, loss = 0.00957675
Iteration 52, loss = 0.00962436
Iteration 53, loss = 0.00945100
Iteration 54, loss = 0.00924936
Iteration 55, loss = 0.00914898
Iteration 56, loss = 0.00912287
Iteration 57, loss = 0.00882347
Iteration 58, loss = 0.00876902
Iteration 59, loss = 0.00868068
Iteration 60, loss = 0.00852253
Iteration 61, loss = 0.00846870
Iteration 62, loss = 0.00826928
Iteration 63, loss = 0.00824440
Iteration 64, loss = 0.00805212
Iteration 65, loss = 0.00814973
Iteration 66, loss = 0.00800228
Iteration 67, loss = 0.00785614
Iteration 68, loss = 0.00766226
Iteration 69, loss = 0.00777929
Iteration 70, loss = 0.00757578
Iteration 71, loss = 0.00757274
Iteration 72, loss = 0.00740334
Iteration 73, loss = 0.00743704
Iteration 74, loss = 0.00732013
Iteration 75, loss = 0.00722360
Iteration 76, loss = 0.00718621
Iteration 77, loss = 0.00707915
Iteration 78, loss = 0.00703918
Iteration 79, loss = 0.00694743
Iteration 80, loss = 0.00703245
Iteration 81, loss = 0.00695767
Iteration 82, loss = 0.00676669
Iteration 83, loss = 0.00678070
Iteration 84, loss = 0.00666369
Iteration 85, loss = 0.00662755
Iteration 86, loss = 0.00649431
Iteration 87, loss = 0.00658175
Iteration 88, loss = 0.00651128
Iteration 89, loss = 0.00650647
Iteration 90, loss = 0.00636033
Iteration 91, loss = 0.00633880
Iteration 92, loss = 0.00628554
Iteration 93, loss = 0.00627458
Iteration 94, loss = 0.00628894
Iteration 95, loss = 0.00615807
Iteration 96, loss = 0.00604889
Iteration 97, loss = 0.00606293
Iteration 98, loss = 0.00614128
Iteration 99, loss = 0.00602990
Iteration 100, loss = 0.00600021
Iteration 101, loss = 0.00603026
Iteration 102, loss = 0.00587734
Iteration 103, loss = 0.00590877
Iteration 104, loss = 0.00582515
Iteration 105, loss = 0.00591269
Iteration 106, loss = 0.00581328
Iteration 107, loss = 0.00576651
Iteration 108, loss = 0.00577878
Iteration 109, loss = 0.00575021
Iteration 110, loss = 0.00567788
Iteration 111, loss = 0.00565693
Iteration 112, loss = 0.00565201
Iteration 113, loss = 0.00566124
Iteration 114, loss = 0.00559445
Iteration 115, loss = 0.00555157
Iteration 116, loss = 0.00554204
Iteration 117, loss = 0.00551441
Iteration 118, loss = 0.00553561
Iteration 119, loss = 0.00547861
Iteration 120, loss = 0.00541269
Iteration 121, loss = 0.00549955
Iteration 122, loss = 0.00546967
Iteration 123, loss = 0.00542517
Iteration 124, loss = 0.00536667
Iteration 125, loss = 0.00535342
Iteration 126, loss = 0.00533439
Iteration 127, loss = 0.00543615
Iteration 128, loss = 0.00531812
Iteration 129, loss = 0.00531196
Iteration 130, loss = 0.00522980
Iteration 131, loss = 0.00525582
Iteration 132, loss = 0.00526516
Iteration 133, loss = 0.00532069
Iteration 134, loss = 0.00521754
Iteration 135, loss = 0.00521678
Iteration 136, loss = 0.00524120
Iteration 137, loss = 0.00524613
Iteration 138, loss = 0.00515471
Iteration 139, loss = 0.00519134
Iteration 140, loss = 0.00516938
Iteration 141, loss = 0.00515595
Iteration 142, loss = 0.00515967
Iteration 143, loss = 0.00507701
Iteration 144, loss = 0.00519787
Iteration 145, loss = 0.00514223
Iteration 146, loss = 0.00511189
Iteration 147, loss = 0.00509458
Iteration 148, loss = 0.00516216
Iteration 149, loss = 0.00512070
Iteration 150, loss = 0.00501866
Iteration 151, loss = 0.00499116
Iteration 152, loss = 0.00504109
Iteration 153, loss = 0.00502326
Iteration 154, loss = 0.00499677
Iteration 155, loss = 0.00498915
Iteration 156, loss = 0.00497045
Iteration 157, loss = 0.00497887
Iteration 158, loss = 0.00498683
Iteration 159, loss = 0.00503343
Iteration 160, loss = 0.00495352
Iteration 161, loss = 0.00497404
Iteration 162, loss = 0.00494012
Iteration 163, loss = 0.00496600
Iteration 164, loss = 0.00497198
Iteration 165, loss = 0.00494662
Iteration 166, loss = 0.00492315
Iteration 167, loss = 0.00489260
Iteration 168, loss = 0.00493180
Iteration 169, loss = 0.00493440
Iteration 170, loss = 0.00486794
Iteration 171, loss = 0.00489365
Iteration 172, loss = 0.00493633
Iteration 173, loss = 0.00489309
Iteration 174, loss = 0.00483877
Iteration 175, loss = 0.00486082
Iteration 176, loss = 0.00487761
Iteration 177, loss = 0.00487207
Iteration 178, loss = 0.00483534
Iteration 179, loss = 0.00485054
Iteration 180, loss = 0.00487222
Iteration 181, loss = 0.00481730
Iteration 182, loss = 0.00479587
Iteration 183, loss = 0.00480221
Iteration 184, loss = 0.00484191
Iteration 185, loss = 0.00481698
Iteration 186, loss = 0.00478280
Iteration 187, loss = 0.00486326
Iteration 188, loss = 0.00485625
Iteration 189, loss = 0.00473327
Iteration 190, loss = 0.00482174
Iteration 191, loss = 0.00483237
Iteration 192, loss = 0.00474397
Iteration 193, loss = 0.00477047
Iteration 194, loss = 0.00474639
Iteration 195, loss = 0.00479524
Iteration 196, loss = 0.00482101
Iteration 197, loss = 0.00469753
Iteration 198, loss = 0.00472741
Iteration 199, loss = 0.00476377
Iteration 200, loss = 0.00474032
Iteration 1, loss = 0.14999573
Iteration 2, loss = 0.06657642
Iteration 3, loss = 0.05568337
Iteration 4, loss = 0.04752943
Iteration 5, loss = 0.04145182
Iteration 6, loss = 0.03686785
Iteration 7, loss = 0.03355775
Iteration 8, loss = 0.03074701
Iteration 9, loss = 0.02872184
Iteration 10, loss = 0.02711001
Iteration 11, loss = 0.02555745
Iteration 12, loss = 0.02427480
Iteration 13, loss = 0.02324728
Iteration 14, loss = 0.02233518
Iteration 15, loss = 0.02147532
Iteration 16, loss = 0.02057018
Iteration 17, loss = 0.01980922
Iteration 18, loss = 0.01935667
Iteration 19, loss = 0.01870002
Iteration 20, loss = 0.01808067
Iteration 21, loss = 0.01749330
Iteration 22, loss = 0.01710803
Iteration 23, loss = 0.01665142
Iteration 24, loss = 0.01630040
Iteration 25, loss = 0.01581601
Iteration 26, loss = 0.01537597
Iteration 27, loss = 0.01501426
Iteration 28, loss = 0.01461660
Iteration 29, loss = 0.01431135
Iteration 30, loss = 0.01403709
Iteration 31, loss = 0.01357805
Iteration 32, loss = 0.01338221
Iteration 33, loss = 0.01308966
Iteration 34, loss = 0.01285035
Iteration 35, loss = 0.01261739
Iteration 36, loss = 0.01236092
Iteration 37, loss = 0.01200267
Iteration 38, loss = 0.01187657
Iteration 39, loss = 0.01167899
Iteration 40, loss = 0.01150605
Iteration 41, loss = 0.01118499
Iteration 42, loss = 0.01103254
Iteration 43, loss = 0.01094457
Iteration 44, loss = 0.01056397
Iteration 45, loss = 0.01055710
Iteration 46, loss = 0.01029731
Iteration 47, loss = 0.01002454
Iteration 48, loss = 0.00998348
Iteration 49, loss = 0.00979918
Iteration 50, loss = 0.00952873
Iteration 51, loss = 0.00941850
Iteration 52, loss = 0.00933541
Iteration 53, loss = 0.00911294
Iteration 54, loss = 0.00898297
Iteration 55, loss = 0.00888826
Iteration 56, loss = 0.00877062
Iteration 57, loss = 0.00859585
Iteration 58, loss = 0.00850103
Iteration 59, loss = 0.00843202
Iteration 60, loss = 0.00825265
Iteration 61, loss = 0.00805455
Iteration 62, loss = 0.00794090
Iteration 63, loss = 0.00796316
Iteration 64, loss = 0.00785527
Iteration 65, loss = 0.00770523
Iteration 66, loss = 0.00772150
Iteration 67, loss = 0.00758138
Iteration 68, loss = 0.00747909
Iteration 69, loss = 0.00731432
Iteration 70, loss = 0.00724281
Iteration 71, loss = 0.00724523
Iteration 72, loss = 0.00719028
Iteration 73, loss = 0.00705965
Iteration 74, loss = 0.00694408
Iteration 75, loss = 0.00688764
Iteration 76, loss = 0.00673487
Iteration 77, loss = 0.00678695
Iteration 78, loss = 0.00677295
Iteration 79, loss = 0.00664881
Iteration 80, loss = 0.00655533
Iteration 81, loss = 0.00650233
Iteration 82, loss = 0.00652613
Iteration 83, loss = 0.00635398
Iteration 84, loss = 0.00632161
Iteration 85, loss = 0.00642480
Iteration 86, loss = 0.00634439
Iteration 87, loss = 0.00612043
Iteration 88, loss = 0.00614015
Iteration 89, loss = 0.00611738
Iteration 90, loss = 0.00613900
Iteration 91, loss = 0.00594693
Iteration 92, loss = 0.00599000
Iteration 93, loss = 0.00596298
Iteration 94, loss = 0.00592430
Iteration 95, loss = 0.00586058
Iteration 96, loss = 0.00580690
Iteration 97, loss = 0.00581189
Iteration 98, loss = 0.00583072
Iteration 99, loss = 0.00569102
Iteration 100, loss = 0.00574223
Iteration 101, loss = 0.00564585
Iteration 102, loss = 0.00564565
Iteration 103, loss = 0.00564060
Iteration 104, loss = 0.00551770
Iteration 105, loss = 0.00555304
Iteration 106, loss = 0.00546011
Iteration 107, loss = 0.00549226
Iteration 108, loss = 0.00540856
Iteration 109, loss = 0.00547809
Iteration 110, loss = 0.00548129Using TensorFlow backend.
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

Iteration 111, loss = 0.00539970
Iteration 112, loss = 0.00541414
Iteration 113, loss = 0.00535085
Iteration 114, loss = 0.00535700
Iteration 115, loss = 0.00536226
Iteration 116, loss = 0.00523596
Iteration 117, loss = 0.00529883
Iteration 118, loss = 0.00520690
Iteration 119, loss = 0.00535392
Iteration 120, loss = 0.00526474
Iteration 121, loss = 0.00517215
Iteration 122, loss = 0.00515087
Iteration 123, loss = 0.00515716
Iteration 124, loss = 0.00515814
Iteration 125, loss = 0.00508082
Iteration 126, loss = 0.00512426
Iteration 127, loss = 0.00512793
Iteration 128, loss = 0.00515110
Iteration 129, loss = 0.00508750
Iteration 130, loss = 0.00506185
Iteration 131, loss = 0.00502498
Iteration 132, loss = 0.00509667
Iteration 133, loss = 0.00498451
Iteration 134, loss = 0.00499633
Iteration 135, loss = 0.00497118
Iteration 136, loss = 0.00501496
Iteration 137, loss = 0.00502176
Iteration 138, loss = 0.00492709
Iteration 139, loss = 0.00487461
Iteration 140, loss = 0.00499786
Iteration 141, loss = 0.00495771
Iteration 142, loss = 0.00491061
Iteration 143, loss = 0.00487920
Iteration 144, loss = 0.00493103
Iteration 145, loss = 0.00489628
Iteration 146, loss = 0.00498240
Iteration 147, loss = 0.00481727
Iteration 148, loss = 0.00485832
Iteration 149, loss = 0.00483974
Iteration 150, loss = 0.00484083
Iteration 151, loss = 0.00490749
Iteration 152, loss = 0.00484707
Iteration 153, loss = 0.00496022
Iteration 154, loss = 0.00478815
Iteration 155, loss = 0.00482165
Iteration 156, loss = 0.00481221
Iteration 157, loss = 0.00479583
Iteration 158, loss = 0.00477392
Iteration 159, loss = 0.00471163
Iteration 160, loss = 0.00480639
Iteration 161, loss = 0.00473416
Iteration 162, loss = 0.00479220
Iteration 163, loss = 0.00477422
Iteration 164, loss = 0.00478526
Iteration 165, loss = 0.00473574
Iteration 166, loss = 0.00474487
Iteration 167, loss = 0.00475982
Iteration 168, loss = 0.00481365
Iteration 169, loss = 0.00471155
Iteration 170, loss = 0.00470433
Iteration 171, loss = 0.00477464
Iteration 172, loss = 0.00469785
Iteration 173, loss = 0.00464131
Iteration 174, loss = 0.00474897
Iteration 175, loss = 0.00470296
Iteration 176, loss = 0.00467236
Iteration 177, loss = 0.00469386
Iteration 178, loss = 0.00470116
Iteration 179, loss = 0.00468824
Iteration 180, loss = 0.00466237
Iteration 181, loss = 0.00468686
Iteration 182, loss = 0.00468726
Iteration 183, loss = 0.00466893
Iteration 184, loss = 0.00464688
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.12574732
Iteration 2, loss = 0.06159152
Iteration 3, loss = 0.05161773
Iteration 4, loss = 0.04439026
Iteration 5, loss = 0.03894894
Iteration 6, loss = 0.03499517
Iteration 7, loss = 0.03179605
Iteration 8, loss = 0.02955148
Iteration 9, loss = 0.02759622
Iteration 10, loss = 0.02599285
Iteration 11, loss = 0.02464106
Iteration 12, loss = 0.02354794
Iteration 13, loss = 0.02255610
Iteration 14, loss = 0.02167346
Iteration 15, loss = 0.02077663
Iteration 16, loss = 0.01995622
Iteration 17, loss = 0.01912316
Iteration 18, loss = 0.01857921
Iteration 19, loss = 0.01804925
Iteration 20, loss = 0.01737322
Iteration 21, loss = 0.01678554
Iteration 22, loss = 0.01638855
Iteration 23, loss = 0.01590819
Iteration 24, loss = 0.01531474
Iteration 25, loss = 0.01504059
Iteration 26, loss = 0.01454071
Iteration 27, loss = 0.01413404
Iteration 28, loss = 0.01378202
Iteration 29, loss = 0.01346129
Iteration 30, loss = 0.01317448
Iteration 31, loss = 0.01282336
Iteration 32, loss = 0.01251482
Iteration 33, loss = 0.01225358
Iteration 34, loss = 0.01196644
Iteration 35, loss = 0.01172096
Iteration 36, loss = 0.01152322
Iteration 37, loss = 0.01123970
Iteration 38, loss = 0.01092868
Iteration 39, loss = 0.01080049
Iteration 40, loss = 0.01050286
Iteration 41, loss = 0.01030856
Iteration 42, loss = 0.01022444
Iteration 43, loss = 0.01005168
Iteration 44, loss = 0.00990586
Iteration 45, loss = 0.00971791
Iteration 46, loss = 0.00948569
Iteration 47, loss = 0.00932557
Iteration 48, loss = 0.00917790
Iteration 49, loss = 0.00905649
Iteration 50, loss = 0.00880127
Iteration 51, loss = 0.00874297
Iteration 52, loss = 0.00860980
Iteration 53, loss = 0.00850924
Iteration 54, loss = 0.00833842
Iteration 55, loss = 0.00829613
Iteration 56, loss = 0.00808828
Iteration 57, loss = 0.00809778
Iteration 58, loss = 0.00794805
Iteration 59, loss = 0.00785429
Iteration 60, loss = 0.00769538
Iteration 61, loss = 0.00759435
Iteration 62, loss = 0.00758297
Iteration 63, loss = 0.00744129
Iteration 64, loss = 0.00736756
Iteration 65, loss = 0.00731630
Iteration 66, loss = 0.00723345
Iteration 67, loss = 0.00706684
Iteration 68, loss = 0.00705783
Iteration 69, loss = 0.00699551
Iteration 70, loss = 0.00692987
Iteration 71, loss = 0.00669002
Iteration 72, loss = 0.00677256
Iteration 73, loss = 0.00672979
Iteration 74, loss = 0.00660051
Iteration 75, loss = 0.00658148
Iteration 76, loss = 0.00650390
Iteration 77, loss = 0.00640752
Iteration 78, loss = 0.00639973
Iteration 79, loss = 0.00636632
Iteration 80, loss = 0.00622901
Iteration 81, loss = 0.00619107
Iteration 82, loss = 0.00615314
Iteration 83, loss = 0.00618491
Iteration 84, loss = 0.00610805
Iteration 85, loss = 0.00613941
Iteration 86, loss = 0.00599380
Iteration 87, loss = 0.00592439
Iteration 88, loss = 0.00594496
Iteration 89, loss = 0.00586630
Iteration 90, loss = 0.00581659
Iteration 91, loss = 0.00576873
Iteration 92, loss = 0.00582432
Iteration 93, loss = 0.00571487
Iteration 94, loss = 0.00569428
Iteration 95, loss = 0.00571413
Iteration 96, loss = 0.00562748
Iteration 97, loss = 0.00560841
Iteration 98, loss = 0.00564537
Iteration 99, loss = 0.00566970
Iteration 100, loss = 0.00553437
Iteration 101, loss = 0.00553497
Iteration 102, loss = 0.00556989
Iteration 103, loss = 0.00542685
Iteration 104, loss = 0.00543510
Iteration 105, loss = 0.00545670
Iteration 106, loss = 0.00542954
Iteration 107, loss = 0.00537398
Iteration 108, loss = 0.00538275
Iteration 109, loss = 0.00527521
Iteration 110, loss = 0.00532189
Iteration 111, loss = 0.00524779
Iteration 112, loss = 0.00521780
Iteration 113, loss = 0.00526841
Iteration 114, loss = 0.00520729
Iteration 115, loss = 0.00517054
Iteration 116, loss = 0.00519430
Iteration 117, loss = 0.00524625
Iteration 118, loss = 0.00519452
Iteration 119, loss = 0.00510103
Iteration 120, loss = 0.00510971
Iteration 121, loss = 0.00514285
Iteration 122, loss = 0.00512450
Iteration 123, loss = 0.00507056
Iteration 124, loss = 0.00504973
Iteration 125, loss = 0.00505434
Iteration 126, loss = 0.00498571
Iteration 127, loss = 0.00503186
Iteration 128, loss = 0.00505032
Iteration 129, loss = 0.00502422
Iteration 130, loss = 0.00495494
Iteration 131, loss = 0.00491866
Iteration 132, loss = 0.00492730
Iteration 133, loss = 0.00497638
Iteration 134, loss = 0.00494730
Iteration 135, loss = 0.00497656
Iteration 136, loss = 0.00495477
Iteration 137, loss = 0.00491274
Iteration 138, loss = 0.00494052
Iteration 139, loss = 0.00493244
Iteration 140, loss = 0.00487249
Iteration 141, loss = 0.00484265
Iteration 142, loss = 0.00487784
Iteration 143, loss = 0.00488768
Iteration 144, loss = 0.00485612
Iteration 145, loss = 0.00484858
Iteration 146, loss = 0.00476346
Iteration 147, loss = 0.00480920
Iteration 148, loss = 0.00483287
Iteration 149, loss = 0.00481044
Iteration 150, loss = 0.00484062
Iteration 151, loss = 0.00483441
Iteration 152, loss = 0.00477707
Iteration 153, loss = 0.00475911
Iteration 154, loss = 0.00494114
Iteration 155, loss = 0.00473265
Iteration 156, loss = 0.00476240
Iteration 157, loss = 0.00477099
Iteration 158, loss = 0.00469020
Iteration 159, loss = 0.00476380
Iteration 160, loss = 0.00477885
Iteration 161, loss = 0.00468249
Iteration 162, loss = 0.00472053
Iteration 163, loss = 0.00466323
Iteration 164, loss = 0.00463587
Iteration 165, loss = 0.00472375
Iteration 166, loss = 0.00473633
Iteration 167, loss = 0.00468449
Iteration 168, loss = 0.00466667
Iteration 169, loss = 0.00475483
Iteration 170, loss = 0.00465104
Iteration 171, loss = 0.00471944
Iteration 172, loss = 0.00468516
Iteration 173, loss = 0.00473995
Iteration 174, loss = 0.00461948
Iteration 175, loss = 0.00470771
Iteration 176, loss = 0.00458463
Iteration 177, loss = 0.00463056
Iteration 178, loss = 0.00472055
Iteration 179, loss = 0.00459871
Iteration 180, loss = 0.00459032
Iteration 181, loss = 0.00468142
Iteration 182, loss = 0.00461457
Iteration 183, loss = 0.00451815
Iteration 184, loss = 0.00470261
Iteration 185, loss = 0.00462726
Iteration 186, loss = 0.00459023
Iteration 187, loss = 0.00460862
Iteration 188, loss = 0.00460396
Iteration 189, loss = 0.00460839
Iteration 190, loss = 0.00462869
Iteration 191, loss = 0.00460499
Iteration 192, loss = 0.00456240
Iteration 193, loss = 0.00457585
Iteration 194, loss = 0.00466324
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.15446701
Iteration 2, loss = 0.06429042
Iteration 3, loss = 0.05353284
Iteration 4, loss = 0.04646921
Iteration 5, loss = 0.04103661
Iteration 6, loss = 0.03678495
Iteration 7, loss = 0.03349812
Iteration 8, loss = 0.03089556
Iteration 9, loss = 0.02884824
Iteration 10, loss = 0.02709815
Iteration 11, loss = 0.02557019
Iteration 12, loss = 0.02440965
Iteration 13, loss = 0.02313730
Iteration 14, loss = 0.02223816
Iteration 15, loss = 0.02127890
Iteration 16, loss = 0.02041898
Iteration 17, loss = 0.01982423
Iteration 18, loss = 0.01909242
Iteration 19, loss = 0.01836917
Iteration 20, loss = 0.01776244
Iteration 21, loss = 0.01730163
Iteration 22, loss = 0.01664444
Iteration 23, loss = 0.01617735
Iteration 24, loss = 0.01572824
Iteration 25, loss = 0.01537931
Iteration 26, loss = 0.01495233
Iteration 27, loss = 0.01447258
Iteration 28, loss = 0.01413064
Iteration 29, loss = 0.01378690
Iteration 30, loss = 0.01352103
Iteration 31, loss = 0.01316768
Iteration 32, loss = 0.01278910
Iteration 33, loss = 0.01267624
Iteration 34, loss = 0.01240125
Iteration 35, loss = 0.01213474
Iteration 36, loss = 0.01182070
Iteration 37, loss = 0.01155910
Iteration 38, loss = 0.01139550
Iteration 39, loss = 0.01118523
Iteration 40, loss = 0.01089372
Iteration 41, loss = 0.01083440
Iteration 42, loss = 0.01057865
Iteration 43, loss = 0.01033843
Iteration 44, loss = 0.01019211
Iteration 45, loss = 0.00998951
Iteration 46, loss = 0.00985564
Iteration 47, loss = 0.00969128
Iteration 48, loss = 0.00950273
Iteration 49, loss = 0.00941581
Iteration 50, loss = 0.00918124
Iteration 51, loss = 0.00905049
Iteration 52, loss = 0.00890803
Iteration 53, loss = 0.00873834
Iteration 54, loss = 0.00868862
Iteration 55, loss = 0.00864316
Iteration 56, loss = 0.00845130
Iteration 57, loss = 0.00828222
Iteration 58, loss = 0.00821857
Iteration 59, loss = 0.00819128
Iteration 60, loss = 0.00805837
Iteration 61, loss = 0.00791675
Iteration 62, loss = 0.00777065
Iteration 63, loss = 0.00784533
Iteration 64, loss = 0.00757807
Iteration 65, loss = 0.00749437
Iteration 66, loss = 0.00753615
Iteration 67, loss = 0.00738359
Iteration 68, loss = 0.00724737
Iteration 69, loss = 0.00720861
Iteration 70, loss = 0.00712293
Iteration 71, loss = 0.00713683
Iteration 72, loss = 0.00699341
Iteration 73, loss = 0.00693860
Iteration 74, loss = 0.00687823
Iteration 75, loss = 0.00679620
Iteration 76, loss = 0.00679106
Iteration 77, loss = 0.00667949
Iteration 78, loss = 0.00671534
Iteration 79, loss = 0.00664675
Iteration 80, loss = 0.00644072
Iteration 81, loss = 0.00648537
Iteration 82, loss = 0.00640710
Iteration 83, loss = 0.00640093
Iteration 84, loss = 0.00634036
Iteration 85, loss = 0.00620428
Iteration 86, loss = 0.00629221
Iteration 87, loss = 0.00623189
Iteration 88, loss = 0.00608516
Iteration 89, loss = 0.00608810
Iteration 90, loss = 0.00618212
Iteration 91, loss = 0.00600374
Iteration 92, loss = 0.00591992
Iteration 93, loss = 0.00598178
Iteration 94, loss = 0.00594597
Iteration 95, loss = 0.00597292
Iteration 96, loss = 0.00585804
Iteration 97, loss = 0.00577825
Iteration 98, loss = 0.00581014
Iteration 99, loss = 0.00570725
Iteration 100, loss = 0.00576183
Iteration 101, loss = 0.00575667
Iteration 102, loss = 0.00571629
Iteration 103, loss = 0.00559238
Iteration 104, loss = 0.00574930
Iteration 105, loss = 0.00559128
Iteration 106, loss = 0.00554488
Iteration 107, loss = 0.00561851
Iteration 108, loss = 0.00553657
Iteration 109, loss = 0.00551572
Iteration 110, loss = 0.00552524
Iteration 111, loss = 0.00548143
Iteration 112, loss = 0.00542938
Iteration 113, loss = 0.00548930
Iteration 114, loss = 0.00535180
Iteration 115, loss = 0.00544080
Iteration 116, loss = 0.00542454
Iteration 117, loss = 0.00529270
Iteration 118, loss = 0.00535137
Iteration 119, loss = 0.00529389
Iteration 120, loss = 0.00531591
Iteration 121, loss = 0.00525679
Iteration 122, loss = 0.00525056
Iteration 123, loss = 0.00522322
Iteration 124, loss = 0.00525027
Iteration 125, loss = 0.00521655
Iteration 126, loss = 0.00526100
Iteration 127, loss = 0.00515787
Iteration 128, loss = 0.00519813
Iteration 129, loss = 0.00511123
Iteration 130, loss = 0.00517653
Iteration 131, loss = 0.00512640
Iteration 132, loss = 0.00511992
Iteration 133, loss = 0.00509444
Iteration 134, loss = 0.00513210
Iteration 135, loss = 0.00518063
Iteration 136, loss = 0.00503899
Iteration 137, loss = 0.00502248
Iteration 138, loss = 0.00500717
Iteration 139, loss = 0.00515991
Iteration 140, loss = 0.00506251
Iteration 141, loss = 0.00503113
Iteration 142, loss = 0.00499747
Iteration 143, loss = 0.00499737
Iteration 144, loss = 0.00496753
Iteration 145, loss = 0.00496565
Iteration 146, loss = 0.00495131
Iteration 147, loss = 0.00505190
Iteration 148, loss = 0.00491121
Iteration 149, loss = 0.00493749
Iteration 150, loss = 0.00492289
Iteration 151, loss = 0.00495700
Iteration 152, loss = 0.00491466
Iteration 153, loss = 0.00489823
Iteration 154, loss = 0.00494203
Iteration 155, loss = 0.00487646
Iteration 156, loss = 0.00490369
Iteration 157, loss = 0.00489454
Iteration 158, loss = 0.00491684
Iteration 159, loss = 0.00487734
Iteration 160, loss = 0.00488117
Iteration 161, loss = 0.00480534
Iteration 162, loss = 0.00484062
Iteration 163, loss = 0.00481691
Iteration 164, loss = 0.00477684
Iteration 165, loss = 0.00481704
Iteration 166, loss = 0.00492794
Iteration 167, loss = 0.00485433
Iteration 168, loss = 0.00474947
Iteration 169, loss = 0.00487475
Iteration 170, loss = 0.00478294
Iteration 171, loss = 0.00478228
Iteration 172, loss = 0.00477234
Iteration 173, loss = 0.00478650
Iteration 174, loss = 0.00475586
Iteration 175, loss = 0.00476630
Iteration 176, loss = 0.00484193
Iteration 177, loss = 0.00484565
Iteration 178, loss = 0.00478119
Iteration 179, loss = 0.00472033
Iteration 180, loss = 0.00475940
Iteration 181, loss = 0.00475206
Iteration 182, loss = 0.00473448
Iteration 183, loss = 0.00481209
Iteration 184, loss = 0.00473919
Iteration 185, loss = 0.00475268
Iteration 186, loss = 0.00468557
Iteration 187, loss = 0.00465886
Iteration 188, loss = 0.00473535
Iteration 189, loss = 0.00475435
Iteration 190, loss = 0.00478291
Iteration 191, loss = 0.00467630
Iteration 192, loss = 0.00476737
Iteration 193, loss = 0.00464970
Iteration 194, loss = 0.00479150
Iteration 195, loss = 0.00462316
Iteration 196, loss = 0.00466141
Iteration 197, loss = 0.00477312
Iteration 198, loss = 0.00465842
Iteration 199, loss = 0.00473545
Iteration 200, loss = 0.00465547
Iteration 1, loss = 0.12789001
Iteration 2, loss = 0.06216757
Iteration 3, loss = 0.05147411
Iteration 4, loss = 0.04353732
Iteration 5, loss = 0.03793118
Iteration 6, loss = 0.03386851
Iteration 7, loss = 0.03067277
Iteration 8, loss = 0.02826918
Iteration 9, loss = 0.02639755
Iteration 10, loss = 0.02461680
Iteration 11, loss = 0.02344568
Iteration 12, loss = 0.02216271
Iteration 13, loss = 0.02121768
Iteration 14, loss = 0.02027958
Iteration 15, loss = 0.01941588
Iteration 16, loss = 0.01864497
Iteration 17, loss = 0.01822955
Iteration 18, loss = 0.01741873
Iteration 19, loss = 0.01662172
Iteration 20, loss = 0.01622224
Iteration 21, loss = 0.01559718
Iteration 22, loss = 0.01529269
Iteration 23, loss = 0.01480150
Iteration 24, loss = 0.01429559
Iteration 25, loss = 0.01393523
Iteration 26, loss = 0.01362349
Iteration 27, loss = 0.01308221
Iteration 28, loss = 0.01282292
Iteration 29, loss = 0.01245325
Iteration 30, loss = 0.01213103
Iteration 31, loss = 0.01190416
Iteration 32, loss = 0.01154724
Iteration 33, loss = 0.01131022
Iteration 34, loss = 0.01101380
Iteration 35, loss = 0.01062977
Iteration 36, loss = 0.01051921
Iteration 37, loss = 0.01037169
Iteration 38, loss = 0.01005150
Iteration 39, loss = 0.00977509
Iteration 40, loss = 0.00960918
Iteration 41, loss = 0.00944012
Iteration 42, loss = 0.00915885
Iteration 43, loss = 0.00912904
Iteration 44, loss = 0.00874714
Iteration 45, loss = 0.00878466
Iteration 46, loss = 0.00854794
Iteration 47, loss = 0.00845979
Iteration 48, loss = 0.00827662
Iteration 49, loss = 0.00802946
Iteration 50, loss = 0.00803241
Iteration 51, loss = 0.00782929
Iteration 52, loss = 0.00775805
Iteration 53, loss = 0.00762618
Iteration 54, loss = 0.00753644
Iteration 55, loss = 0.00740681
Iteration 56, loss = 0.00733376
Iteration 57, loss = 0.00716977
Iteration 58, loss = 0.00710767
Iteration 59, loss = 0.00694772
Iteration 60, loss = 0.00686759
Iteration 61, loss = 0.00687011
Iteration 62, loss = 0.00663578
Iteration 63, loss = 0.00664555
Iteration 64, loss = 0.00661297
Iteration 65, loss = 0.00654604
Iteration 66, loss = 0.00637575
Iteration 67, loss = 0.00631584
Iteration 68, loss = 0.00628699
Iteration 69, loss = 0.00625582
Iteration 70, loss = 0.00609740
Iteration 71, loss = 0.00605717
Iteration 72, loss = 0.00597076
Iteration 73, loss = 0.00603252
Iteration 74, loss = 0.00594905
Iteration 75, loss = 0.00591984
Iteration 76, loss = 0.00581066
Iteration 77, loss = 0.00587888
Iteration 78, loss = 0.00578827
Iteration 79, loss = 0.00565055
Iteration 80, loss = 0.00561604
Iteration 81, loss = 0.00563357
Iteration 82, loss = 0.00565610
Iteration 83, loss = 0.00559135
Iteration 84, loss = 0.00561075
Iteration 85, loss = 0.00545311
Iteration 86, loss = 0.00554472
Iteration 87, loss = 0.00541106
Iteration 88, loss = 0.00540070
Iteration 89, loss = 0.00539237
Iteration 90, loss = 0.00541190
Iteration 91, loss = 0.00536340
Iteration 92, loss = 0.00536073
Iteration 93, loss = 0.00518442
Iteration 94, loss = 0.00528541
Iteration 95, loss = 0.00526233
Iteration 96, loss = 0.00525849
Iteration 97, loss = 0.00518273
Iteration 98, loss = 0.00517980
Iteration 99, loss = 0.00511509
Iteration 100, loss = 0.00506203
Iteration 101, loss = 0.00513229
Iteration 102, loss = 0.00511899
Iteration 103, loss = 0.00524320
Iteration 104, loss = 0.00508786
Iteration 105, loss = 0.00505160
Iteration 106, loss = 0.00503465
Iteration 107, loss = 0.00501017
Iteration 108, loss = 0.00497945
Iteration 109, loss = 0.00498557
Iteration 110, loss = 0.00496201
Iteration 111, loss = 0.00494051
Iteration 112, loss = 0.00507043
Iteration 113, loss = 0.00491367
Iteration 114, loss = 0.00490543
Iteration 115, loss = 0.00491819
Iteration 116, loss = 0.00490033
Iteration 117, loss = 0.00490400
Iteration 118, loss = 0.00486295
Iteration 119, loss = 0.00489516
Iteration 120, loss = 0.00483440
Iteration 121, loss = 0.00487164
Iteration 122, loss = 0.00480020
Iteration 123, loss = 0.00482287
Iteration 124, loss = 0.00480304
Iteration 125, loss = 0.00487619
Iteration 126, loss = 0.00476597
Iteration 127, loss = 0.00470889
Iteration 128, loss = 0.00477442
Iteration 129, loss = 0.00474103
Iteration 130, loss = 0.00469173
Iteration 131, loss = 0.00470707
Iteration 132, loss = 0.00480772
Iteration 133, loss = 0.00486859
Iteration 134, loss = 0.00465510
Iteration 135, loss = 0.00471290
Iteration 136, loss = 0.00475696
Iteration 137, loss = 0.00464897
Iteration 138, loss = 0.00468535
Iteration 139, loss = 0.00474210
Iteration 140, loss = 0.00470274
Iteration 141, loss = 0.00464204
Iteration 142, loss = 0.00455876
Iteration 143, loss = 0.00480182
Iteration 144, loss = 0.00468632
Iteration 145, loss = 0.00468798
Iteration 146, loss = 0.00465019
Iteration 147, loss = 0.00459027
Iteration 148, loss = 0.00460097
Iteration 149, loss = 0.00465193
Iteration 150, loss = 0.00472821
Iteration 151, loss = 0.00455578
Iteration 152, loss = 0.00462628
Iteration 153, loss = 0.00455289
Iteration 154, loss = 0.00467931
Iteration 155, loss = 0.00459981
Iteration 156, loss = 0.00453044
Iteration 157, loss = 0.00455496
Iteration 158, loss = 0.00455682
Iteration 159, loss = 0.00464587
Iteration 160, loss = 0.00452387
Iteration 161, loss = 0.00458109
Iteration 162, loss = 0.00457107
Iteration 163, loss = 0.00460869
Iteration 164, loss = 0.00460776
Iteration 165, loss = 0.00452831
Iteration 166, loss = 0.00455867
Iteration 167, loss = 0.00447627
Iteration 168, loss = 0.00456144
Iteration 169, loss = 0.00460718
Iteration 170, loss = 0.00448576
Iteration 171, loss = 0.00449826
Iteration 172, loss = 0.00456417
Iteration 173, loss = 0.00442438
Iteration 174, loss = 0.00450139
Iteration 175, loss = 0.00471866
Iteration 176, loss = 0.00447054
Iteration 177, loss = 0.00453733
Iteration 178, loss = 0.00453725
Iteration 179, loss = 0.00447686
Iteration 180, loss = 0.00443482
Iteration 181, loss = 0.00447574
Iteration 182, loss = 0.00447506
Iteration 183, loss = 0.00448633
Iteration 184, loss = 0.00445654
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13951920
Iteration 2, loss = 0.06367829
Iteration 3, loss = 0.05404925
Iteration 4, loss = 0.04564336
Iteration 5, loss = 0.03955582
Iteration 6, loss = 0.03537549
Iteration 7, loss = 0.03200967
Iteration 8, loss = 0.02925649
Iteration 9, loss = 0.02716362
Iteration 10, loss = 0.02531174
Iteration 11, loss = 0.02388651
Iteration 12, loss = 0.02254772
Iteration 13, loss = 0.02132708
Iteration 14, loss = 0.02034268
Iteration 15, loss = 0.01942845
Iteration 16, loss = 0.01864989
Iteration 17, loss = 0.01797632
Iteration 18, loss = 0.01724586
Iteration 19, loss = 0.01657231
Iteration 20, loss = 0.01603661
Iteration 21, loss = 0.01557819
Iteration 22, loss = 0.01520157
Iteration 23, loss = 0.01455662
Iteration 24, loss = 0.01409552
Iteration 25, loss = 0.01378426
Iteration 26, loss = 0.01346235
Iteration 27, loss = 0.01301662
Iteration 28, loss = 0.01272403
Iteration 29, loss = 0.01235260
Iteration 30, loss = 0.01217430
Iteration 31, loss = 0.01167831
Iteration 32, loss = 0.01148271
Iteration 33, loss = 0.01129020
Iteration 34, loss = 0.01086005
Iteration 35, loss = 0.01067071
Iteration 36, loss = 0.01043770
Iteration 37, loss = 0.01025991
Iteration 38, loss = 0.00997245
Iteration 39, loss = 0.00983748
Iteration 40, loss = 0.00956580
Iteration 41, loss = 0.00946512
Iteration 42, loss = 0.00933582
Iteration 43, loss = 0.00916905
Iteration 44, loss = 0.00895043
Iteration 45, loss = 0.00875885
Iteration 46, loss = 0.00851929
Iteration 47, loss = 0.00846228
Iteration 48, loss = 0.00832014
Iteration 49, loss = 0.00812624
Iteration 50, loss = 0.00808304
Iteration 51, loss = 0.00794468
Iteration 52, loss = 0.00783782
Iteration 53, loss = 0.00770062
Iteration 54, loss = 0.00767500
Iteration 55, loss = 0.00743494
Iteration 56, loss = 0.00735534
Iteration 57, loss = 0.00720044
Iteration 58, loss = 0.00719482
Iteration 59, loss = 0.00709730
Iteration 60, loss = 0.00693691
Iteration 61, loss = 0.00691425
Iteration 62, loss = 0.00696755
Iteration 63, loss = 0.00674196
Iteration 64, loss = 0.00665207
Iteration 65, loss = 0.00659312
Iteration 66, loss = 0.00665873
Iteration 67, loss = 0.00642646
Iteration 68, loss = 0.00641785
Iteration 69, loss = 0.00635668
Iteration 70, loss = 0.00635960
Iteration 71, loss = 0.00625362
Iteration 72, loss = 0.00620486
Iteration 73, loss = 0.00615890
Iteration 74, loss = 0.00617424
Iteration 75, loss = 0.00596745
Iteration 76, loss = 0.00598700
Iteration 77, loss = 0.00590578
Iteration 78, loss = 0.00598742
Iteration 79, loss = 0.00587505
Iteration 80, loss = 0.00580847
Iteration 81, loss = 0.00576639
Iteration 82, loss = 0.00574602
Iteration 83, loss = 0.00566953
Iteration 84, loss = 0.00560534
Iteration 85, loss = 0.00571995
Iteration 86, loss = 0.00561718
Iteration 87, loss = 0.00555463
Iteration 88, loss = 0.00550459
Iteration 89, loss = 0.00542532
Iteration 90, loss = 0.00549292
Iteration 91, loss = 0.00546394
Iteration 92, loss = 0.00535894
Iteration 93, loss = 0.00541395
Iteration 94, loss = 0.00538685
Iteration 95, loss = 0.00528625
Iteration 96, loss = 0.00527348
Iteration 97, loss = 0.00541655
Iteration 98, loss = 0.00523854
Iteration 99, loss = 0.00531200
Iteration 100, loss = 0.00527858
Iteration 101, loss = 0.00515871
Iteration 102, loss = 0.00514241
Iteration 103, loss = 0.00512979
Iteration 104, loss = 0.00512752
Iteration 105, loss = 0.00516140
Iteration 106, loss = 0.00525715
Iteration 107, loss = 0.00507845
Iteration 108, loss = 0.00509951
Iteration 109, loss = 0.00502864
Iteration 110, loss = 0.00506335
Iteration 111, loss = 0.00502060
Iteration 112, loss = 0.00494384
Iteration 113, loss = 0.00501191
Iteration 114, loss = 0.00486444
Iteration 115, loss = 0.00504099
Iteration 116, loss = 0.00514330
Iteration 117, loss = 0.00501115
Iteration 118, loss = 0.00496020
Iteration 119, loss = 0.00496282
Iteration 120, loss = 0.00492239
Iteration 121, loss = 0.00483406
Iteration 122, loss = 0.00493268
Iteration 123, loss = 0.00488839
Iteration 124, loss = 0.00489540
Iteration 125, loss = 0.00491773
Iteration 126, loss = 0.00491466
Iteration 127, loss = 0.00478346
Iteration 128, loss = 0.00492541
Iteration 129, loss = 0.00487303
Iteration 130, loss = 0.00484848
Iteration 131, loss = 0.00483617
Iteration 132, loss = 0.00484755
Iteration 133, loss = 0.00477654
Iteration 134, loss = 0.00480611
Iteration 135, loss = 0.00472166
Iteration 136, loss = 0.00483947
Iteration 137, loss = 0.00480705
Iteration 138, loss = 0.00475239
Iteration 139, loss = 0.00470203
Iteration 140, loss = 0.00476834
Iteration 141, loss = 0.00476421
Iteration 142, loss = 0.00478843
Iteration 143, loss = 0.00465924
Iteration 144, loss = 0.00470105
Iteration 145, loss = 0.00474110
Iteration 146, loss = 0.00472766
Iteration 147, loss = 0.00467975
Iteration 148, loss = 0.00470016
Iteration 149, loss = 0.00466823
Iteration 150, loss = 0.00478439
Iteration 151, loss = 0.00457853
Iteration 152, loss = 0.00468656
Iteration 153, loss = 0.00484137
Iteration 154, loss = 0.00463816
Iteration 155, loss = 0.00458022
Iteration 156, loss = 0.00469708
Iteration 157, loss = 0.00457664
Iteration 158, loss = 0.00463877
Iteration 159, loss = 0.00468500
Iteration 160, loss = 0.00470842
Iteration 161, loss = 0.00461126
Iteration 162, loss = 0.00474001
Iteration 163, loss = 0.00468940
Iteration 164, loss = 0.00456213
Iteration 165, loss = 0.00454451
Iteration 166, loss = 0.00468310
Iteration 167, loss = 0.00460935
Iteration 168, loss = 0.00450001
Iteration 169, loss = 0.00468611
Iteration 170, loss = 0.00453992
Iteration 171, loss = 0.00460726
Iteration 172, loss = 0.00454018
Iteration 173, loss = 0.00453810
Iteration 174, loss = 0.00458908
Iteration 175, loss = 0.00464481
Iteration 176, loss = 0.00450639
Iteration 177, loss = 0.00451441
Iteration 178, loss = 0.00468749
Iteration 179, loss = 0.00454276
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13233692
Iteration 2, loss = 0.06184710
Iteration 3, loss = 0.05145209
Iteration 4, loss = 0.04367889
Iteration 5, loss = 0.03783923
Iteration 6, loss = 0.03384150
Iteration 7, loss = 0.03070765
Iteration 8, loss = 0.02854716
Iteration 9, loss = 0.02676745
Iteration 10, loss = 0.02522269
Iteration 11, loss = 0.02384358
Iteration 12, loss = 0.02269737
Iteration 13, loss = 0.02155817
Iteration 14, loss = 0.02052683
Iteration 15, loss = 0.01964641
Iteration 16, loss = 0.01893070
Iteration 17, loss = 0.01815331
Iteration 18, loss = 0.01756621
Iteration 19, loss = 0.01691770
Iteration 20, loss = 0.01635111
Iteration 21, loss = 0.01573594
Iteration 22, loss = 0.01531906
Iteration 23, loss = 0.01494056
Iteration 24, loss = 0.01441456
Iteration 25, loss = 0.01400105
Iteration 26, loss = 0.01355869
Iteration 27, loss = 0.01332180
Iteration 28, loss = 0.01278996
Iteration 29, loss = 0.01259110
Iteration 30, loss = 0.01231224
Iteration 31, loss = 0.01196708
Iteration 32, loss = 0.01173246
Iteration 33, loss = 0.01141814
Iteration 34, loss = 0.01112529
Iteration 35, loss = 0.01103949
Iteration 36, loss = 0.01064516
Iteration 37, loss = 0.01046776
Iteration 38, loss = 0.01024528
Iteration 39, loss = 0.00996319
Iteration 40, loss = 0.00982375
Iteration 41, loss = 0.00972736
Iteration 42, loss = 0.00945072
Iteration 43, loss = 0.00925639
Iteration 44, loss = 0.00910553
Iteration 45, loss = 0.00887990
Iteration 46, loss = 0.00869086
Iteration 47, loss = 0.00872681
Iteration 48, loss = 0.00853220
Iteration 49, loss = 0.00833618
Iteration 50, loss = 0.00825757
Iteration 51, loss = 0.00808257
Iteration 52, loss = 0.00789875
Iteration 53, loss = 0.00784789
Iteration 54, loss = 0.00783732
Iteration 55, loss = 0.00758216
Iteration 56, loss = 0.00753675
Iteration 57, loss = 0.00735656
Iteration 58, loss = 0.00727440
Iteration 59, loss = 0.00711497
Iteration 60, loss = 0.00704073
Iteration 61, loss = 0.00699444
Iteration 62, loss = 0.00691517
Iteration 63, loss = 0.00690984
Iteration 64, loss = 0.00678259
Iteration 65, loss = 0.00663370
Iteration 66, loss = 0.00653327
Iteration 67, loss = 0.00654442
Iteration 68, loss = 0.00654261
Iteration 69, loss = 0.00642755
Iteration 70, loss = 0.00638773
Iteration 71, loss = 0.00628075
Iteration 72, loss = 0.00614153
Iteration 73, loss = 0.00623211
Iteration 74, loss = 0.00609116
Iteration 75, loss = 0.00599811
Iteration 76, loss = 0.00596234
Iteration 77, loss = 0.00596647
Iteration 78, loss = 0.00584129
Iteration 79, loss = 0.00594382
Iteration 80, loss = 0.00572809
Iteration 81, loss = 0.00573373
Iteration 82, loss = 0.00570070
Iteration 83, loss = 0.00573695
Iteration 84, loss = 0.00564339
Iteration 85, loss = 0.00557531
Iteration 86, loss = 0.00561255
Iteration 87, loss = 0.00553788
Iteration 88, loss = 0.00554361
Iteration 89, loss = 0.00542534
Iteration 90, loss = 0.00537181
Iteration 91, loss = 0.00545042
Iteration 92, loss = 0.00541329
Iteration 93, loss = 0.00527867
Iteration 94, loss = 0.00530516
Iteration 95, loss = 0.00530402
Iteration 96, loss = 0.00532717
Iteration 97, loss = 0.00525044
Iteration 98, loss = 0.00522773
Iteration 99, loss = 0.00524806
Iteration 100, loss = 0.00513839
Iteration 101, loss = 0.00514564
Iteration 102, loss = 0.00519259
Iteration 103, loss = 0.00513770
Iteration 104, loss = 0.00510291
Iteration 105, loss = 0.00503625
Iteration 106, loss = 0.00505427
Iteration 107, loss = 0.00512890
Iteration 108, loss = 0.00500579
Iteration 109, loss = 0.00499536
Iteration 110, loss = 0.00511191
Iteration 111, loss = 0.00498143
Iteration 112, loss = 0.00493154
Iteration 113, loss = 0.00494943
Iteration 114, loss = 0.00489493
Iteration 115, loss = 0.00503646
Iteration 116, loss = 0.00481020
Iteration 117, loss = 0.00493014
Iteration 118, loss = 0.00491169
Iteration 119, loss = 0.00488080
Iteration 120, loss = 0.00487125
Iteration 121, loss = 0.00486650
Iteration 122, loss = 0.00491501
Iteration 123, loss = 0.00479373
Iteration 124, loss = 0.00482847
Iteration 125, loss = 0.00475484
Iteration 126, loss = 0.00482574
Iteration 127, loss = 0.00486673
Iteration 128, loss = 0.00482273
Iteration 129, loss = 0.00475049
Iteration 130, loss = 0.00476886
Iteration 131, loss = 0.00485854
Iteration 132, loss = 0.00469520
Iteration 133, loss = 0.00477242
Iteration 134, loss = 0.00481496
Iteration 135, loss = 0.00478137
Iteration 136, loss = 0.00475838
Iteration 137, loss = 0.00466565
Iteration 138, loss = 0.00470853
Iteration 139, loss = 0.00461623
Iteration 140, loss = 0.00464627
Iteration 141, loss = 0.00471751
Iteration 142, loss = 0.00465578
Iteration 143, loss = 0.00460964
Iteration 144, loss = 0.00477588
Iteration 145, loss = 0.00466287
Iteration 146, loss = 0.00468909
Iteration 147, loss = 0.00465058
Iteration 148, loss = 0.00468984
Iteration 149, loss = 0.00471105
Iteration 150, loss = 0.00463522
Iteration 151, loss = 0.00465737
Iteration 152, loss = 0.00463593
Iteration 153, loss = 0.00460254
Iteration 154, loss = 0.00453792
Iteration 155, loss = 0.00475817
Iteration 156, loss = 0.00456558
Iteration 157, loss = 0.00462905
Iteration 158, loss = 0.00458840
Iteration 159, loss = 0.00458254
Iteration 160, loss = 0.00455799
Iteration 161, loss = 0.00471832
Iteration 162, loss = 0.00455402
Iteration 163, loss = 0.00450008
Iteration 164, loss = 0.00454293
Iteration 165, loss = 0.00456691
Iteration 166, loss = 0.00462628
Iteration 167, loss = 0.00448515
Iteration 168, loss = 0.00452779
Iteration 169, loss = 0.00464471
Iteration 170, loss = 0.00457444
Iteration 171, loss = 0.00455024
Iteration 172, loss = 0.00444314
Iteration 173, loss = 0.00452797
Iteration 174, loss = 0.00451652
Iteration 175, loss = 0.00453328
Iteration 176, loss = 0.00465800
Iteration 177, loss = 0.00457193
Iteration 178, loss = 0.00441979
Iteration 179, loss = 0.00453389
Iteration 180, loss = 0.00454741
Iteration 181, loss = 0.00449051
Iteration 182, loss = 0.00442973
Iteration 183, loss = 0.00446808
Iteration 184, loss = 0.00455770
Iteration 185, loss = 0.00443997
Iteration 186, loss = 0.00451802
Iteration 187, loss = 0.00446797
Iteration 188, loss = 0.00449377
Iteration 189, loss = 0.00447938
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.13103973
Iteration 2, loss = 0.06101224
Iteration 3, loss = 0.05076014
Iteration 4, loss = 0.04346132
Iteration 5, loss = 0.03807141
Iteration 6, loss = 0.03407940
Iteration 7, loss = 0.03093104
Iteration 8, loss = 0.02848575
Iteration 9, loss = 0.02645697
Iteration 10, loss = 0.02468599
Iteration 11, loss = 0.02337145
Iteration 12, loss = 0.02218865
Iteration 13, loss = 0.02119024
Iteration 14, loss = 0.02011552
Iteration 15, loss = 0.01927788
Iteration 16, loss = 0.01854496
Iteration 17, loss = 0.01788705
Iteration 18, loss = 0.01728955
Iteration 19, loss = 0.01649534
Iteration 20, loss = 0.01604707
Iteration 21, loss = 0.01544303
Iteration 22, loss = 0.01493943
Iteration 23, loss = 0.01456006
Iteration 24, loss = 0.01397683
Iteration 25, loss = 0.01366691
Iteration 26, loss = 0.01331621
Iteration 27, loss = 0.01295815
Iteration 28, loss = 0.01259817
Iteration 29, loss = 0.01221283
Iteration 30, loss = 0.01197120
Iteration 31, loss = 0.01158058
Iteration 32, loss = 0.01126698
Iteration 33, loss = 0.01109764
Iteration 34, loss = 0.01079498
Iteration 35, loss = 0.01056579
Iteration 36, loss = 0.01021948
Iteration 37, loss = 0.01011496
Iteration 38, loss = 0.00978831
Iteration 39, loss = 0.00966309
Iteration 40, loss = 0.00937710
Iteration 41, loss = 0.00931167
Iteration 42, loss = 0.00901031
Iteration 43, loss = 0.00886516
Iteration 44, loss = 0.00877265
Iteration 45, loss = 0.00862973
Iteration 46, loss = 0.00839310
Iteration 47, loss = 0.00828773
Iteration 48, loss = 0.00819495
Iteration 49, loss = 0.00795257
Iteration 50, loss = 0.00787117
Iteration 51, loss = 0.00770408
Iteration 52, loss = 0.00770470
Iteration 53, loss = 0.00757085
Iteration 54, loss = 0.00749214
Iteration 55, loss = 0.00733916
Iteration 56, loss = 0.00718082
Iteration 57, loss = 0.00711061
Iteration 58, loss = 0.00716522
Iteration 59, loss = 0.00694427
Iteration 60, loss = 0.00693238
Iteration 61, loss = 0.00684630
Iteration 62, loss = 0.00674620
Iteration 63, loss = 0.00672735
Iteration 64, loss = 0.00650947
Iteration 65, loss = 0.00640266
Iteration 66, loss = 0.00650164
Iteration 67, loss = 0.00636749
Iteration 68, loss = 0.00630792
Iteration 69, loss = 0.00626324
Iteration 70, loss = 0.00618749
Iteration 71, loss = 0.00615618
Iteration 72, loss = 0.00601184
Iteration 73, loss = 0.00598538
Iteration 74, loss = 0.00593897
Iteration 75, loss = 0.00594597
Iteration 76, loss = 0.00594214
Iteration 77, loss = 0.00574359
Iteration 78, loss = 0.00582586
Iteration 79, loss = 0.00572697
Iteration 80, loss = 0.00571179
Iteration 81, loss = 0.00561268
Iteration 82, loss = 0.00571879
Iteration 83, loss = 0.00552672
Iteration 84, loss = 0.00553661
Iteration 85, loss = 0.00556782
Iteration 86, loss = 0.00556603
Iteration 87, loss = 0.00546165
Iteration 88, loss = 0.00541657
Iteration 89, loss = 0.00547830
Iteration 90, loss = 0.00528931
Iteration 91, loss = 0.00534207
Iteration 92, loss = 0.00532368
Iteration 93, loss = 0.00525774
Iteration 94, loss = 0.00528457
Iteration 95, loss = 0.00526960
Iteration 96, loss = 0.00523588
Iteration 97, loss = 0.00517897
Iteration 98, loss = 0.00511855
Iteration 99, loss = 0.00518266
Iteration 100, loss = 0.00523793
Iteration 101, loss = 0.00512161
Iteration 102, loss = 0.00511489
Iteration 103, loss = 0.00504438
Iteration 104, loss = 0.00506449
Iteration 105, loss = 0.00501693
Iteration 106, loss = 0.00504352
Iteration 107, loss = 0.00501752
Iteration 108, loss = 0.00505939
Iteration 109, loss = 0.00497135
Iteration 110, loss = 0.00499346
Iteration 111, loss = 0.00493598
Iteration 112, loss = 0.00495783
Iteration 113, loss = 0.00495611
Iteration 114, loss = 0.00481157
Iteration 115, loss = 0.00501227
Iteration 116, loss = 0.00499901
Iteration 117, loss = 0.00487121
Iteration 118, loss = 0.00484271
Iteration 119, loss = 0.00487968
Iteration 120, loss = 0.00489066
Iteration 121, loss = 0.00484296
Iteration 122, loss = 0.00494339
Iteration 123, loss = 0.00475238
Iteration 124, loss = 0.00480255
Iteration 125, loss = 0.00477165
Iteration 126, loss = 0.00476414
Iteration 127, loss = 0.00482793
Iteration 128, loss = 0.00470969
Iteration 129, loss = 0.00480246
Iteration 130, loss = 0.00473762
Iteration 131, loss = 0.00477544
Iteration 132, loss = 0.00478252
Iteration 133, loss = 0.00472792
Iteration 134, loss = 0.00473512
Iteration 135, loss = 0.00481646
Iteration 136, loss = 0.00472317
Iteration 137, loss = 0.00472255
Iteration 138, loss = 0.00463120
Iteration 139, loss = 0.00465191
Iteration 140, loss = 0.00473319
Iteration 141, loss = 0.00469481
Iteration 142, loss = 0.00466601
Iteration 143, loss = 0.00469909
Iteration 144, loss = 0.00461867
Iteration 145, loss = 0.00474374
Iteration 146, loss = 0.00457540
Iteration 147, loss = 0.00468299
Iteration 148, loss = 0.00458756
Iteration 149, loss = 0.00468148
Iteration 150, loss = 0.00469739
Iteration 151, loss = 0.00461834
Iteration 152, loss = 0.00465128
Iteration 153, loss = 0.00456868
Iteration 154, loss = 0.00455696
Iteration 155, loss = 0.00455765
Iteration 156, loss = 0.00470011
Iteration 157, loss = 0.00463009
Iteration 158, loss = 0.00448137
Iteration 159, loss = 0.00461938
Iteration 160, loss = 0.00459878
Iteration 161, loss = 0.00458763
Iteration 162, loss = 0.00460783
Iteration 163, loss = 0.00449300
Iteration 164, loss = 0.00452907
Iteration 165, loss = 0.00465208
Iteration 166, loss = 0.00456044
Iteration 167, loss = 0.00458234
Iteration 168, loss = 0.00444397
Iteration 169, loss = 0.00455470
Iteration 170, loss = 0.00467563
Iteration 171, loss = 0.00454444
Iteration 172, loss = 0.00443188
Iteration 173, loss = 0.00444907
Iteration 174, loss = 0.00449758
Iteration 175, loss = 0.00450820
Iteration 176, loss = 0.00462553
Iteration 177, loss = 0.00452023
Iteration 178, loss = 0.00441402
Iteration 179, loss = 0.00448370
Iteration 180, loss = 0.00444788
Iteration 181, loss = 0.00479178
Iteration 182, loss = 0.00445854
Iteration 183, loss = 0.00436366
Iteration 184, loss = 0.00442714
Iteration 185, loss = 0.00445651
Iteration 186, loss = 0.00454518
Iteration 187, loss = 0.00439106
Iteration 188, loss = 0.00464154
Iteration 189, loss = 0.00454826
Iteration 190, loss = 0.00446718
Iteration 191, loss = 0.00431132
Iteration 192, loss = 0.00430993
Iteration 193, loss = 0.00459504
Iteration 194, loss = 0.00440517
Iteration 195, loss = 0.00444325
Iteration 196, loss = 0.00442550
Iteration 197, loss = 0.00443490
Iteration 198, loss = 0.00445540
Iteration 199, loss = 0.00444546
Iteration 200, loss = 0.00436877
Iteration 1, loss = 0.12144989
Iteration 2, loss = 0.06007181
Iteration 3, loss = 0.04974030
Iteration 4, loss = 0.04173630
Iteration 5, loss = 0.03586851
Iteration 6, loss = 0.03203604
Iteration 7, loss = 0.02907188
Iteration 8, loss = 0.02682208
Iteration 9, loss = 0.02511230
Iteration 10, loss = 0.02353784
Iteration 11, loss = 0.02243195
Iteration 12, loss = 0.02121515
Iteration 13, loss = 0.02037984
Iteration 14, loss = 0.01942364
Iteration 15, loss = 0.01863502
Iteration 16, loss = 0.01799653
Iteration 17, loss = 0.01716983
Iteration 18, loss = 0.01652255
Iteration 19, loss = 0.01603446
Iteration 20, loss = 0.01544275
Iteration 21, loss = 0.01502237
Iteration 22, loss = 0.01431763
Iteration 23, loss = 0.01414595
Iteration 24, loss = 0.01356047
Iteration 25, loss = 0.01329407
Iteration 26, loss = 0.01279008
Iteration 27, loss = 0.01260756
Iteration 28, loss = 0.01213600
Iteration 29, loss = 0.01185695
Iteration 30, loss = 0.01159030
Iteration 31, loss = 0.01131866
Iteration 32, loss = 0.01107123
Iteration 33, loss = 0.01070790
Iteration 34, loss = 0.01059970
Iteration 35, loss = 0.01036269
Iteration 36, loss = 0.00998384
Iteration 37, loss = 0.00988136
Iteration 38, loss = 0.00967814
Iteration 39, loss = 0.00949069
Iteration 40, loss = 0.00926943
Iteration 41, loss = 0.00910297
Iteration 42, loss = 0.00891239
Iteration 43, loss = 0.00874300
Iteration 44, loss = 0.00851846
Iteration 45, loss = 0.00845991
Iteration 46, loss = 0.00835179
Iteration 47, loss = 0.00817960
Iteration 48, loss = 0.00803950
Iteration 49, loss = 0.00777817
Iteration 50, loss = 0.00786937
Iteration 51, loss = 0.00773491
Iteration 52, loss = 0.00747109
Iteration 53, loss = 0.00748883
Iteration 54, loss = 0.00737347
Iteration 55, loss = 0.00721123
Iteration 56, loss = 0.00720014
Iteration 57, loss = 0.00702624
Iteration 58, loss = 0.00709139
Iteration 59, loss = 0.00680221
Iteration 60, loss = 0.00678825
Iteration 61, loss = 0.00664962
Iteration 62, loss = 0.00666733
Iteration 63, loss = 0.00656720
Iteration 64, loss = 0.00649985
Iteration 65, loss = 0.00646565
Iteration 66, loss = 0.00635723
Iteration 67, loss = 0.00628195
Iteration 68, loss = 0.00620741
Iteration 69, loss = 0.00616731
Iteration 70, loss = 0.00611315
Iteration 71, loss = 0.00603994
Iteration 72, loss = 0.00603847
Iteration 73, loss = 0.00598437
Iteration 74, loss = 0.00595390
Iteration 75, loss = 0.00586282
Iteration 76, loss = 0.00589980
Iteration 77, loss = 0.00575263
Iteration 78, loss = 0.00581842
Iteration 79, loss = 0.00573961
Iteration 80, loss = 0.00564960
Iteration 81, loss = 0.00558932
Iteration 82, loss = 0.00555121
Iteration 83, loss = 0.00564161
Iteration 84, loss = 0.00550705
Iteration 85, loss = 0.00562464
Iteration 86, loss = 0.00541426
Iteration 87, loss = 0.00547803
Iteration 88, loss = 0.00541634
Iteration 89, loss = 0.00538712
Iteration 90, loss = 0.00536621
Iteration 91, loss = 0.00532595
Iteration 92, loss = 0.00531304
Iteration 93, loss = 0.00522642
Iteration 94, loss = 0.00535699
Iteration 95, loss = 0.00525074
Iteration 96, loss = 0.00517996
Iteration 97, loss = 0.00520721
Iteration 98, loss = 0.00513952
Iteration 99, loss = 0.00509749
Iteration 100, loss = 0.00514756
Iteration 101, loss = 0.00516812
Iteration 102, loss = 0.00517402
Iteration 103, loss = 0.00508997
Iteration 104, loss = 0.00506468
Iteration 105, loss = 0.00503654
Iteration 106, loss = 0.00507123
Iteration 107, loss = 0.00499883
Iteration 108, loss = 0.00501764
Iteration 109, loss = 0.00503388
Iteration 110, loss = 0.00502715
Iteration 111, loss = 0.00494083
Iteration 112, loss = 0.00493647
Iteration 113, loss = 0.00492789
Iteration 114, loss = 0.00496118
Iteration 115, loss = 0.00493578
Iteration 116, loss = 0.00496938
Iteration 117, loss = 0.00489253
Iteration 118, loss = 0.00489368
Iteration 119, loss = 0.00487130
Iteration 120, loss = 0.00492539
Iteration 121, loss = 0.00486620
Iteration 122, loss = 0.00483346
Iteration 123, loss = 0.00485250
Iteration 124, loss = 0.00482503
Iteration 125, loss = 0.00483701
Iteration 126, loss = 0.00478980
Iteration 127, loss = 0.00479408
Iteration 128, loss = 0.00485576
Iteration 129, loss = 0.00476510
Iteration 130, loss = 0.00478017
Iteration 131, loss = 0.00479512
Iteration 132, loss = 0.00472766
Iteration 133, loss = 0.00475996
Iteration 134, loss = 0.00484708
Iteration 135, loss = 0.00474878
Iteration 136, loss = 0.00465363
Iteration 137, loss = 0.00473325
Iteration 138, loss = 0.00488066
Iteration 139, loss = 0.00466337
Iteration 140, loss = 0.00468090
Iteration 141, loss = 0.00464414
Iteration 142, loss = 0.00472170
Iteration 143, loss = 0.00481410
Iteration 144, loss = 0.00467049
Iteration 145, loss = 0.00462150
Iteration 146, loss = 0.00464230
Iteration 147, loss = 0.00471286
Iteration 148, loss = 0.00472174
Iteration 149, loss = 0.00459156
Iteration 150, loss = 0.00459268
Iteration 151, loss = 0.00467877
Iteration 152, loss = 0.00473625
Iteration 153, loss = 0.00461401
Iteration 154, loss = 0.00465899
Iteration 155, loss = 0.00455047
Iteration 156, loss = 0.00457461
Iteration 157, loss = 0.00455950
Iteration 158, loss = 0.00465719
Iteration 159, loss = 0.00464665
Iteration 160, loss = 0.00457665
Iteration 161, loss = 0.00465351
Iteration 162, loss = 0.00445415
Iteration 163, loss = 0.00452903
Iteration 164, loss = 0.00461712
Iteration 165, loss = 0.00466329
Iteration 166, loss = 0.00453455
Iteration 167, loss = 0.00453478
Iteration 168, loss = 0.00458625
Iteration 169, loss = 0.00450390
Iteration 170, loss = 0.00455345
Iteration 171, loss = 0.00451066
Iteration 172, loss = 0.00447716
Iteration 173, loss = 0.00467624
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
Iteration 1, loss = 0.11852778
Iteration 2, loss = 0.05928321
Iteration 3, loss = 0.04914441
Iteration 4, loss = 0.04164132
Iteration 5, loss = 0.03636852
Iteration 6, loss = 0.03261773
Iteration 7, loss = 0.02984646
Iteration 8, loss = 0.02763799
Iteration 9, loss = 0.02583087
Iteration 10, loss = 0.02440746
Iteration 11, loss = 0.02294399
Iteration 12, loss = 0.02173993
Iteration 13, loss = 0.02079066
Iteration 14, loss = 0.01982702
Iteration 15, loss = 0.01904553
Iteration 16, loss = 0.01820457
Iteration 17, loss = 0.01760933
Iteration 18, loss = 0.01692428
Iteration 19, loss = 0.01642799
Iteration 20, loss = 0.01580904
Iteration 21, loss = 0.01527043
Iteration 22, loss = 0.01489774
Iteration 23, loss = 0.01443774
Iteration 24, loss = 0.01392220
Iteration 25, loss = 0.01345257
Iteration 26, loss = 0.01300713
Iteration 27, loss = 0.01293193
Iteration 28, loss = 0.01244342
Iteration 29, loss = 0.01211590
Iteration 30, loss = 0.01180603
Iteration 31, loss = 0.01159340
Iteration 32, loss = 0.01122685
Iteration 33, loss = 0.01088529
Iteration 34, loss = 0.01081343
Iteration 35, loss = 0.01059850
Iteration 36, loss = 0.01030935
Iteration 37, loss = 0.01014835
Iteration 38, loss = 0.00978403
Iteration 39, loss = 0.00976183
Iteration 40, loss = 0.00949479
Iteration 41, loss = 0.00934344
Iteration 42, loss = 0.00921658
Iteration 43, loss = 0.00879914
Iteration 44, loss = 0.00874546
Iteration 45, loss = 0.00876461
Iteration 46, loss = 0.00847366
Iteration 47, loss = 0.00838403
Iteration 48, loss = 0.00835896
Iteration 49, loss = 0.00796764
Iteration 50, loss = 0.00802152
Iteration 51, loss = 0.00776996
Iteration 52, loss = 0.00780936
Iteration 53, loss = 0.00753251
Iteration 54, loss = 0.00750196
Iteration 55, loss = 0.00743273
Iteration 56, loss = 0.00723450
Iteration 57, loss = 0.00717074
Iteration 58, loss = 0.00701654
Iteration 59, loss = 0.00695218
Iteration 60, loss = 0.00689038
Iteration 61, loss = 0.00681884
Iteration 62, loss = 0.00673983
Iteration 63, loss = 0.00659997
Iteration 64, loss = 0.00652303
Iteration 65, loss = 0.00645756
Iteration 66, loss = 0.00639564
Iteration 67, loss = 0.00637603
Iteration 68, loss = 0.00634726
Iteration 69, loss = 0.00621250
Iteration 70, loss = 0.00623900
Iteration 71, loss = 0.00633054
Iteration 72, loss = 0.00599894
Iteration 73, loss = 0.00597878
Iteration 74, loss = 0.00590514
Iteration 75, loss = 0.00595061
Iteration 76, loss = 0.00583040
Iteration 77, loss = 0.00594605
Iteration 78, loss = 0.00567668
Iteration 79, loss = 0.00570914
Iteration 80, loss = 0.00576743
Iteration 81, loss = 0.00563338
Iteration 82, loss = 0.00558398
Iteration 83, loss = 0.00560144
Iteration 84, loss = 0.00552366
Iteration 85, loss = 0.00555935
Iteration 86, loss = 0.00550731
Iteration 87, loss = 0.00553932
Iteration 88, loss = 0.00551810
Iteration 89, loss = 0.00543237
Iteration 90, loss = 0.00533147
Iteration 91, loss = 0.00537095
Iteration 92, loss = 0.00534494
Iteration 93, loss = 0.00532916
Iteration 94, loss = 0.00525185
Iteration 95, loss = 0.00531616
Iteration 96, loss = 0.00521597
Iteration 97, loss = 0.00521557
Iteration 98, loss = 0.00520062
Iteration 99, loss = 0.00509591
Iteration 100, loss = 0.00509295
Iteration 101, loss = 0.00514144
Iteration 102, loss = 0.00516425
Iteration 103, loss = 0.00504968
Iteration 104, loss = 0.00512492
Iteration 105, loss = 0.00515479
Iteration 106, loss = 0.00499592
Iteration 107, loss = 0.00509653
Iteration 108, loss = 0.00509160
Iteration 109, loss = 0.00499780
Iteration 110, loss = 0.00491731
Iteration 111, loss = 0.00491920
Iteration 112, loss = 0.00505245
Iteration 113, loss = 0.00513847
Iteration 114, loss = 0.00487433
Iteration 115, loss = 0.00490111
Iteration 116, loss = 0.00490929
Iteration 117, loss = 0.00498901
Iteration 118, loss = 0.00487900
Iteration 119, loss = 0.00485158
Iteration 120, loss = 0.00493787
Iteration 121, loss = 0.00490196
Iteration 122, loss = 0.00482721
Iteration 123, loss = 0.00479491
Iteration 124, loss = 0.00484838
Iteration 125, loss = 0.00488967
Iteration 126, loss = 0.00488096
Iteration 127, loss = 0.00481379
Iteration 128, loss = 0.00476069
Iteration 129, loss = 0.00470404
Iteration 130, loss = 0.00472483
Iteration 131, loss = 0.00487240
Iteration 132, loss = 0.00475634
Iteration 133, loss = 0.00474478
Iteration 134, loss = 0.00467340
Iteration 135, loss = 0.00477242
Iteration 136, loss = 0.00470977
Iteration 137, loss = 0.00467085
Iteration 138, loss = 0.00473736
Iteration 139, loss = 0.00488678
Iteration 140, loss = 0.00481914
Iteration 141, loss = 0.00462964
Iteration 142, loss = 0.00460762
Iteration 143, loss = 0.00468570
Iteration 144, loss = 0.00465733
Iteration 145, loss = 0.00463563
Iteration 146, loss = 0.00463778
Iteration 147, loss = 0.00472408
Iteration 148, loss = 0.00468003
Iteration 149, loss = 0.00464257
Iteration 150, loss = 0.00470957
Iteration 151, loss = 0.00478654
Iteration 152, loss = 0.00458753
Iteration 153, loss = 0.00456736
Iteration 154, loss = 0.00468421
Iteration 155, loss = 0.00461340
Iteration 156, loss = 0.00471722
Iteration 157, loss = 0.00463159
Iteration 158, loss = 0.00451505
Iteration 159, loss = 0.00457625
Iteration 160, loss = 0.00469625
Iteration 161, loss = 0.00458970
Iteration 162, loss = 0.00460248
Iteration 163, loss = 0.00453249
Iteration 164, loss = 0.00455621
Iteration 165, loss = 0.00452781
Iteration 166, loss = 0.00460079
Iteration 167, loss = 0.00461823
Iteration 168, loss = 0.00458489
Iteration 169, loss = 0.00453646
Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.
